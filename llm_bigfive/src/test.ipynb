{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from vllm.lora.request import LoRARequest\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.llms.vllm import VLLM\n",
    "import evaluate\n",
    "import json\n",
    "from langchain_core.prompts import (\n",
    "  ChatPromptTemplate,\n",
    "  SystemMessagePromptTemplate,\n",
    "  HumanMessagePromptTemplate\n",
    ")\n",
    "import rich\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define system prompt and human message\n",
    "\n",
    "model_paths = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "system_template = \"You are a helpful assistant.\"\n",
    "messages = [\n",
    "  SystemMessagePromptTemplate.from_template(system_template),\n",
    "  HumanMessagePromptTemplate.from_template('{question}')\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 23:59:25,052\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-15 23:59:32 llm_engine.py:98] Initializing an LLM engine (v0.4.1) with config: model='meta-llama/Meta-Llama-3-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=4, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-15 23:59:41 utils.py:608] Found nccl from library /home/wenkail/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "\u001b[36m(RayWorkerWrapper pid=563652)\u001b[0m INFO 05-15 23:59:41 utils.py:608] Found nccl from library /home/wenkail/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 05-15 23:59:41 selector.py:77] Cannot use FlashAttention backend because the flash_attn package is not found. Please install it for better performance.\n",
      "INFO 05-15 23:59:41 selector.py:33] Using XFormers backend.\n",
      "\u001b[36m(RayWorkerWrapper pid=563725)\u001b[0m INFO 05-15 23:59:42 selector.py:77] Cannot use FlashAttention backend because the flash_attn package is not found. Please install it for better performance.\n",
      "\u001b[36m(RayWorkerWrapper pid=563725)\u001b[0m INFO 05-15 23:59:42 selector.py:33] Using XFormers backend.\n",
      "INFO 05-15 23:59:43 pynccl_utils.py:43] vLLM is using nccl==2.18.1\n",
      "\u001b[36m(RayWorkerWrapper pid=563652)\u001b[0m INFO 05-15 23:59:43 pynccl_utils.py:43] vLLM is using nccl==2.18.1\n",
      "WARNING 05-15 23:59:44 custom_all_reduce.py:65] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[36m(RayWorkerWrapper pid=563652)\u001b[0m WARNING 05-15 23:59:44 custom_all_reduce.py:65] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "INFO 05-15 23:59:44 weight_utils.py:193] Using model weights format ['*.safetensors']\n",
      "\u001b[36m(RayWorkerWrapper pid=563725)\u001b[0m INFO 05-15 23:59:44 weight_utils.py:193] Using model weights format ['*.safetensors']\n",
      "INFO 05-15 23:59:46 model_runner.py:173] Loading model weights took 3.7417 GB\n",
      "\u001b[36m(RayWorkerWrapper pid=563652)\u001b[0m INFO 05-15 23:59:46 model_runner.py:173] Loading model weights took 3.7417 GB\n",
      "\u001b[36m(RayWorkerWrapper pid=563805)\u001b[0m INFO 05-15 23:59:41 utils.py:608] Found nccl from library /home/wenkail/.config/vllm/nccl/cu12/libnccl.so.2.18.1\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=563805)\u001b[0m INFO 05-15 23:59:42 selector.py:77] Cannot use FlashAttention backend because the flash_attn package is not found. Please install it for better performance.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=563805)\u001b[0m INFO 05-15 23:59:42 selector.py:33] Using XFormers backend.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "INFO 05-15 23:59:49 ray_gpu_executor.py:217] # GPU blocks: 76613, # CPU blocks: 8192\n",
      "INFO 05-15 23:59:51 model_runner.py:976] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 05-15 23:59:51 model_runner.py:980] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerWrapper pid=563652)\u001b[0m INFO 05-15 23:59:51 model_runner.py:976] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[36m(RayWorkerWrapper pid=563652)\u001b[0m INFO 05-15 23:59:51 model_runner.py:980] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerWrapper pid=563805)\u001b[0m INFO 05-15 23:59:43 pynccl_utils.py:43] vLLM is using nccl==2.18.1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=563805)\u001b[0m WARNING 05-15 23:59:44 custom_all_reduce.py:65] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=563805)\u001b[0m INFO 05-15 23:59:44 weight_utils.py:193] Using model weights format ['*.safetensors']\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "INFO 05-15 23:59:58 model_runner.py:1057] Graph capturing finished in 7 secs.\n",
      "\u001b[36m(RayWorkerWrapper pid=563652)\u001b[0m INFO 05-15 23:59:58 model_runner.py:1057] Graph capturing finished in 7 secs.\n",
      "\u001b[36m(RayWorkerWrapper pid=563725)\u001b[0m INFO 05-15 23:59:47 model_runner.py:173] Loading model weights took 3.7417 GB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=563805)\u001b[0m INFO 05-15 23:59:51 model_runner.py:976] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=563805)\u001b[0m INFO 05-15 23:59:51 model_runner.py:980] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Now Loading LLama\n",
    "sampling_params = SamplingParams(temperature=0.0, top_p=0.9, top_k=10, max_tokens=4096)\n",
    "model = VLLM(model=model_paths, gpu_memory_utilization = 0.95, tensor_parallel_size=4, sampling_params = sampling_params)\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.97s/it]\n"
     ]
    }
   ],
   "source": [
    "# Test on the first sample\n",
    "\n",
    "# q = \"Act as a openness person in Big Five Personality test. And answer the following question: \"\n",
    "question = \"Please expand a fictional personality background for a person with only one dimension of the big 5 personality traits: openness.\"\n",
    "pair = {\"question\":question}\n",
    "\n",
    "answer = chain.invoke(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> \n",
       "System: Ahaha, what a fascinating request! Here's a background for a character who's super open to new experiences \n",
       "and ideas:\n",
       "\n",
       "Name: Aurora <span style=\"color: #008000; text-decoration-color: #008000\">\"Rory\"</span> Quick\n",
       "\n",
       "Background: Rory grew up in a family that encouraged exploration and creativity. Her parents, both free-spirited \n",
       "artists, owned a small art studio where they hosted weekly jam sessions, painting classes, and workshops. From a \n",
       "young age, Rory was surrounded by musicians, poets, and artists, which fostered her innate curiosity and love for \n",
       "the unknown. She spent hours pouring over her parents' extensive book collection, devouring eclectic mixtapes, and \n",
       "building her own peculiar art projects.\n",
       "\n",
       "As she grew older, Rory became fascinated with contemporary concepts like astral travel, consciousness, and the \n",
       "mysteries of the universe. She started attending lectures, workshops, and seminars on topics like spiritual growth,\n",
       "consciousness, and mysticism. Her friends affectionately nicknamed her <span style=\"color: #008000; text-decoration-color: #008000\">\"Rory the Guru\"</span> due to her uncanny ability \n",
       "to find the most unusual, offbeat events and share them with her social circle.\n",
       "\n",
       "Personality: Rory's unparalleled craving for novelty and exploration makes her the life of the party. She \n",
       "approaches every experience with an insatiable curiosity, asking probing questions and seeking feedback from \n",
       "others. Her wide-eyed enthusiasm can be infectious, drawing others into her passion and energy. When engaged in \n",
       "conversation, Rory's words are peppered with philosophical musings, new-age buzzwords, and tantalizing anecdotes \n",
       "from her latest intellectual discoveries.\n",
       "\n",
       "Strengths:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Curiosity**: Rory's insatiable desire for new experiences and knowledge drives her to seek out the unknown, \n",
       "often leading to unexpected breakthroughs and connections.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Creativity**: Her artistic upbringing and appreciation for unconventional ideas enable her to approach \n",
       "problems from innovative angles, often yielding novel solutions.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **Empathy**: Rory's willingness to explore new perspectives and personas allows her to empathize with others, \n",
       "fostering strong bonds and friendships.\n",
       "\n",
       "Weaknesses:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Idealism**: Rory's unwavering optimism can lead her to idealize certain situations or individuals, causing her\n",
       "to overlook potential flaws or deal-breakers.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Distractibility**: Her constant quest for novelty and stimulation can make it challenging for her to focus on \n",
       "a single task or project for extended periods.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **Overly analytical**: Rory's analytical mind can sometimes lead her to overthink and overanalyze, making it \n",
       "difficult for her to trust her instincts or make quick decisions.\n",
       "\n",
       "Overall, Rory's high openness to experience makes her\n",
       "</pre>\n"
      ],
      "text/plain": [
       " \n",
       "System: Ahaha, what a fascinating request! Here's a background for a character who's super open to new experiences \n",
       "and ideas:\n",
       "\n",
       "Name: Aurora \u001b[32m\"Rory\"\u001b[0m Quick\n",
       "\n",
       "Background: Rory grew up in a family that encouraged exploration and creativity. Her parents, both free-spirited \n",
       "artists, owned a small art studio where they hosted weekly jam sessions, painting classes, and workshops. From a \n",
       "young age, Rory was surrounded by musicians, poets, and artists, which fostered her innate curiosity and love for \n",
       "the unknown. She spent hours pouring over her parents' extensive book collection, devouring eclectic mixtapes, and \n",
       "building her own peculiar art projects.\n",
       "\n",
       "As she grew older, Rory became fascinated with contemporary concepts like astral travel, consciousness, and the \n",
       "mysteries of the universe. She started attending lectures, workshops, and seminars on topics like spiritual growth,\n",
       "consciousness, and mysticism. Her friends affectionately nicknamed her \u001b[32m\"Rory the Guru\"\u001b[0m due to her uncanny ability \n",
       "to find the most unusual, offbeat events and share them with her social circle.\n",
       "\n",
       "Personality: Rory's unparalleled craving for novelty and exploration makes her the life of the party. She \n",
       "approaches every experience with an insatiable curiosity, asking probing questions and seeking feedback from \n",
       "others. Her wide-eyed enthusiasm can be infectious, drawing others into her passion and energy. When engaged in \n",
       "conversation, Rory's words are peppered with philosophical musings, new-age buzzwords, and tantalizing anecdotes \n",
       "from her latest intellectual discoveries.\n",
       "\n",
       "Strengths:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **Curiosity**: Rory's insatiable desire for new experiences and knowledge drives her to seek out the unknown, \n",
       "often leading to unexpected breakthroughs and connections.\n",
       "\u001b[1;36m2\u001b[0m. **Creativity**: Her artistic upbringing and appreciation for unconventional ideas enable her to approach \n",
       "problems from innovative angles, often yielding novel solutions.\n",
       "\u001b[1;36m3\u001b[0m. **Empathy**: Rory's willingness to explore new perspectives and personas allows her to empathize with others, \n",
       "fostering strong bonds and friendships.\n",
       "\n",
       "Weaknesses:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **Idealism**: Rory's unwavering optimism can lead her to idealize certain situations or individuals, causing her\n",
       "to overlook potential flaws or deal-breakers.\n",
       "\u001b[1;36m2\u001b[0m. **Distractibility**: Her constant quest for novelty and stimulation can make it challenging for her to focus on \n",
       "a single task or project for extended periods.\n",
       "\u001b[1;36m3\u001b[0m. **Overly analytical**: Rory's analytical mind can sometimes lead her to overthink and overanalyze, making it \n",
       "difficult for her to trust her instincts or make quick decisions.\n",
       "\n",
       "Overall, Rory's high openness to experience makes her\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_personality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
