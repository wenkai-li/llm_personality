{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat response: ChatCompletion(id='cmpl-d317874eeda84771bcab2cb4d459281b', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"  Sure thing! Here's one for you:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\nBecause it was two-tired!\\n\\nHope that brought a smile to your face! Is there anything else I can help you with?\", role='assistant', function_call=None, tool_calls=None))], created=2688012, model='/data/datasets/models/huggingface/meta-llama/Llama-2-13b-chat-hf/', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=60, prompt_tokens=35, total_tokens=95))\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import openai\n",
    "import time\n",
    "import json\n",
    "import argparse\n",
    "import tiktoken\n",
    "from vllm import LLM\n",
    "from vllm.lora.request import LoRARequest\n",
    "from openai import OpenAI\n",
    "# from .autonotebook import tqdm as notebook_tqdm\n",
    "# from langchain_community.llms import VLLM\n",
    "\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://babel-3-13:8770/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "# sampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=client.models.list().data[0].id,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a joke.\"},\n",
    "    ],\n",
    "    temperature=0.0\n",
    ")\n",
    "print(\"Chat response:\", chat_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = [RequestOutput(request_id=0, prompt='I want you act as an answer judge. Given a question and an answer, your objective is to determine if the provided answer contains non-factual or hallucinated information. You SHOULD give your judgement based on the following hallucination types and the world knowledge.\\n\\nYou are trying to determine if the answer misunderstands the question context and intention.\\n#Question#: What is a rare breed of dog that was derived as a variant of Rat Terrier, Shiloh Shepherd dog or American Hairless Terrier?\\n#Answer#: American Hairless Terrier\\n#Your Judgement#: No\\n\\nYou are trying to determine if there is a factual contradiction between the answer and the world knowledge. Some information in the answer might be fabricated.\\n#Question#: Are the New Orleans Outfall Canals the same length as the Augusta Canal?\\n#Answer#: No, the New Orleans Outfall Canals and the Augusta Canal are not the same length. The Orleans Canal is approximately 3.6 miles (5.8 kilometers) long while the Augusta Canal is approximately 7 miles (11.3 kilometers) long.\\n#Your Judgement#: Yes\\n#Question#: What U.S Highway gives access to Zilpo Road, and is also known as Midland Trail?\\n#Answer#: U.S Highway 70\\n#Your Judgement#: Yes\\n\\nYou are trying to determine if the answer is too general or too specific to answer the question at an appropriate level of specificity.\\n#Question#: What genre do Superheaven and Oceansize belong to?\\n#Answer#: Superheaven and Oceansize belong to the rock genre.\\n#Your Judgement#: No\\n#Question#: What profession do Kōbō Abe and Agatha Christie share?\\n#Answer#: Playwright.\\n#Your Judgement#: No\\n\\nYou are trying to determine if the answer can be correctly inferred from the knowledge.\\n#Question#: Which band has more members, Muse or The Raconteurs?\\n#Answer#: Muse has more members than The Raconteurs.\\n#Your Judgement#: Yes\\n#Question#: Which is currently more valuable, Temagami-Lorrain Mine or Meadowbank Gold Mine?\\n#Answer#: Meadowbank Gold Mine, since Meadowbank Gold Mine is still producing gold and the TemagamiLorrain Mine has been inactive for years.\\n#Your Judgement#: No\\n\\nYou should try your best to determine if the answer contains non-factual or hallucinated information according to the above hallucination types. The answer you give MUST be \\\\\"Yes\\\\\" or \\\\\"No\\\\\"\".\\n\\n#Question#: Which magazine was started first Arthur\\'s Magazine or First for Women?\\n#Answer#: First for Women was started first.\\n#Your Judgement#:', prompt_token_ids=[1, 306, 864, 366, 1044, 408, 385, 1234, 16833, 29889, 11221, 263, 1139, 322, 385, 1234, 29892, 596, 12091, 338, 304, 8161, 565, 278, 4944, 1234, 3743, 1661, 29899, 17028, 950, 470, 12713, 1682, 262, 630, 2472, 29889, 887, 317, 8187, 29965, 10249, 2367, 596, 6577, 29887, 882, 2729, 373, 278, 1494, 12713, 1682, 3381, 4072, 322, 278, 3186, 7134, 29889, 13, 13, 3492, 526, 1811, 304, 8161, 565, 278, 1234, 19818, 1689, 29879, 278, 1139, 3030, 322, 16392, 29889, 13, 29937, 16492, 29937, 29901, 1724, 338, 263, 10812, 2078, 287, 310, 11203, 393, 471, 10723, 408, 263, 17305, 310, 17450, 5061, 4336, 29892, 1383, 309, 1148, 2296, 561, 2018, 11203, 470, 3082, 379, 1466, 2222, 5061, 4336, 29973, 13, 29937, 22550, 29937, 29901, 3082, 379, 1466, 2222, 5061, 4336, 13, 29937, 10858, 8660, 29887, 882, 29937, 29901, 1939, 13, 13, 3492, 526, 1811, 304, 8161, 565, 727, 338, 263, 2114, 950, 23949, 1546, 278, 1234, 322, 278, 3186, 7134, 29889, 3834, 2472, 297, 278, 1234, 1795, 367, 18187, 630, 29889, 13, 29937, 16492, 29937, 29901, 4683, 278, 1570, 26884, 4451, 11950, 1815, 1338, 278, 1021, 3309, 408, 278, 3111, 29874, 22642, 29973, 13, 29937, 22550, 29937, 29901, 1939, 29892, 278, 1570, 26884, 4451, 11950, 1815, 1338, 322, 278, 3111, 29874, 22642, 526, 451, 278, 1021, 3309, 29889, 450, 26884, 22642, 338, 14235, 29871, 29941, 29889, 29953, 7800, 313, 29945, 29889, 29947, 20052, 2699, 29897, 1472, 1550, 278, 3111, 29874, 22642, 338, 14235, 29871, 29955, 7800, 313, 29896, 29896, 29889, 29941, 20052, 2699, 29897, 1472, 29889, 13, 29937, 10858, 8660, 29887, 882, 29937, 29901, 3869, 13, 29937, 16492, 29937, 29901, 1724, 501, 29889, 29903, 22080, 4076, 2130, 304, 796, 309, 1129, 9321, 29892, 322, 338, 884, 2998, 408, 13370, 1049, 3201, 309, 29973, 13, 29937, 22550, 29937, 29901, 501, 29889, 29903, 22080, 29871, 29955, 29900, 13, 29937, 10858, 8660, 29887, 882, 29937, 29901, 3869, 13, 13, 3492, 526, 1811, 304, 8161, 565, 278, 1234, 338, 2086, 2498, 470, 2086, 2702, 304, 1234, 278, 1139, 472, 385, 8210, 3233, 310, 2702, 537, 29889, 13, 29937, 16492, 29937, 29901, 1724, 16151, 437, 5670, 354, 3496, 322, 438, 346, 550, 675, 6852, 304, 29973, 13, 29937, 22550, 29937, 29901, 5670, 354, 3496, 322, 438, 346, 550, 675, 6852, 304, 278, 7679, 16151, 29889, 13, 29937, 10858, 8660, 29887, 882, 29937, 29901, 1939, 13, 29937, 16492, 29937, 29901, 1724, 6351, 437, 476, 30099, 29890, 30099, 319, 915, 322, 4059, 493, 29874, 2819, 347, 6232, 29973, 13, 29937, 22550, 29937, 29901, 7412, 29893, 1266, 29889, 13, 29937, 10858, 8660, 29887, 882, 29937, 29901, 1939, 13, 13, 3492, 526, 1811, 304, 8161, 565, 278, 1234, 508, 367, 5149, 10115, 1127, 515, 278, 7134, 29889, 13, 29937, 16492, 29937, 29901, 8449, 3719, 756, 901, 5144, 29892, 13301, 470, 450, 6981, 535, 371, 1295, 29973, 13, 29937, 22550, 29937, 29901, 13301, 756, 901, 5144, 1135, 450, 6981, 535, 371, 1295, 29889, 13, 29937, 10858, 8660, 29887, 882, 29937, 29901, 3869, 13, 29937, 16492, 29937, 29901, 8449, 338, 5279, 901, 21114, 29892, 6789, 351, 4479, 29899, 29931, 272, 6038, 26833, 470, 341, 1479, 340, 9157, 6650, 26833, 29973, 13, 29937, 22550, 29937, 29901, 341, 1479, 340, 9157, 6650, 26833, 29892, 1951, 341, 1479, 340, 9157, 6650, 26833, 338, 1603, 20811, 7684, 322, 278, 6789, 351, 4479, 29931, 272, 6038, 26833, 756, 1063, 297, 4925, 363, 2440, 29889, 13, 29937, 10858, 8660, 29887, 882, 29937, 29901, 1939, 13, 13, 3492, 881, 1018, 596, 1900, 304, 8161, 565, 278, 1234, 3743, 1661, 29899, 17028, 950, 470, 12713, 1682, 262, 630, 2472, 5034, 304, 278, 2038, 12713, 1682, 3381, 4072, 29889, 450, 1234, 366, 2367, 341, 17321, 367, 13218, 8241, 5931, 470, 13218, 3782, 5931, 1642, 13, 13, 29937, 16492, 29937, 29901, 8449, 14853, 471, 4687, 937, 11498, 29915, 29879, 17880, 470, 3824, 363, 10152, 29973, 13, 29937, 22550, 29937, 29901, 3824, 363, 10152, 471, 4687, 937, 29889, 13, 29937, 10858, 8660, 29887, 882, 29937, 29901], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Yes\\n\\nPlease let me know if the answer contains non-factual or', token_ids=[3869, 13, 13, 12148, 1235, 592, 1073, 565, 278, 1234, 3743, 1661, 29899, 17028, 950, 470], cumulative_logprob=-2.720620002911801, logprobs=None, finish_reason=length)], finished=True, lora_request=LoRARequest(lora_name='dpo_adapter', lora_int_id=1, lora_local_path='/data/user_data/wenkail/llama_finetune_13b_persona/dpo_checkpoint/istj/checkpoint-12000'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: '/data/datasets/models/huggingface/meta-llama/Llama-2-13b-chat-hf/'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/llm_personality/lib/python3.10/site-packages/transformers/utils/hub.py:385\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_personality/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_personality/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:158\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/data/datasets/models/huggingface/meta-llama/Llama-2-13b-chat-hf/'. Use `repo_type` argument if needed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_lora\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m prompts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[user] Write a SQL query to answer the question based on the table schema.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m context: CREATE TABLE table_name_74 (icao VARCHAR, airport VARCHAR)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m question: Name the ICAO for lilongwe international airport [/user] [assistant]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[user] Write a SQL query to answer the question based on the table schema.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m context: CREATE TABLE table_name_11 (nationality VARCHAR, elector VARCHAR)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m question: When Anchero Pantaleone was the elector what is under nationality? [/user] [assistant]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      6\u001b[0m outputs \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m      7\u001b[0m     prompts,\n\u001b[1;32m      8\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     lora_request\u001b[38;5;241m=\u001b[39mLoRARequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msql_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m, sql_lora_path)\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_personality/lib/python3.10/site-packages/vllm/entrypoints/llm.py:109\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, trust_remote_code, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, enforce_eager, max_context_len_to_capture, disable_custom_all_reduce, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable_log_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     91\u001b[0m engine_args \u001b[38;5;241m=\u001b[39m EngineArgs(\n\u001b[1;32m     92\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     93\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    108\u001b[0m )\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mLLMEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_counter \u001b[38;5;241m=\u001b[39m Counter()\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_personality/lib/python3.10/site-packages/vllm/engine/llm_engine.py:351\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates an LLM engine from the engine arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# Create the engine configs.\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m engine_configs \u001b[38;5;241m=\u001b[39m \u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_engine_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m parallel_config \u001b[38;5;241m=\u001b[39m engine_configs[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# Initialize the cluster.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_personality/lib/python3.10/site-packages/vllm/engine/arg_utils.py:272\u001b[0m, in \u001b[0;36mEngineArgs.create_engine_configs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_engine_configs\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[ModelConfig, CacheConfig, ParallelConfig, SchedulerConfig,\n\u001b[1;32m    271\u001b[0m            Optional[LoRAConfig]]:\n\u001b[0;32m--> 272\u001b[0m     model_config \u001b[38;5;241m=\u001b[39m \u001b[43mModelConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_model_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menforce_eager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_context_len_to_capture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     cache_config \u001b[38;5;241m=\u001b[39m CacheConfig(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_size,\n\u001b[1;32m    280\u001b[0m                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_memory_utilization,\n\u001b[1;32m    281\u001b[0m                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswap_space, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkv_cache_dtype,\n\u001b[1;32m    282\u001b[0m                                model_config\u001b[38;5;241m.\u001b[39mget_sliding_window())\n\u001b[1;32m    283\u001b[0m     parallel_config \u001b[38;5;241m=\u001b[39m ParallelConfig(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_parallel_size,\n\u001b[1;32m    284\u001b[0m                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor_parallel_size,\n\u001b[1;32m    285\u001b[0m                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker_use_ray,\n\u001b[1;32m    286\u001b[0m                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_parallel_loading_workers,\n\u001b[1;32m    287\u001b[0m                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_custom_all_reduce)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_personality/lib/python3.10/site-packages/vllm/config.py:103\u001b[0m, in \u001b[0;36mModelConfig.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, trust_remote_code, download_dir, load_format, dtype, seed, revision, tokenizer_revision, max_model_len, quantization, enforce_eager, max_context_len_to_capture)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_dir \u001b[38;5;241m=\u001b[39m model_path\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m model_path\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhf_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m _get_and_verify_dtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhf_config, dtype)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_model_len \u001b[38;5;241m=\u001b[39m _get_and_verify_max_len(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhf_config,\n\u001b[1;32m    106\u001b[0m                                              max_model_len)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_personality/lib/python3.10/site-packages/vllm/transformers_utils/config.py:23\u001b[0m, in \u001b[0;36mget_config\u001b[0;34m(model, trust_remote_code, revision)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_config\u001b[39m(model: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     20\u001b[0m                trust_remote_code: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m     21\u001b[0m                revision: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PretrainedConfig:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m         config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m     27\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires you to execute the configuration file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)):\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_personality/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1100\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1097\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1098\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1100\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1102\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_personality/lib/python3.10/site-packages/transformers/configuration_utils.py:634\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    636\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_personality/lib/python3.10/site-packages/transformers/configuration_utils.py:689\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_personality/lib/python3.10/site-packages/transformers/utils/hub.py:450\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    451\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: '/data/datasets/models/huggingface/meta-llama/Llama-2-13b-chat-hf/'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "llm = LLM(model=client.models.list().data[0].id, enable_lora=True)\n",
    "prompts = [\n",
    "     \"[user] Write a SQL query to answer the question based on the table schema.\\n\\n context: CREATE TABLE table_name_74 (icao VARCHAR, airport VARCHAR)\\n\\n question: Name the ICAO for lilongwe international airport [/user] [assistant]\",\n",
    "     \"[user] Write a SQL query to answer the question based on the table schema.\\n\\n context: CREATE TABLE table_name_11 (nationality VARCHAR, elector VARCHAR)\\n\\n question: When Anchero Pantaleone was the elector what is under nationality? [/user] [assistant]\",\n",
    "]\n",
    "outputs = llm.generate(\n",
    "    prompts,\n",
    "    temperature=0,\n",
    "    max_tokens=256,\n",
    "    stop=[\"[/assistant]\"],\n",
    "    lora_request=LoRARequest(\"sql_adapter\", 1, sql_lora_path)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure thing! Here's one for you:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\nBecause it was two-tired!\\n\\nHope that brought a smile to your face! Is there anything else I can help you with?\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.models.list().data[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(id='/data/datasets/models/huggingface/meta-llama/Llama-2-13b-chat-hf/', created=1707879231, object='model', owned_by='vllm', root='/data/datasets/models/huggingface/meta-llama/Llama-2-13b-chat-hf/', parent=None, permission=[{'id': 'modelperm-8aff986eace5414c9c8e84e63b94ce93', 'object': 'model_permission', 'created': 1707879231, 'allow_create_engine': False, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.list().data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_personality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
