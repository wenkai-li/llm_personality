### model
# model_name_or_path: /data/user_data/jiaruil5/.cache/models--meta-llama--Meta-Llama-3-8B-Instruct/snapshots/c4a54320a52ed5f88b7a2f84496903ea4ff07b45/
model_name_or_path: /compute/babel-0-37/jiaruil5/personality/checkpoints/generator_whole_1e-6/checkpoint-9000/
# model_name_or_path: /compute/babel-0-37/jiaruil5/personality/checkpoints/generator_whole_no_tokens_1e-6/checkpoint-6000/

### method
stage: sft
do_predict: true
finetuning_type: full

### dataset
dataset: alpaca_big_five_dataset_test_5_tokens_deduplicated
# dataset: alpaca_big_five_dataset_test_no_tokens
dataset_dir: /data/user_data/wenkail/llm_personality/generator/data/
template: llama3
cutoff_len: 512
# max_samples: 10000
overwrite_cache: true
preprocessing_num_workers: 16

### output
output_dir: /home/jiaruil5/personality/llm_personality/llm_bigfive/generator/outputs/w_tokens
# output_dir: /home/jiaruil5/personality/llm_personality/llm_bigfive/generator/outputs/no_tokens
overwrite_output_dir: true

### eval
per_device_eval_batch_size: 1
predict_with_generate: true

# CUDA_VISIBLE_DEVICES=0,1,2,3 WANDB_PROJECT=llm_personality WANDB_ENTITY=kyle_organization llamafactory-cli train llama3_inference.yaml 