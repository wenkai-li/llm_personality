### model
model_name_or_path: /data/user_data/wenkail/llm_personality/generator/generator_whole_n_1e-6/

### method
stage: sft
do_predict: true
finetuning_type: full

### dataset
dataset: test_n
dataset_dir: /data/user_data/wenkail/llm_personality/generator/data/
template: llama3
cutoff_len: 1024
max_samples: 1000
overwrite_cache: true
preprocessing_num_workers: 16

### output
output_dir: /home/jiaruil5/personality/llm_personality/llm_bigfive/generator/outputs/test_n
overwrite_output_dir: true

### generation
do_sample: False

### eval
per_device_eval_batch_size: 1
predict_with_generate: true

# CUDA_VISIBLE_DEVICES=0,1,2,3 WANDB_PROJECT=llm_personality WANDB_ENTITY=kyle_organization llamafactory-cli train inference_generator_n.yaml 