06/19/2024 01:31:46 - INFO - __main__ - Logging setup complete.
06/19/2024 01:31:48 - ERROR - root - wandb: Currently logged in as: jiaruiliu999 (kyle_organization). Use `wandb login --relogin` to force relogin
06/19/2024 01:32:02 - ERROR - root - wandb: wandb version 0.17.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
06/19/2024 01:32:02 - ERROR - root - wandb: Tracking run with wandb version 0.16.3
06/19/2024 01:32:02 - ERROR - root - wandb: Run data is saved locally in /home/jiaruil5/personality/llm_personality/llm_bigfive/classifier/wandb/run-20240619_013148-p2uh9csg
wandb: Run `wandb offline` to turn off syncing.
06/19/2024 01:32:02 - ERROR - root - wandb: Syncing run test-ce-50-examples-1e-4
06/19/2024 01:32:02 - ERROR - root - wandb:  View project at https://wandb.ai/kyle_organization/llm_personality
06/19/2024 01:32:02 - ERROR - root - wandb:  View run at https://wandb.ai/kyle_organization/llm_personality/runs/p2uh9csg
06/19/2024 01:32:04 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
06/19/2024 01:32:04 - ERROR - root - /data/user_data/jiaruil5/miniconda3/envs/new/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
06/19/2024 01:32:04 - ERROR - root -   0%|          | 0/390 [00:00<?, ?it/s]
06/19/2024 01:32:07 - INFO - modeling_roberta - Training sub-loss: O 1.2005603313446045, C 1.1025559902191162, E 1.0030157566070557, A 1.1442921161651611, N 1.0863916873931885
06/19/2024 01:32:08 - INFO - modeling_roberta - Training sub-loss: O 1.0918238162994385, C 1.0804102420806885, E 1.353718638420105, A 1.0901130437850952, N 1.1081733703613281
06/19/2024 01:32:08 - ERROR - root - /data/user_data/jiaruil5/miniconda3/envs/new/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
06/19/2024 01:32:10 - INFO - modeling_roberta - Training sub-loss: O 1.104254961013794, C 1.1305437088012695, E 1.1191699504852295, A 1.2248668670654297, N 1.1373330354690552
06/19/2024 01:32:10 - INFO - modeling_roberta - Training sub-loss: O 1.0912621021270752, C 1.1214699745178223, E 1.1395766735076904, A 1.12430739402771, N 1.0296308994293213
06/19/2024 01:32:11 - ERROR - root -   0%|          | 1/390 [00:06<42:51,  6.61s/it]
06/19/2024 01:32:12 - INFO - modeling_roberta - Training sub-loss: O 1.3018423318862915, C 1.2656365633010864, E 1.0466160774230957, A 1.2264282703399658, N 1.2646687030792236
06/19/2024 01:32:12 - INFO - modeling_roberta - Training sub-loss: O 1.1679192781448364, C 1.0177464485168457, E 0.9401021599769592, A 1.1292088031768799, N 1.1213735342025757
06/19/2024 01:32:13 - INFO - modeling_roberta - Training sub-loss: O 1.3168622255325317, C 1.263205885887146, E 1.1002914905548096, A 1.1026266813278198, N 1.1632969379425049
06/19/2024 01:32:13 - INFO - modeling_roberta - Training sub-loss: O 1.0835723876953125, C 1.1699070930480957, E 1.170287847518921, A 1.0198500156402588, N 1.1212501525878906
06/19/2024 01:32:14 - ERROR - root -   1%|          | 2/390 [00:09<29:15,  4.53s/it]
06/19/2024 01:32:15 - INFO - modeling_roberta - Training sub-loss: O 1.2099841833114624, C 1.045737862586975, E 1.1819406747817993, A 1.0389246940612793, N 1.1309328079223633
06/19/2024 01:32:15 - INFO - modeling_roberta - Training sub-loss: O 1.142104148864746, C 1.096541404724121, E 1.0772314071655273, A 1.0723934173583984, N 1.1017900705337524
06/19/2024 01:32:16 - INFO - modeling_roberta - Training sub-loss: O 1.0988014936447144, C 1.1484662294387817, E 1.0500630140304565, A 1.0978703498840332, N 1.1314051151275635
06/19/2024 01:32:16 - INFO - modeling_roberta - Training sub-loss: O 1.146214246749878, C 1.1243367195129395, E 1.085587739944458, A 1.140946865081787, N 1.0489392280578613
06/19/2024 01:32:17 - ERROR - root -   1%|          | 3/390 [00:12<24:59,  3.87s/it]
06/19/2024 01:32:18 - INFO - modeling_roberta - Training sub-loss: O 1.1212947368621826, C 1.1850413084030151, E 1.153908371925354, A 1.1577606201171875, N 1.204000473022461
06/19/2024 01:32:18 - INFO - modeling_roberta - Training sub-loss: O 1.099365472793579, C 1.0513451099395752, E 1.1294927597045898, A 1.1303045749664307, N 1.0202319622039795
06/19/2024 01:32:19 - INFO - modeling_roberta - Training sub-loss: O 1.1410340070724487, C 1.112726092338562, E 1.1713974475860596, A 1.0778244733810425, N 1.1038572788238525
06/19/2024 01:32:19 - INFO - modeling_roberta - Training sub-loss: O 1.0937514305114746, C 1.0872740745544434, E 1.1112306118011475, A 1.1882421970367432, N 1.0803636312484741
06/19/2024 01:32:20 - ERROR - root -   1%|1         | 4/390 [00:15<22:56,  3.56s/it]
06/19/2024 01:32:21 - INFO - modeling_roberta - Training sub-loss: O 1.1011297702789307, C 1.0979654788970947, E 1.151684045791626, A 1.09133780002594, N 1.1371583938598633
06/19/2024 01:32:21 - INFO - modeling_roberta - Training sub-loss: O 1.1007177829742432, C 1.1244462728500366, E 1.1225695610046387, A 1.1825662851333618, N 1.1593871116638184
06/19/2024 01:32:22 - INFO - modeling_roberta - Training sub-loss: O 1.1725592613220215, C 0.991106390953064, E 0.9891736507415771, A 1.1037390232086182, N 1.1135329008102417
06/19/2024 01:32:22 - INFO - modeling_roberta - Training sub-loss: O 1.1589750051498413, C 1.1534826755523682, E 1.1167534589767456, A 1.1890532970428467, N 1.1940677165985107
06/19/2024 01:32:23 - ERROR - root -   1%|1         | 5/390 [00:18<21:46,  3.39s/it]
06/19/2024 01:32:24 - INFO - modeling_roberta - Training sub-loss: O 1.1238927841186523, C 1.0706841945648193, E 1.182886004447937, A 1.0927717685699463, N 1.1041343212127686
06/19/2024 01:32:24 - INFO - modeling_roberta - Training sub-loss: O 1.114366888999939, C 1.1450154781341553, E 1.16177237033844, A 1.132547378540039, N 1.1006522178649902
06/19/2024 01:32:26 - INFO - modeling_roberta - Training sub-loss: O 1.1221232414245605, C 1.067399501800537, E 1.129570722579956, A 1.0779554843902588, N 1.107400894165039
06/19/2024 01:32:26 - INFO - modeling_roberta - Training sub-loss: O 1.1168264150619507, C 1.096158504486084, E 1.0902793407440186, A 1.0960073471069336, N 1.0832901000976562
06/19/2024 01:32:26 - ERROR - root -   2%|1         | 6/390 [00:22<21:02,  3.29s/it]
06/19/2024 01:32:27 - INFO - modeling_roberta - Training sub-loss: O 1.1223070621490479, C 1.094268798828125, E 1.1928683519363403, A 1.1116573810577393, N 1.1729204654693604
06/19/2024 01:32:27 - INFO - modeling_roberta - Training sub-loss: O 1.0885858535766602, C 1.1569623947143555, E 1.1234102249145508, A 1.1469781398773193, N 1.0644443035125732
06/19/2024 01:32:29 - INFO - modeling_roberta - Training sub-loss: O 1.0628327131271362, C 1.0611774921417236, E 1.1517962217330933, A 1.1607491970062256, N 1.1151256561279297
06/19/2024 01:32:29 - INFO - modeling_roberta - Training sub-loss: O 1.0877652168273926, C 1.0742400884628296, E 1.094544529914856, A 1.0790534019470215, N 1.136803150177002
06/19/2024 01:32:30 - ERROR - root -   2%|1         | 7/390 [00:25<20:34,  3.22s/it]
06/19/2024 01:32:30 - INFO - modeling_roberta - Training sub-loss: O 1.0683274269104004, C 1.1254167556762695, E 1.065312385559082, A 1.1848253011703491, N 1.1075164079666138
06/19/2024 01:32:30 - INFO - modeling_roberta - Training sub-loss: O 1.149090051651001, C 1.119006633758545, E 1.0838549137115479, A 1.15826416015625, N 1.110958218574524
06/19/2024 01:32:32 - INFO - modeling_roberta - Training sub-loss: O 1.1166507005691528, C 1.1302711963653564, E 1.0331002473831177, A 1.1576696634292603, N 1.142366647720337
06/19/2024 01:32:32 - INFO - modeling_roberta - Training sub-loss: O 1.1056394577026367, C 1.1149394512176514, E 1.1345081329345703, A 1.1022284030914307, N 1.1375224590301514
06/19/2024 01:32:33 - ERROR - root -   2%|2         | 8/390 [00:28<20:14,  3.18s/it]
06/19/2024 01:32:33 - INFO - modeling_roberta - Training sub-loss: O 1.0890278816223145, C 1.071485996246338, E 1.0765559673309326, A 1.0968633890151978, N 1.1847198009490967
06/19/2024 01:32:33 - INFO - modeling_roberta - Training sub-loss: O 1.0753371715545654, C 1.1246283054351807, E 1.094710350036621, A 1.1531347036361694, N 1.1202397346496582
06/19/2024 01:32:35 - INFO - modeling_roberta - Training sub-loss: O 1.1316535472869873, C 1.1094260215759277, E 1.0812691450119019, A 1.0811591148376465, N 1.0468287467956543
06/19/2024 01:32:35 - INFO - modeling_roberta - Training sub-loss: O 1.0577064752578735, C 1.111872673034668, E 1.118573784828186, A 1.1121492385864258, N 1.0868300199508667
06/19/2024 01:32:36 - ERROR - root -   2%|2         | 9/390 [00:31<19:59,  3.15s/it]
06/19/2024 01:32:36 - INFO - modeling_roberta - Training sub-loss: O 1.0978469848632812, C 1.0755444765090942, E 1.348554015159607, A 1.1075347661972046, N 1.2416763305664062
06/19/2024 01:32:36 - INFO - modeling_roberta - Training sub-loss: O 1.210396647453308, C 1.16127347946167, E 1.2894303798675537, A 1.1621923446655273, N 1.1971344947814941
06/19/2024 01:32:38 - INFO - modeling_roberta - Training sub-loss: O 1.121619462966919, C 1.129504680633545, E 1.094462275505066, A 1.120787262916565, N 1.1473994255065918
06/19/2024 01:32:38 - INFO - modeling_roberta - Training sub-loss: O 1.1788454055786133, C 1.1664197444915771, E 1.0926973819732666, A 1.134455680847168, N 1.1175553798675537
06/19/2024 01:32:39 - ERROR - root -   3%|2         | 10/390 [00:34<19:48,  3.13s/it]
06/19/2024 01:32:39 - INFO - root - {'loss': 1.123, 'grad_norm': 524248.65625, 'learning_rate': 9.743589743589744e-05, 'epoch': 0.13}
06/19/2024 01:32:39 - ERROR - root -   3%|2         | 10/390 [00:34<19:48,  3.13s/it]
06/19/2024 01:32:40 - INFO - modeling_roberta - Training sub-loss: O 1.1798127889633179, C 1.029785394668579, E 1.0679337978363037, A 1.1319842338562012, N 0.9907334446907043
06/19/2024 01:32:40 - INFO - modeling_roberta - Training sub-loss: O 1.1710511445999146, C 1.3342204093933105, E 1.2155234813690186, A 1.084122896194458, N 1.1698795557022095
06/19/2024 01:32:41 - INFO - modeling_roberta - Training sub-loss: O 1.1658577919006348, C 1.0313960313796997, E 1.0698261260986328, A 1.2016098499298096, N 1.1691601276397705
06/19/2024 01:32:41 - INFO - modeling_roberta - Training sub-loss: O 1.150693416595459, C 1.158458948135376, E 1.1357461214065552, A 1.1521574258804321, N 1.166418433189392
06/19/2024 01:32:42 - ERROR - root -   3%|2         | 11/390 [00:37<19:42,  3.12s/it]
06/19/2024 01:32:43 - INFO - modeling_roberta - Training sub-loss: O 1.0559278726577759, C 1.1048905849456787, E 1.109771966934204, A 1.042989730834961, N 1.1003742218017578
06/19/2024 01:32:43 - INFO - modeling_roberta - Training sub-loss: O 1.0635137557983398, C 1.0971254110336304, E 1.10213303565979, A 1.113905429840088, N 1.0800977945327759
06/19/2024 01:32:44 - INFO - modeling_roberta - Training sub-loss: O 1.1219249963760376, C 1.0592055320739746, E 1.1339435577392578, A 1.0838911533355713, N 1.113211750984192
06/19/2024 01:32:44 - INFO - modeling_roberta - Training sub-loss: O 1.145021915435791, C 1.0747239589691162, E 1.050851583480835, A 1.096924066543579, N 1.0292015075683594
06/19/2024 01:32:45 - ERROR - root -   3%|3         | 12/390 [00:40<19:48,  3.14s/it]
06/19/2024 01:32:46 - INFO - modeling_roberta - Training sub-loss: O 1.132575511932373, C 1.1137635707855225, E 1.0471060276031494, A 1.0905629396438599, N 1.103076696395874
06/19/2024 01:32:46 - INFO - modeling_roberta - Training sub-loss: O 1.072989821434021, C 1.0668590068817139, E 1.0452429056167603, A 1.0905121564865112, N 1.1084048748016357
06/19/2024 01:32:47 - INFO - modeling_roberta - Training sub-loss: O 1.1599462032318115, C 1.1389381885528564, E 1.1804841756820679, A 1.1444768905639648, N 1.1881672143936157
06/19/2024 01:32:47 - INFO - modeling_roberta - Training sub-loss: O 1.1600674390792847, C 1.0955990552902222, E 1.0809104442596436, A 1.1123836040496826, N 1.0505956411361694
06/19/2024 01:32:48 - ERROR - root -   3%|3         | 13/390 [00:43<19:47,  3.15s/it]
06/19/2024 01:32:49 - INFO - modeling_roberta - Training sub-loss: O 1.1573753356933594, C 1.0776323080062866, E 1.1078290939331055, A 1.0603711605072021, N 1.096480131149292
06/19/2024 01:32:49 - INFO - modeling_roberta - Training sub-loss: O 1.1188217401504517, C 1.1169955730438232, E 1.137701392173767, A 1.1270921230316162, N 1.068371057510376
06/19/2024 01:32:51 - INFO - modeling_roberta - Training sub-loss: O 1.1264299154281616, C 1.0897585153579712, E 1.0465452671051025, A 1.0593492984771729, N 1.0488502979278564
06/19/2024 01:32:51 - INFO - modeling_roberta - Training sub-loss: O 1.084783911705017, C 1.151188611984253, E 1.1853998899459839, A 1.1207913160324097, N 1.153123378753662
06/19/2024 01:32:52 - ERROR - root -   4%|3         | 14/390 [00:47<19:59,  3.19s/it]
06/19/2024 01:32:52 - INFO - modeling_roberta - Training sub-loss: O 1.105114459991455, C 1.138075590133667, E 1.0883336067199707, A 1.098924994468689, N 1.137054443359375
06/19/2024 01:32:52 - INFO - modeling_roberta - Training sub-loss: O 1.125959873199463, C 1.1485991477966309, E 1.122624397277832, A 1.0213209390640259, N 1.1952723264694214
06/19/2024 01:32:54 - INFO - modeling_roberta - Training sub-loss: O 1.0993895530700684, C 1.0708048343658447, E 1.0875188112258911, A 1.140075922012329, N 1.0903513431549072
06/19/2024 01:32:54 - INFO - modeling_roberta - Training sub-loss: O 1.0844273567199707, C 1.1438515186309814, E 1.0309001207351685, A 1.1278588771820068, N 1.169445276260376
06/19/2024 01:32:55 - ERROR - root -   4%|3         | 15/390 [00:50<19:59,  3.20s/it]
06/19/2024 01:32:55 - INFO - modeling_roberta - Training sub-loss: O 1.0899465084075928, C 1.2014278173446655, E 1.0960960388183594, A 1.0973138809204102, N 1.1399948596954346
06/19/2024 01:32:55 - INFO - modeling_roberta - Training sub-loss: O 1.0670273303985596, C 1.1141104698181152, E 1.1445671319961548, A 1.0934669971466064, N 1.0850491523742676
06/19/2024 01:32:57 - INFO - modeling_roberta - Training sub-loss: O 1.1048800945281982, C 1.1366515159606934, E 1.1576282978057861, A 1.0863161087036133, N 1.1360323429107666
06/19/2024 01:32:57 - INFO - modeling_roberta - Training sub-loss: O 1.1332075595855713, C 1.1112291812896729, E 1.1260665655136108, A 1.1233141422271729, N 1.1094975471496582
06/19/2024 01:32:58 - ERROR - root -   4%|4         | 16/390 [00:53<19:47,  3.17s/it]
06/19/2024 01:32:59 - INFO - modeling_roberta - Training sub-loss: O 1.1387301683425903, C 1.138066053390503, E 1.0998966693878174, A 1.1090644598007202, N 1.2197966575622559
06/19/2024 01:32:59 - INFO - modeling_roberta - Training sub-loss: O 1.1482834815979004, C 1.1075177192687988, E 1.0762531757354736, A 1.1142266988754272, N 1.1389211416244507
06/19/2024 01:33:00 - INFO - modeling_roberta - Training sub-loss: O 1.0608222484588623, C 1.0829737186431885, E 1.079455852508545, A 1.1256053447723389, N 1.1848783493041992
06/19/2024 01:33:00 - INFO - modeling_roberta - Training sub-loss: O 1.0581295490264893, C 1.0994665622711182, E 1.153918981552124, A 1.1252332925796509, N 1.0826047658920288
06/19/2024 01:33:01 - ERROR - root -   4%|4         | 17/390 [00:56<19:40,  3.17s/it]
06/19/2024 01:33:02 - INFO - modeling_roberta - Training sub-loss: O 1.1163287162780762, C 1.1284711360931396, E 1.1016958951950073, A 1.0932296514511108, N 1.1116122007369995
06/19/2024 01:33:02 - INFO - modeling_roberta - Training sub-loss: O 1.087990403175354, C 1.0718703269958496, E 1.117877721786499, A 1.0770065784454346, N 1.0976167917251587
06/19/2024 01:33:03 - INFO - modeling_roberta - Training sub-loss: O 1.0919828414916992, C 1.0930644273757935, E 1.1140419244766235, A 1.1336873769760132, N 1.1245388984680176
06/19/2024 01:33:03 - INFO - modeling_roberta - Training sub-loss: O 1.047698974609375, C 1.0740983486175537, E 1.1281390190124512, A 1.0930564403533936, N 1.1479196548461914
06/19/2024 01:33:04 - ERROR - root -   5%|4         | 18/390 [00:59<19:36,  3.16s/it]
06/19/2024 01:33:05 - INFO - modeling_roberta - Training sub-loss: O 1.0933022499084473, C 1.0940961837768555, E 1.1103557348251343, A 1.1384954452514648, N 1.0777643918991089
06/19/2024 01:33:05 - INFO - modeling_roberta - Training sub-loss: O 1.1276605129241943, C 1.1355597972869873, E 1.1186439990997314, A 1.1554887294769287, N 1.1278948783874512
06/19/2024 01:33:06 - INFO - modeling_roberta - Training sub-loss: O 1.1005074977874756, C 1.1121407747268677, E 1.1030508279800415, A 1.1318209171295166, N 1.0992708206176758
06/19/2024 01:33:06 - INFO - modeling_roberta - Training sub-loss: O 1.1038031578063965, C 1.0789717435836792, E 1.1099376678466797, A 1.074333906173706, N 1.111346960067749
06/19/2024 01:33:08 - ERROR - root -   5%|4         | 19/390 [01:03<19:47,  3.20s/it]
06/19/2024 01:33:08 - INFO - modeling_roberta - Training sub-loss: O 1.117925763130188, C 1.0774515867233276, E 1.1152706146240234, A 1.0646159648895264, N 1.0943608283996582
06/19/2024 01:33:08 - INFO - modeling_roberta - Training sub-loss: O 1.1157481670379639, C 1.0950863361358643, E 1.0704280138015747, A 1.0550036430358887, N 1.1093590259552002
06/19/2024 01:33:10 - INFO - modeling_roberta - Training sub-loss: O 1.1059966087341309, C 1.0449669361114502, E 1.065711259841919, A 1.065129280090332, N 1.1175614595413208
06/19/2024 01:33:10 - INFO - modeling_roberta - Training sub-loss: O 1.0735251903533936, C 1.1952707767486572, E 1.0776312351226807, A 1.0846006870269775, N 1.0975584983825684
06/19/2024 01:33:11 - ERROR - root -   5%|5         | 20/390 [01:06<19:36,  3.18s/it]
06/19/2024 01:33:11 - INFO - root - {'loss': 1.1095, 'grad_norm': 66202.078125, 'learning_rate': 9.487179487179487e-05, 'epoch': 0.25}
06/19/2024 01:33:11 - ERROR - root -   5%|5         | 20/390 [01:06<19:36,  3.18s/it]
06/19/2024 01:33:11 - INFO - modeling_roberta - Training sub-loss: O 1.1005775928497314, C 1.0746853351593018, E 1.1272828578948975, A 1.1045275926589966, N 1.1319818496704102
06/19/2024 01:33:11 - INFO - modeling_roberta - Training sub-loss: O 1.1495476961135864, C 1.1238527297973633, E 1.1185622215270996, A 1.1396679878234863, N 1.104666829109192
06/19/2024 01:33:13 - INFO - modeling_roberta - Training sub-loss: O 1.1093106269836426, C 1.1487675905227661, E 1.1693010330200195, A 1.1614943742752075, N 1.1293339729309082
06/19/2024 01:33:13 - INFO - modeling_roberta - Training sub-loss: O 1.0837230682373047, C 1.1467646360397339, E 1.101104736328125, A 1.1013092994689941, N 1.1077144145965576
06/19/2024 01:33:14 - ERROR - root -   5%|5         | 21/390 [01:09<19:39,  3.20s/it]
06/19/2024 01:33:15 - INFO - modeling_roberta - Training sub-loss: O 1.1584835052490234, C 1.125325322151184, E 1.1246250867843628, A 1.1259188652038574, N 1.1302440166473389
06/19/2024 01:33:15 - INFO - modeling_roberta - Training sub-loss: O 1.0219902992248535, C 1.080078363418579, E 1.0735799074172974, A 1.124190330505371, N 1.1078683137893677
06/19/2024 01:33:16 - INFO - modeling_roberta - Training sub-loss: O 1.1847105026245117, C 1.157446265220642, E 1.0937080383300781, A 1.03470778465271, N 1.1429494619369507
06/19/2024 01:33:16 - INFO - modeling_roberta - Training sub-loss: O 1.0875649452209473, C 1.231963038444519, E 1.114710807800293, A 1.0472087860107422, N 1.1063313484191895
06/19/2024 01:33:17 - ERROR - root -   6%|5         | 22/390 [01:12<20:04,  3.27s/it]
06/19/2024 01:33:18 - INFO - modeling_roberta - Training sub-loss: O 1.0852627754211426, C 1.0887138843536377, E 1.099687099456787, A 1.1092487573623657, N 1.079885721206665
06/19/2024 01:33:18 - INFO - modeling_roberta - Training sub-loss: O 1.1390867233276367, C 1.0614210367202759, E 1.0875675678253174, A 1.0801396369934082, N 1.0449295043945312
06/19/2024 01:33:20 - INFO - modeling_roberta - Training sub-loss: O 1.1321521997451782, C 1.106215238571167, E 1.1077840328216553, A 1.1097415685653687, N 1.0873326063156128
06/19/2024 01:33:20 - INFO - modeling_roberta - Training sub-loss: O 1.0434907674789429, C 1.067441701889038, E 1.0864636898040771, A 1.1254349946975708, N 1.0666131973266602
06/19/2024 01:33:21 - ERROR - root -   6%|5         | 23/390 [01:16<19:54,  3.26s/it]
06/19/2024 01:33:21 - INFO - modeling_roberta - Training sub-loss: O 1.1399054527282715, C 1.1257725954055786, E 1.0437581539154053, A 1.0964317321777344, N 1.0819714069366455
06/19/2024 01:33:21 - INFO - modeling_roberta - Training sub-loss: O 1.051556944847107, C 1.060577630996704, E 1.1027591228485107, A 1.151059865951538, N 1.136522889137268
06/19/2024 01:33:23 - INFO - modeling_roberta - Training sub-loss: O 1.1842234134674072, C 1.0951582193374634, E 1.1693223714828491, A 1.1010031700134277, N 1.023209810256958
06/19/2024 01:33:23 - INFO - modeling_roberta - Training sub-loss: O 1.034096598625183, C 1.057743787765503, E 1.1239204406738281, A 1.1316254138946533, N 1.1131670475006104
06/19/2024 01:33:24 - ERROR - root -   6%|6         | 24/390 [01:19<19:40,  3.23s/it]
06/19/2024 01:33:24 - INFO - modeling_roberta - Training sub-loss: O 1.067061424255371, C 1.1146730184555054, E 1.0914459228515625, A 1.1153554916381836, N 1.195659875869751
06/19/2024 01:33:24 - INFO - modeling_roberta - Training sub-loss: O 1.1093738079071045, C 1.1171098947525024, E 1.1298370361328125, A 1.104120135307312, N 1.098197340965271
06/19/2024 01:33:26 - INFO - modeling_roberta - Training sub-loss: O 1.1568952798843384, C 1.0530200004577637, E 1.0484592914581299, A 1.1411670446395874, N 1.120881199836731
06/19/2024 01:33:26 - INFO - modeling_roberta - Training sub-loss: O 1.0787553787231445, C 1.0863522291183472, E 1.1238386631011963, A 1.0414929389953613, N 1.0623762607574463
06/19/2024 01:33:27 - ERROR - root -   6%|6         | 25/390 [01:22<19:29,  3.20s/it]
06/19/2024 01:33:28 - INFO - modeling_roberta - Training sub-loss: O 1.075191617012024, C 1.1005536317825317, E 1.1490182876586914, A 1.1643352508544922, N 1.1819562911987305
06/19/2024 01:33:28 - INFO - modeling_roberta - Training sub-loss: O 1.1146537065505981, C 1.1787954568862915, E 1.1429507732391357, A 1.1419079303741455, N 1.1865653991699219
06/19/2024 01:33:29 - INFO - modeling_roberta - Training sub-loss: O 1.175079345703125, C 1.1732604503631592, E 1.0786170959472656, A 1.116166353225708, N 1.1550471782684326
06/19/2024 01:33:29 - INFO - modeling_roberta - Training sub-loss: O 1.0982463359832764, C 1.0986511707305908, E 1.1322376728057861, A 1.0854896306991577, N 1.1162550449371338
06/19/2024 01:33:30 - ERROR - root -   7%|6         | 26/390 [01:25<19:22,  3.19s/it]
06/19/2024 01:33:31 - INFO - modeling_roberta - Training sub-loss: O 1.0564931631088257, C 1.09934663772583, E 1.115129828453064, A 1.06742262840271, N 1.1570899486541748
06/19/2024 01:33:31 - INFO - modeling_roberta - Training sub-loss: O 1.1658579111099243, C 1.1462900638580322, E 1.0957248210906982, A 1.1675748825073242, N 1.156122088432312
06/19/2024 01:33:32 - INFO - modeling_roberta - Training sub-loss: O 1.095499873161316, C 1.0686752796173096, E 1.0786033868789673, A 1.0669878721237183, N 1.1814013719558716
06/19/2024 01:33:32 - INFO - modeling_roberta - Training sub-loss: O 1.1670002937316895, C 1.0880870819091797, E 1.1340383291244507, A 1.120368242263794, N 1.1379988193511963
06/19/2024 01:33:33 - ERROR - root -   7%|6         | 27/390 [01:28<19:16,  3.19s/it]
06/19/2024 01:33:34 - INFO - modeling_roberta - Training sub-loss: O 1.1116178035736084, C 1.0859627723693848, E 1.055166244506836, A 1.1309943199157715, N 1.1673504114151
06/19/2024 01:33:34 - INFO - modeling_roberta - Training sub-loss: O 1.1579560041427612, C 1.1406629085540771, E 1.050844669342041, A 1.0776076316833496, N 1.1018654108047485
06/19/2024 01:33:35 - INFO - modeling_roberta - Training sub-loss: O 1.0850294828414917, C 1.1165437698364258, E 1.1506038904190063, A 1.1222742795944214, N 1.1821739673614502
06/19/2024 01:33:35 - INFO - modeling_roberta - Training sub-loss: O 1.1796060800552368, C 1.0838690996170044, E 1.1447398662567139, A 1.1498059034347534, N 1.1466144323349
06/19/2024 01:33:36 - ERROR - root -   7%|7         | 28/390 [01:31<19:12,  3.18s/it]
06/19/2024 01:33:37 - INFO - modeling_roberta - Training sub-loss: O 1.1390316486358643, C 1.1084709167480469, E 1.2010160684585571, A 1.1065828800201416, N 1.1203315258026123
06/19/2024 01:33:37 - INFO - modeling_roberta - Training sub-loss: O 1.103693962097168, C 1.101960301399231, E 1.150142788887024, A 1.1179485321044922, N 1.0984923839569092
06/19/2024 01:33:39 - INFO - modeling_roberta - Training sub-loss: O 1.169961929321289, C 1.0920952558517456, E 1.1630699634552002, A 1.1261961460113525, N 1.104144811630249
06/19/2024 01:33:39 - INFO - modeling_roberta - Training sub-loss: O 1.1515358686447144, C 1.1533050537109375, E 1.0320560932159424, A 1.1830991506576538, N 1.1483805179595947
06/19/2024 01:33:40 - ERROR - root -   7%|7         | 29/390 [01:35<19:07,  3.18s/it]
06/19/2024 01:33:40 - INFO - modeling_roberta - Training sub-loss: O 1.1273831129074097, C 1.0849323272705078, E 1.1565090417861938, A 1.102532982826233, N 1.0892232656478882
06/19/2024 01:33:40 - INFO - modeling_roberta - Training sub-loss: O 1.0769582986831665, C 1.1284908056259155, E 1.2788708209991455, A 1.0682880878448486, N 1.0789483785629272
06/19/2024 01:33:42 - INFO - modeling_roberta - Training sub-loss: O 1.1164661645889282, C 1.1040735244750977, E 1.0473854541778564, A 1.114906668663025, N 1.1555397510528564
06/19/2024 01:33:42 - INFO - modeling_roberta - Training sub-loss: O 1.0918564796447754, C 1.1344245672225952, E 1.0530986785888672, A 1.119044542312622, N 1.1105537414550781
06/19/2024 01:33:43 - ERROR - root -   8%|7         | 30/390 [01:38<19:03,  3.18s/it]
06/19/2024 01:33:43 - INFO - root - {'loss': 1.1144, 'grad_norm': 62739.0, 'learning_rate': 9.230769230769232e-05, 'epoch': 0.38}
06/19/2024 01:33:43 - ERROR - root -   8%|7         | 30/390 [01:38<19:03,  3.18s/it]
06/19/2024 01:33:43 - INFO - modeling_roberta - Training sub-loss: O 1.1172173023223877, C 1.061954140663147, E 1.225019931793213, A 1.0789225101470947, N 1.1014207601547241
06/19/2024 01:33:43 - INFO - modeling_roberta - Training sub-loss: O 1.0949419736862183, C 1.081092119216919, E 0.9999076128005981, A 1.0212602615356445, N 1.094963788986206
06/19/2024 01:33:45 - INFO - modeling_roberta - Training sub-loss: O 1.1070530414581299, C 1.1558281183242798, E 1.1365256309509277, A 1.06394362449646, N 1.117777943611145
06/19/2024 01:33:45 - INFO - modeling_roberta - Training sub-loss: O 1.120808720588684, C 1.0797606706619263, E 1.0890344381332397, A 1.099927544593811, N 1.0550340414047241
06/19/2024 01:33:46 - ERROR - root -   8%|7         | 31/390 [01:41<19:03,  3.19s/it]
06/19/2024 01:33:47 - INFO - modeling_roberta - Training sub-loss: O 1.074303150177002, C 1.1327626705169678, E 1.16483473777771, A 1.0619328022003174, N 1.1746456623077393
06/19/2024 01:33:47 - INFO - modeling_roberta - Training sub-loss: O 1.0790562629699707, C 1.0609544515609741, E 1.1806797981262207, A 1.1438045501708984, N 1.0832126140594482
06/19/2024 01:33:48 - INFO - modeling_roberta - Training sub-loss: O 1.0771081447601318, C 1.1725835800170898, E 1.2335820198059082, A 1.1051287651062012, N 1.0852632522583008
06/19/2024 01:33:48 - INFO - modeling_roberta - Training sub-loss: O 1.1221271753311157, C 1.0936663150787354, E 1.2199125289916992, A 1.1493500471115112, N 1.1742775440216064
06/19/2024 01:33:49 - ERROR - root -   8%|8         | 32/390 [01:44<18:58,  3.18s/it]
06/19/2024 01:33:50 - INFO - modeling_roberta - Training sub-loss: O 0.9988570213317871, C 1.0117290019989014, E 1.0529217720031738, A 1.1816246509552002, N 0.9751321077346802
06/19/2024 01:33:50 - INFO - modeling_roberta - Training sub-loss: O 1.0349235534667969, C 1.1807773113250732, E 1.1929936408996582, A 1.2342627048492432, N 1.0878679752349854
06/19/2024 01:33:51 - INFO - modeling_roberta - Training sub-loss: O 1.1181471347808838, C 1.1400868892669678, E 1.1740063428878784, A 1.1190924644470215, N 1.1490583419799805
06/19/2024 01:33:51 - INFO - modeling_roberta - Training sub-loss: O 1.0732964277267456, C 1.1052708625793457, E 1.1004722118377686, A 1.1086220741271973, N 1.0927953720092773
06/19/2024 01:33:52 - ERROR - root -   8%|8         | 33/390 [01:47<18:54,  3.18s/it]
06/19/2024 01:33:53 - INFO - modeling_roberta - Training sub-loss: O 1.1830742359161377, C 1.0655491352081299, E 1.0994997024536133, A 1.1081340312957764, N 1.1257717609405518
06/19/2024 01:33:53 - INFO - modeling_roberta - Training sub-loss: O 1.2463371753692627, C 1.1333513259887695, E 1.1118848323822021, A 1.0597792863845825, N 1.0817639827728271
06/19/2024 01:33:54 - INFO - modeling_roberta - Training sub-loss: O 1.1527605056762695, C 1.0588035583496094, E 1.0942217111587524, A 1.1072897911071777, N 1.1289808750152588
06/19/2024 01:33:54 - INFO - modeling_roberta - Training sub-loss: O 1.1494101285934448, C 1.0635453462600708, E 1.0757687091827393, A 1.0767000913619995, N 1.074039340019226
06/19/2024 01:33:55 - ERROR - root -   9%|8         | 34/390 [01:50<18:52,  3.18s/it]
06/19/2024 01:33:56 - INFO - modeling_roberta - Training sub-loss: O 1.1503556966781616, C 1.1075987815856934, E 1.0704975128173828, A 1.1314520835876465, N 1.0720305442810059
06/19/2024 01:33:56 - INFO - modeling_roberta - Training sub-loss: O 0.9921062588691711, C 1.0746936798095703, E 1.0784351825714111, A 1.02191162109375, N 1.052071452140808
06/19/2024 01:33:58 - INFO - modeling_roberta - Training sub-loss: O 1.1344865560531616, C 1.058937430381775, E 1.102986454963684, A 1.0541132688522339, N 1.1249957084655762
06/19/2024 01:33:58 - INFO - modeling_roberta - Training sub-loss: O 1.1242091655731201, C 1.0822211503982544, E 1.0993967056274414, A 1.1199610233306885, N 1.1183475255966187
06/19/2024 01:33:59 - ERROR - root -   9%|8         | 35/390 [01:54<18:47,  3.18s/it]
06/19/2024 01:33:59 - INFO - modeling_roberta - Training sub-loss: O 1.1095850467681885, C 1.1302270889282227, E 1.1455000638961792, A 1.1222797632217407, N 1.1710712909698486
06/19/2024 01:33:59 - INFO - modeling_roberta - Training sub-loss: O 1.093048095703125, C 1.1071560382843018, E 1.1240395307540894, A 1.1145851612091064, N 1.199623703956604
06/19/2024 01:34:01 - INFO - modeling_roberta - Training sub-loss: O 1.1195921897888184, C 1.057103157043457, E 1.0728925466537476, A 1.1723511219024658, N 1.1083242893218994
06/19/2024 01:34:01 - INFO - modeling_roberta - Training sub-loss: O 1.0758346319198608, C 1.110103964805603, E 1.1049822568893433, A 1.0509734153747559, N 1.2742369174957275
06/19/2024 01:34:02 - ERROR - root -   9%|9         | 36/390 [01:57<18:50,  3.19s/it]
06/19/2024 01:34:03 - INFO - modeling_roberta - Training sub-loss: O 1.052208423614502, C 1.100170612335205, E 1.1113417148590088, A 1.1574726104736328, N 1.0730104446411133
06/19/2024 01:34:03 - INFO - modeling_roberta - Training sub-loss: O 1.1644854545593262, C 1.169183611869812, E 1.091652750968933, A 1.1490813493728638, N 1.1921939849853516
06/19/2024 01:34:04 - INFO - modeling_roberta - Training sub-loss: O 1.0675256252288818, C 1.1058473587036133, E 1.134131669998169, A 1.110675573348999, N 1.0962514877319336
06/19/2024 01:34:04 - INFO - modeling_roberta - Training sub-loss: O 1.1153850555419922, C 1.0659745931625366, E 1.0651229619979858, A 1.1457265615463257, N 1.0818650722503662
06/19/2024 01:34:05 - ERROR - root -   9%|9         | 37/390 [02:00<18:50,  3.20s/it]
06/19/2024 01:34:06 - INFO - modeling_roberta - Training sub-loss: O 1.0627946853637695, C 1.0592608451843262, E 1.1117336750030518, A 1.1204633712768555, N 1.015521764755249
06/19/2024 01:34:06 - INFO - modeling_roberta - Training sub-loss: O 1.0881227254867554, C 1.1607112884521484, E 1.1037408113479614, A 1.1257390975952148, N 1.1498258113861084
06/19/2024 01:34:07 - INFO - modeling_roberta - Training sub-loss: O 1.1554838418960571, C 1.1562141180038452, E 1.1244101524353027, A 1.1629738807678223, N 1.0877048969268799
06/19/2024 01:34:07 - INFO - modeling_roberta - Training sub-loss: O 1.0521221160888672, C 1.095759391784668, E 1.1489651203155518, A 1.141472339630127, N 1.1275615692138672
06/19/2024 01:34:08 - ERROR - root -  10%|9         | 38/390 [02:03<18:49,  3.21s/it]
06/19/2024 01:34:09 - INFO - modeling_roberta - Training sub-loss: O 1.0459578037261963, C 1.0456781387329102, E 1.0295288562774658, A 1.095868468284607, N 1.155147910118103
06/19/2024 01:34:09 - INFO - modeling_roberta - Training sub-loss: O 1.0931637287139893, C 1.077316403388977, E 1.1852649450302124, A 1.0725760459899902, N 1.1540898084640503
06/19/2024 01:34:11 - INFO - modeling_roberta - Training sub-loss: O 1.0874288082122803, C 1.1444776058197021, E 1.076389193534851, A 1.1205124855041504, N 1.0739818811416626
06/19/2024 01:34:11 - INFO - modeling_roberta - Training sub-loss: O 1.1328680515289307, C 1.1512320041656494, E 1.1428476572036743, A 1.1192786693572998, N 1.0888776779174805
06/19/2024 01:34:11 - ERROR - root -  10%|#         | 39/390 [02:07<18:45,  3.21s/it]
06/19/2024 01:34:12 - INFO - modeling_roberta - Training sub-loss: O 1.131864070892334, C 1.1663588285446167, E 1.1113786697387695, A 1.1428101062774658, N 1.0828495025634766
06/19/2024 01:34:12 - INFO - modeling_roberta - Training sub-loss: O 1.105988621711731, C 1.0952305793762207, E 1.084742546081543, A 1.078660249710083, N 1.1289982795715332
06/19/2024 01:34:14 - INFO - modeling_roberta - Training sub-loss: O 1.1382893323898315, C 1.0689700841903687, E 1.07023286819458, A 1.1488879919052124, N 1.0903990268707275
06/19/2024 01:34:14 - INFO - modeling_roberta - Training sub-loss: O 1.1446123123168945, C 1.112665057182312, E 1.0887422561645508, A 1.153015375137329, N 1.1056610345840454
06/19/2024 01:34:15 - ERROR - root -  10%|#         | 40/390 [02:10<18:39,  3.20s/it]
06/19/2024 01:34:15 - INFO - root - {'loss': 1.1095, 'grad_norm': 100407.5859375, 'learning_rate': 8.974358974358975e-05, 'epoch': 0.51}
06/19/2024 01:34:15 - ERROR - root -  10%|#         | 40/390 [02:10<18:39,  3.20s/it]
06/19/2024 01:34:15 - INFO - modeling_roberta - Training sub-loss: O 1.1094014644622803, C 1.1060855388641357, E 1.0952868461608887, A 1.1004343032836914, N 1.1371283531188965
06/19/2024 01:34:15 - INFO - modeling_roberta - Training sub-loss: O 1.1069809198379517, C 1.1178913116455078, E 1.0694987773895264, A 1.0758702754974365, N 1.1138375997543335
06/19/2024 01:34:17 - INFO - modeling_roberta - Training sub-loss: O 1.1215009689331055, C 1.1356942653656006, E 1.1256964206695557, A 1.145466923713684, N 1.1079062223434448
06/19/2024 01:34:17 - INFO - modeling_roberta - Training sub-loss: O 1.1217952966690063, C 1.1049013137817383, E 1.119805097579956, A 1.1147083044052124, N 1.0900813341140747
06/19/2024 01:34:18 - ERROR - root -  11%|#         | 41/390 [02:13<18:36,  3.20s/it]
06/19/2024 01:34:19 - INFO - modeling_roberta - Training sub-loss: O 1.1189017295837402, C 1.1112174987792969, E 1.0827901363372803, A 1.1700621843338013, N 1.0970386266708374
06/19/2024 01:34:19 - INFO - modeling_roberta - Training sub-loss: O 1.1209156513214111, C 1.060745358467102, E 1.1607744693756104, A 1.2412009239196777, N 1.1096429824829102
06/19/2024 01:34:20 - INFO - modeling_roberta - Training sub-loss: O 1.093689203262329, C 1.0744576454162598, E 1.1392765045166016, A 1.0720853805541992, N 1.1031920909881592
06/19/2024 01:34:20 - INFO - modeling_roberta - Training sub-loss: O 1.1769561767578125, C 1.0899088382720947, E 1.116529941558838, A 1.118023157119751, N 1.1045619249343872
06/19/2024 01:34:21 - ERROR - root -  11%|#         | 42/390 [02:16<18:31,  3.20s/it]
06/19/2024 01:34:22 - INFO - modeling_roberta - Training sub-loss: O 1.0847417116165161, C 1.1419060230255127, E 1.0861375331878662, A 1.1539585590362549, N 1.0915250778198242
06/19/2024 01:34:22 - INFO - modeling_roberta - Training sub-loss: O 1.11810302734375, C 1.0823016166687012, E 1.0899602174758911, A 1.0565685033798218, N 1.1149101257324219
06/19/2024 01:34:23 - INFO - modeling_roberta - Training sub-loss: O 1.1454859972000122, C 1.1714445352554321, E 1.1156961917877197, A 1.0681873559951782, N 1.1382012367248535
06/19/2024 01:34:23 - INFO - modeling_roberta - Training sub-loss: O 1.0465370416641235, C 1.1327298879623413, E 1.0772687196731567, A 1.143742561340332, N 1.1132993698120117
06/19/2024 01:34:24 - ERROR - root -  11%|#1        | 43/390 [02:19<18:37,  3.22s/it]
06/19/2024 01:34:25 - INFO - modeling_roberta - Training sub-loss: O 1.1400458812713623, C 1.1282165050506592, E 1.1075488328933716, A 1.0800094604492188, N 1.0912199020385742
06/19/2024 01:34:25 - INFO - modeling_roberta - Training sub-loss: O 1.0922082662582397, C 1.1041278839111328, E 1.1154687404632568, A 1.0773515701293945, N 1.1211038827896118
06/19/2024 01:34:27 - INFO - modeling_roberta - Training sub-loss: O 1.1675503253936768, C 1.0920615196228027, E 1.1370981931686401, A 1.0712705850601196, N 1.1028170585632324
06/19/2024 01:34:27 - INFO - modeling_roberta - Training sub-loss: O 1.1235558986663818, C 1.1063385009765625, E 1.12233304977417, A 1.1598668098449707, N 1.0857126712799072
06/19/2024 01:34:28 - ERROR - root -  11%|#1        | 44/390 [02:23<18:30,  3.21s/it]
06/19/2024 01:34:28 - INFO - modeling_roberta - Training sub-loss: O 1.2306314706802368, C 1.1881577968597412, E 1.126431941986084, A 1.1726585626602173, N 1.2097734212875366
06/19/2024 01:34:28 - INFO - modeling_roberta - Training sub-loss: O 1.1327342987060547, C 1.0743865966796875, E 1.1094411611557007, A 1.0934336185455322, N 1.2127454280853271
06/19/2024 01:34:30 - INFO - modeling_roberta - Training sub-loss: O 1.0961143970489502, C 1.0547001361846924, E 1.0883357524871826, A 1.1731139421463013, N 1.1199183464050293
06/19/2024 01:34:30 - INFO - modeling_roberta - Training sub-loss: O 1.1693685054779053, C 1.1137043237686157, E 1.1167722940444946, A 1.14955472946167, N 1.180975079536438
06/19/2024 01:34:31 - ERROR - root -  12%|#1        | 45/390 [02:26<18:30,  3.22s/it]
06/19/2024 01:34:31 - INFO - modeling_roberta - Training sub-loss: O 1.0838758945465088, C 1.1023794412612915, E 1.1176159381866455, A 1.137078046798706, N 1.1839016675949097
06/19/2024 01:34:31 - INFO - modeling_roberta - Training sub-loss: O 1.0650205612182617, C 1.1234636306762695, E 1.0910096168518066, A 1.1172192096710205, N 1.0852009057998657
06/19/2024 01:34:33 - INFO - modeling_roberta - Training sub-loss: O 1.0466668605804443, C 1.086228609085083, E 1.064262866973877, A 1.074277639389038, N 1.08890700340271
06/19/2024 01:34:33 - INFO - modeling_roberta - Training sub-loss: O 1.167224645614624, C 1.172823429107666, E 1.1397627592086792, A 1.1715147495269775, N 1.2132554054260254
06/19/2024 01:34:34 - ERROR - root -  12%|#1        | 46/390 [02:29<18:24,  3.21s/it]
06/19/2024 01:34:35 - INFO - modeling_roberta - Training sub-loss: O 1.1508190631866455, C 1.0835882425308228, E 1.0898289680480957, A 1.0903903245925903, N 1.1483957767486572
06/19/2024 01:34:35 - INFO - modeling_roberta - Training sub-loss: O 1.134138822555542, C 1.1757919788360596, E 1.0813541412353516, A 1.0612611770629883, N 1.1356831789016724
06/19/2024 01:34:36 - INFO - modeling_roberta - Training sub-loss: O 1.0548279285430908, C 1.071628451347351, E 1.1344410181045532, A 1.136247158050537, N 1.0746114253997803
06/19/2024 01:34:36 - INFO - modeling_roberta - Training sub-loss: O 1.0810980796813965, C 1.1308916807174683, E 1.1081593036651611, A 1.0654466152191162, N 1.143074631690979
06/19/2024 01:34:37 - ERROR - root -  12%|#2        | 47/390 [02:32<18:19,  3.20s/it]
06/19/2024 01:34:38 - INFO - modeling_roberta - Training sub-loss: O 1.1632966995239258, C 1.1010046005249023, E 1.0717198848724365, A 1.1291807889938354, N 1.115466594696045
06/19/2024 01:34:38 - INFO - modeling_roberta - Training sub-loss: O 1.1004488468170166, C 1.0972572565078735, E 1.0789793729782104, A 1.1481289863586426, N 1.1169368028640747
06/19/2024 01:34:39 - INFO - modeling_roberta - Training sub-loss: O 1.0745357275009155, C 1.098741888999939, E 1.081803560256958, A 1.0891175270080566, N 1.0512174367904663
06/19/2024 01:34:39 - INFO - modeling_roberta - Training sub-loss: O 1.0697087049484253, C 1.1160016059875488, E 1.1155383586883545, A 1.0751583576202393, N 1.0860004425048828
06/19/2024 01:34:40 - ERROR - root -  12%|#2        | 48/390 [02:35<18:17,  3.21s/it]
06/19/2024 01:34:41 - INFO - modeling_roberta - Training sub-loss: O 1.08991277217865, C 1.1290454864501953, E 1.134657859802246, A 1.1494485139846802, N 1.1342837810516357
06/19/2024 01:34:41 - INFO - modeling_roberta - Training sub-loss: O 1.1011615991592407, C 1.1005877256393433, E 1.0836613178253174, A 1.0527105331420898, N 1.1468818187713623
06/19/2024 01:34:43 - INFO - modeling_roberta - Training sub-loss: O 1.0791873931884766, C 1.0943578481674194, E 1.058363437652588, A 1.176499843597412, N 1.1290762424468994
06/19/2024 01:34:43 - INFO - modeling_roberta - Training sub-loss: O 1.1448478698730469, C 1.1804194450378418, E 1.1407724618911743, A 1.0836321115493774, N 1.1482182741165161
06/19/2024 01:34:44 - ERROR - root -  13%|#2        | 49/390 [02:39<18:12,  3.20s/it]
06/19/2024 01:34:44 - INFO - modeling_roberta - Training sub-loss: O 1.1065491437911987, C 1.118658185005188, E 1.162214756011963, A 1.0551598072052002, N 1.0457432270050049
06/19/2024 01:34:44 - INFO - modeling_roberta - Training sub-loss: O 1.0772485733032227, C 1.0857617855072021, E 1.053694725036621, A 1.1233563423156738, N 1.0655978918075562
06/19/2024 01:34:46 - INFO - modeling_roberta - Training sub-loss: O 1.1018917560577393, C 1.0902067422866821, E 1.1181329488754272, A 1.1234385967254639, N 1.062027096748352
06/19/2024 01:34:46 - INFO - modeling_roberta - Training sub-loss: O 1.041571021080017, C 1.1271600723266602, E 1.0904666185379028, A 1.1462008953094482, N 1.121246576309204
06/19/2024 01:34:47 - ERROR - root -  13%|#2        | 50/390 [02:42<18:06,  3.20s/it]
06/19/2024 01:34:47 - INFO - root - {'loss': 1.1127, 'grad_norm': 76384.9765625, 'learning_rate': 8.717948717948718e-05, 'epoch': 0.64}
06/19/2024 01:34:47 - ERROR - root -  13%|#2        | 50/390 [02:42<18:06,  3.20s/it]
06/19/2024 01:34:47 - INFO - modeling_roberta - Training sub-loss: O 1.1079809665679932, C 1.049267053604126, E 1.0844357013702393, A 1.131088376045227, N 1.095474123954773
06/19/2024 01:34:47 - INFO - modeling_roberta - Training sub-loss: O 1.1513333320617676, C 1.1091883182525635, E 1.142394781112671, A 1.1571556329727173, N 1.107276201248169
06/19/2024 01:34:49 - INFO - modeling_roberta - Training sub-loss: O 1.130810260772705, C 1.131697654724121, E 1.0545010566711426, A 1.1137101650238037, N 1.0815162658691406
06/19/2024 01:34:49 - INFO - modeling_roberta - Training sub-loss: O 1.0410354137420654, C 1.110137701034546, E 1.0927205085754395, A 1.1288249492645264, N 1.101474404335022
06/19/2024 01:34:50 - ERROR - root -  13%|#3        | 51/390 [02:45<18:05,  3.20s/it]
06/19/2024 01:34:51 - INFO - modeling_roberta - Training sub-loss: O 1.0827568769454956, C 1.0629651546478271, E 1.088395118713379, A 1.0699061155319214, N 1.0992614030838013
06/19/2024 01:34:51 - INFO - modeling_roberta - Training sub-loss: O 1.108180046081543, C 1.1326651573181152, E 1.1205095052719116, A 1.0858339071273804, N 1.0930031538009644
06/19/2024 01:34:52 - INFO - modeling_roberta - Training sub-loss: O 1.0830204486846924, C 1.1166906356811523, E 1.0904371738433838, A 1.1071076393127441, N 1.0756802558898926
06/19/2024 01:34:52 - INFO - modeling_roberta - Training sub-loss: O 1.1585657596588135, C 1.1062307357788086, E 1.1089017391204834, A 1.0823373794555664, N 1.1477389335632324
06/19/2024 01:34:53 - ERROR - root -  13%|#3        | 52/390 [02:48<18:05,  3.21s/it]
06/19/2024 01:34:54 - INFO - modeling_roberta - Training sub-loss: O 1.1007219552993774, C 1.0809582471847534, E 1.1331799030303955, A 1.1014480590820312, N 1.050492763519287
06/19/2024 01:34:54 - INFO - modeling_roberta - Training sub-loss: O 1.110064148902893, C 1.0795385837554932, E 1.0701794624328613, A 1.1496555805206299, N 1.1519159078598022
06/19/2024 01:34:55 - INFO - modeling_roberta - Training sub-loss: O 1.0773508548736572, C 1.0807945728302002, E 1.1081318855285645, A 1.0812808275222778, N 1.1607627868652344
06/19/2024 01:34:55 - INFO - modeling_roberta - Training sub-loss: O 1.1155906915664673, C 1.11785888671875, E 1.0719856023788452, A 1.125612497329712, N 1.0714367628097534
06/19/2024 01:34:56 - ERROR - root -  14%|#3        | 53/390 [02:51<18:07,  3.23s/it]
06/19/2024 01:34:57 - INFO - modeling_roberta - Training sub-loss: O 1.1649850606918335, C 1.1277132034301758, E 1.1187976598739624, A 1.0915359258651733, N 1.1854439973831177
06/19/2024 01:34:57 - INFO - modeling_roberta - Training sub-loss: O 1.1546083688735962, C 1.077925682067871, E 1.159285068511963, A 1.062337040901184, N 1.151618480682373
06/19/2024 01:34:59 - INFO - modeling_roberta - Training sub-loss: O 1.1303582191467285, C 1.1234989166259766, E 1.0977647304534912, A 1.0711346864700317, N 1.0451505184173584
06/19/2024 01:34:59 - INFO - modeling_roberta - Training sub-loss: O 1.1335740089416504, C 1.1364331245422363, E 1.1715835332870483, A 1.1386191844940186, N 1.2143185138702393
06/19/2024 01:35:00 - ERROR - root -  14%|#3        | 54/390 [02:55<18:13,  3.25s/it]
06/19/2024 01:35:00 - INFO - modeling_roberta - Training sub-loss: O 1.0764544010162354, C 1.1649808883666992, E 1.1321020126342773, A 1.1210979223251343, N 1.2339832782745361
06/19/2024 01:35:00 - INFO - modeling_roberta - Training sub-loss: O 1.098053216934204, C 1.183410882949829, E 1.0797704458236694, A 1.1242984533309937, N 1.0372555255889893
06/19/2024 01:35:02 - INFO - modeling_roberta - Training sub-loss: O 1.1134846210479736, C 1.1355582475662231, E 1.0602974891662598, A 1.115298867225647, N 1.0933313369750977
06/19/2024 01:35:02 - INFO - modeling_roberta - Training sub-loss: O 1.097156047821045, C 1.1549725532531738, E 1.1183222532272339, A 1.0979188680648804, N 1.160763144493103
06/19/2024 01:35:03 - ERROR - root -  14%|#4        | 55/390 [02:58<18:18,  3.28s/it]
06/19/2024 01:35:04 - INFO - modeling_roberta - Training sub-loss: O 1.0882081985473633, C 1.0595703125, E 1.0854668617248535, A 1.0655739307403564, N 1.2216010093688965
06/19/2024 01:35:04 - INFO - modeling_roberta - Training sub-loss: O 1.115823745727539, C 1.1336963176727295, E 1.10053551197052, A 1.0755846500396729, N 1.2111058235168457
06/19/2024 01:35:05 - INFO - modeling_roberta - Training sub-loss: O 1.2317665815353394, C 1.1505305767059326, E 1.1374282836914062, A 1.2148377895355225, N 1.0894594192504883
06/19/2024 01:35:05 - INFO - modeling_roberta - Training sub-loss: O 1.0297222137451172, C 1.1905288696289062, E 1.1908223628997803, A 1.0426785945892334, N 1.1339694261550903
06/19/2024 01:35:07 - ERROR - root -  14%|#4        | 56/390 [03:02<18:32,  3.33s/it]
06/19/2024 01:35:07 - INFO - modeling_roberta - Training sub-loss: O 1.0762193202972412, C 1.1233010292053223, E 1.1393264532089233, A 1.1214901208877563, N 1.118369221687317
06/19/2024 01:35:07 - INFO - modeling_roberta - Training sub-loss: O 1.2255934476852417, C 1.171111822128296, E 1.0272324085235596, A 1.1381127834320068, N 1.1070454120635986
06/19/2024 01:35:09 - INFO - modeling_roberta - Training sub-loss: O 1.1343202590942383, C 1.1081355810165405, E 1.1000829935073853, A 1.1133954524993896, N 1.1971269845962524
06/19/2024 01:35:09 - INFO - modeling_roberta - Training sub-loss: O 1.137162208557129, C 1.0514521598815918, E 1.144538402557373, A 1.1081702709197998, N 1.073575496673584
06/19/2024 01:35:10 - ERROR - root -  15%|#4        | 57/390 [03:05<18:35,  3.35s/it]
06/19/2024 01:35:11 - INFO - modeling_roberta - Training sub-loss: O 1.1180731058120728, C 1.1357917785644531, E 1.1579926013946533, A 1.1421599388122559, N 1.2094039916992188
06/19/2024 01:35:11 - INFO - modeling_roberta - Training sub-loss: O 1.1565666198730469, C 1.1098623275756836, E 1.0634088516235352, A 1.0696334838867188, N 1.0211834907531738
06/19/2024 01:35:12 - INFO - modeling_roberta - Training sub-loss: O 1.0499173402786255, C 1.168623924255371, E 1.058933973312378, A 1.1395419836044312, N 1.1681032180786133
06/19/2024 01:35:12 - INFO - modeling_roberta - Training sub-loss: O 1.0584051609039307, C 1.129748821258545, E 1.0880248546600342, A 1.0897983312606812, N 1.1590087413787842
06/19/2024 01:35:13 - ERROR - root -  15%|#4        | 58/390 [03:08<18:31,  3.35s/it]
06/19/2024 01:35:14 - INFO - modeling_roberta - Training sub-loss: O 1.0862782001495361, C 1.0937347412109375, E 1.1016647815704346, A 1.1472759246826172, N 1.1264365911483765
06/19/2024 01:35:14 - INFO - modeling_roberta - Training sub-loss: O 1.1259888410568237, C 1.1025519371032715, E 1.1392529010772705, A 1.1254323720932007, N 1.1395633220672607
06/19/2024 01:35:16 - INFO - modeling_roberta - Training sub-loss: O 1.0896689891815186, C 1.1144764423370361, E 1.104133129119873, A 1.072557806968689, N 1.109518051147461
06/19/2024 01:35:16 - INFO - modeling_roberta - Training sub-loss: O 1.0724462270736694, C 1.0836753845214844, E 1.1015712022781372, A 1.1103732585906982, N 1.0902822017669678
06/19/2024 01:35:17 - ERROR - root -  15%|#5        | 59/390 [03:12<18:24,  3.34s/it]
06/19/2024 01:35:17 - INFO - modeling_roberta - Training sub-loss: O 1.0875906944274902, C 1.139447569847107, E 1.025650143623352, A 1.0935161113739014, N 1.0954276323318481
06/19/2024 01:35:17 - INFO - modeling_roberta - Training sub-loss: O 1.1016501188278198, C 1.1514979600906372, E 1.1585345268249512, A 1.096237301826477, N 1.0653868913650513
06/19/2024 01:35:19 - INFO - modeling_roberta - Training sub-loss: O 1.1098101139068604, C 1.055562973022461, E 1.1615691184997559, A 1.0798895359039307, N 1.069972276687622
06/19/2024 01:35:19 - INFO - modeling_roberta - Training sub-loss: O 1.1090381145477295, C 1.0577266216278076, E 1.0952963829040527, A 1.0843980312347412, N 1.1196448802947998
06/19/2024 01:35:20 - ERROR - root -  15%|#5        | 60/390 [03:15<18:21,  3.34s/it]
06/19/2024 01:35:20 - INFO - root - {'loss': 1.1125, 'grad_norm': 68821.203125, 'learning_rate': 8.461538461538461e-05, 'epoch': 0.76}
06/19/2024 01:35:20 - ERROR - root -  15%|#5        | 60/390 [03:15<18:21,  3.34s/it]
06/19/2024 01:35:21 - INFO - modeling_roberta - Training sub-loss: O 1.1131541728973389, C 1.1406006813049316, E 1.155465006828308, A 1.06575608253479, N 1.1422604322433472
06/19/2024 01:35:21 - INFO - modeling_roberta - Training sub-loss: O 1.088987112045288, C 1.0864136219024658, E 1.2272268533706665, A 1.1460459232330322, N 1.0819004774093628
06/19/2024 01:35:22 - INFO - modeling_roberta - Training sub-loss: O 1.1149020195007324, C 1.1286275386810303, E 1.0884183645248413, A 1.1091523170471191, N 1.1196115016937256
06/19/2024 01:35:22 - INFO - modeling_roberta - Training sub-loss: O 1.1378674507141113, C 1.1068189144134521, E 1.1757149696350098, A 1.0674426555633545, N 1.101001501083374
06/19/2024 01:35:23 - ERROR - root -  16%|#5        | 61/390 [03:18<18:17,  3.34s/it]
06/19/2024 01:35:24 - INFO - modeling_roberta - Training sub-loss: O 1.0588891506195068, C 1.1485936641693115, E 1.1782052516937256, A 1.1237266063690186, N 1.145016074180603
06/19/2024 01:35:24 - INFO - modeling_roberta - Training sub-loss: O 1.1168153285980225, C 1.0874900817871094, E 1.224152684211731, A 1.0741430521011353, N 1.127629041671753
06/19/2024 01:35:26 - INFO - modeling_roberta - Training sub-loss: O 1.0774173736572266, C 1.078613042831421, E 1.0929430723190308, A 1.1191797256469727, N 1.092666745185852
06/19/2024 01:35:26 - INFO - modeling_roberta - Training sub-loss: O 1.0794529914855957, C 1.1078345775604248, E 1.085587739944458, A 1.1165320873260498, N 1.1078898906707764
06/19/2024 01:35:27 - ERROR - root -  16%|#5        | 62/390 [03:22<18:27,  3.38s/it]
06/19/2024 01:35:27 - INFO - modeling_roberta - Training sub-loss: O 1.0767672061920166, C 1.0510692596435547, E 1.111295223236084, A 1.0865949392318726, N 1.0774675607681274
06/19/2024 01:35:27 - INFO - modeling_roberta - Training sub-loss: O 1.160796880722046, C 1.1129543781280518, E 1.1403319835662842, A 1.093635082244873, N 1.1053320169448853
06/19/2024 01:35:29 - INFO - modeling_roberta - Training sub-loss: O 1.081960916519165, C 1.0914549827575684, E 1.1935756206512451, A 1.0730392932891846, N 1.0826820135116577
06/19/2024 01:35:29 - INFO - modeling_roberta - Training sub-loss: O 1.052330493927002, C 1.1371066570281982, E 1.0335921049118042, A 1.1332406997680664, N 1.0991742610931396
06/19/2024 01:35:30 - ERROR - root -  16%|#6        | 63/390 [03:25<18:23,  3.37s/it]
06/19/2024 01:35:31 - INFO - modeling_roberta - Training sub-loss: O 1.143844485282898, C 1.061048984527588, E 1.1730635166168213, A 1.0498958826065063, N 1.122322678565979
06/19/2024 01:35:31 - INFO - modeling_roberta - Training sub-loss: O 1.1239330768585205, C 1.0852298736572266, E 1.1835212707519531, A 1.1881014108657837, N 1.0828825235366821
06/19/2024 01:35:32 - INFO - modeling_roberta - Training sub-loss: O 1.1203687191009521, C 1.1935241222381592, E 1.1292037963867188, A 1.0440393686294556, N 1.156699538230896
06/19/2024 01:35:32 - INFO - modeling_roberta - Training sub-loss: O 1.081282615661621, C 1.1230573654174805, E 1.0991270542144775, A 1.1344505548477173, N 1.0605860948562622
06/19/2024 01:35:33 - ERROR - root -  16%|#6        | 64/390 [03:28<18:15,  3.36s/it]
06/19/2024 01:35:34 - INFO - modeling_roberta - Training sub-loss: O 1.0879924297332764, C 1.1408202648162842, E 1.1634951829910278, A 1.0904247760772705, N 1.1090466976165771
06/19/2024 01:35:34 - INFO - modeling_roberta - Training sub-loss: O 1.0704715251922607, C 1.0986733436584473, E 1.1369552612304688, A 1.1286365985870361, N 1.1050652265548706
06/19/2024 01:35:36 - INFO - modeling_roberta - Training sub-loss: O 1.0805261135101318, C 1.074489951133728, E 1.0491738319396973, A 1.1312944889068604, N 1.2017003297805786
06/19/2024 01:35:36 - INFO - modeling_roberta - Training sub-loss: O 1.0533843040466309, C 1.107276439666748, E 1.1967335939407349, A 1.1440849304199219, N 1.1380864381790161
06/19/2024 01:35:37 - ERROR - root -  17%|#6        | 65/390 [03:32<18:12,  3.36s/it]
06/19/2024 01:35:38 - INFO - modeling_roberta - Training sub-loss: O 1.128483772277832, C 1.0830926895141602, E 1.067277431488037, A 1.0822135210037231, N 1.188532829284668
06/19/2024 01:35:38 - INFO - modeling_roberta - Training sub-loss: O 1.0404411554336548, C 1.1220753192901611, E 1.1154577732086182, A 1.1437857151031494, N 1.202460765838623
06/19/2024 01:35:39 - INFO - modeling_roberta - Training sub-loss: O 1.1560966968536377, C 1.0914828777313232, E 1.0696742534637451, A 1.1355292797088623, N 1.1037867069244385
06/19/2024 01:35:39 - INFO - modeling_roberta - Training sub-loss: O 1.140775442123413, C 1.0685052871704102, E 1.1059215068817139, A 1.065706729888916, N 1.006981372833252
06/19/2024 01:35:40 - ERROR - root -  17%|#6        | 66/390 [03:35<18:16,  3.38s/it]
06/19/2024 01:35:41 - INFO - modeling_roberta - Training sub-loss: O 1.1548391580581665, C 1.0984998941421509, E 1.0522687435150146, A 1.2025002241134644, N 1.0921516418457031
06/19/2024 01:35:41 - INFO - modeling_roberta - Training sub-loss: O 1.1354396343231201, C 1.1298425197601318, E 1.129492998123169, A 1.1596853733062744, N 1.2104687690734863
06/19/2024 01:35:43 - INFO - modeling_roberta - Training sub-loss: O 1.0776760578155518, C 1.1581339836120605, E 1.118025779724121, A 0.9989975094795227, N 1.1402084827423096
06/19/2024 01:35:43 - INFO - modeling_roberta - Training sub-loss: O 1.1318578720092773, C 1.140718936920166, E 1.1103178262710571, A 1.1442915201187134, N 1.1193342208862305
06/19/2024 01:35:44 - ERROR - root -  17%|#7        | 67/390 [03:39<18:48,  3.49s/it]
06/19/2024 01:35:45 - INFO - modeling_roberta - Training sub-loss: O 1.0522222518920898, C 1.0632367134094238, E 1.1468385457992554, A 1.1747889518737793, N 1.0585575103759766
06/19/2024 01:35:45 - INFO - modeling_roberta - Training sub-loss: O 1.084599256515503, C 1.0664488077163696, E 1.1081340312957764, A 1.1106843948364258, N 1.1187670230865479
06/19/2024 01:35:46 - INFO - modeling_roberta - Training sub-loss: O 1.0983357429504395, C 1.1109539270401, E 1.1130768060684204, A 1.078108549118042, N 1.027156114578247
06/19/2024 01:35:46 - INFO - modeling_roberta - Training sub-loss: O 1.1153430938720703, C 1.1218862533569336, E 1.1030936241149902, A 1.0771889686584473, N 1.082843542098999
06/19/2024 01:35:47 - ERROR - root -  17%|#7        | 68/390 [03:42<18:23,  3.43s/it]
06/19/2024 01:35:48 - INFO - modeling_roberta - Training sub-loss: O 1.079869270324707, C 1.1109354496002197, E 1.0864241123199463, A 1.093003749847412, N 1.127201795578003
06/19/2024 01:35:48 - INFO - modeling_roberta - Training sub-loss: O 1.0914713144302368, C 1.1169565916061401, E 1.0882439613342285, A 1.060521125793457, N 1.1004364490509033
06/19/2024 01:35:50 - INFO - modeling_roberta - Training sub-loss: O 1.1177539825439453, C 1.0395772457122803, E 1.1479462385177612, A 1.181340217590332, N 1.1177089214324951
06/19/2024 01:35:50 - INFO - modeling_roberta - Training sub-loss: O 1.1670186519622803, C 1.075636625289917, E 1.1233893632888794, A 1.137542963027954, N 1.101668119430542
06/19/2024 01:35:50 - ERROR - root -  18%|#7        | 69/390 [03:46<18:00,  3.37s/it]
06/19/2024 01:35:51 - INFO - modeling_roberta - Training sub-loss: O 1.1120561361312866, C 1.1480987071990967, E 1.0789356231689453, A 1.127667784690857, N 1.1250051259994507
06/19/2024 01:35:51 - INFO - modeling_roberta - Training sub-loss: O 1.129577875137329, C 1.0699607133865356, E 1.0855300426483154, A 1.1686229705810547, N 1.0477304458618164
06/19/2024 01:35:53 - INFO - modeling_roberta - Training sub-loss: O 1.0662976503372192, C 1.03157377243042, E 1.1932358741760254, A 1.149359941482544, N 1.1035208702087402
06/19/2024 01:35:53 - INFO - modeling_roberta - Training sub-loss: O 1.071251392364502, C 1.135115385055542, E 1.0884889364242554, A 1.1194515228271484, N 1.100651741027832
06/19/2024 01:35:54 - ERROR - root -  18%|#7        | 70/390 [03:49<17:45,  3.33s/it]
06/19/2024 01:35:54 - INFO - root - {'loss': 1.1108, 'grad_norm': 85924.1875, 'learning_rate': 8.205128205128205e-05, 'epoch': 0.89}
06/19/2024 01:35:54 - ERROR - root -  18%|#7        | 70/390 [03:49<17:45,  3.33s/it]
06/19/2024 01:35:54 - INFO - modeling_roberta - Training sub-loss: O 1.119217038154602, C 1.1071795225143433, E 1.1116093397140503, A 1.0688493251800537, N 1.104024887084961
06/19/2024 01:35:54 - INFO - modeling_roberta - Training sub-loss: O 1.093353509902954, C 1.132728099822998, E 1.1006803512573242, A 1.0757813453674316, N 1.139045238494873
06/19/2024 01:35:56 - INFO - modeling_roberta - Training sub-loss: O 1.0579780340194702, C 1.1442525386810303, E 1.1246956586837769, A 1.0895442962646484, N 1.1371766328811646
06/19/2024 01:35:56 - INFO - modeling_roberta - Training sub-loss: O 1.082660436630249, C 1.1488897800445557, E 1.0836083889007568, A 1.127176284790039, N 1.1837310791015625
06/19/2024 01:35:57 - ERROR - root -  18%|#8        | 71/390 [03:52<17:31,  3.30s/it]
06/19/2024 01:35:58 - INFO - modeling_roberta - Training sub-loss: O 1.107439398765564, C 1.0786449909210205, E 1.1608595848083496, A 1.1305123567581177, N 1.1444717645645142
06/19/2024 01:35:58 - INFO - modeling_roberta - Training sub-loss: O 1.0900702476501465, C 1.1469589471817017, E 1.1104649305343628, A 1.1341989040374756, N 1.1135478019714355
06/19/2024 01:35:59 - INFO - modeling_roberta - Training sub-loss: O 1.1414451599121094, C 1.1231498718261719, E 1.0896124839782715, A 1.14107346534729, N 1.1162946224212646
06/19/2024 01:35:59 - INFO - modeling_roberta - Training sub-loss: O 1.108365535736084, C 1.1153056621551514, E 1.0998965501785278, A 1.119645357131958, N 1.095395565032959
06/19/2024 01:36:00 - ERROR - root -  18%|#8        | 72/390 [03:55<17:24,  3.28s/it]
06/19/2024 01:36:01 - INFO - modeling_roberta - Training sub-loss: O 1.101205825805664, C 1.1239027976989746, E 1.0688565969467163, A 1.0819875001907349, N 1.0803401470184326
06/19/2024 01:36:01 - INFO - modeling_roberta - Training sub-loss: O 1.0305007696151733, C 1.0821640491485596, E 1.1163784265518188, A 1.1411488056182861, N 1.1806679964065552
06/19/2024 01:36:02 - INFO - modeling_roberta - Training sub-loss: O 1.0353068113327026, C 1.230659008026123, E 1.144476056098938, A 1.2688379287719727, N 1.0873496532440186
06/19/2024 01:36:03 - INFO - modeling_roberta - Training sub-loss: O 1.0807886123657227, C 1.1696641445159912, E 1.113996148109436, A 1.2748278379440308, N 1.071254014968872
06/19/2024 01:36:03 - ERROR - root -  19%|#8        | 73/390 [03:59<17:18,  3.28s/it]
06/19/2024 01:36:04 - INFO - modeling_roberta - Training sub-loss: O 1.080536127090454, C 1.0887850522994995, E 1.0981131792068481, A 1.085039734840393, N 1.0948362350463867
06/19/2024 01:36:04 - INFO - modeling_roberta - Training sub-loss: O 1.0736372470855713, C 1.0830771923065186, E 1.1098177433013916, A 1.0753204822540283, N 1.0970737934112549
06/19/2024 01:36:06 - INFO - modeling_roberta - Training sub-loss: O 1.1541564464569092, C 1.1051175594329834, E 1.121708869934082, A 1.11812162399292, N 1.1565728187561035
06/19/2024 01:36:06 - INFO - modeling_roberta - Training sub-loss: O 1.076906681060791, C 1.1105387210845947, E 1.1080725193023682, A 1.0349833965301514, N 1.0951173305511475
06/19/2024 01:36:07 - ERROR - root -  19%|#8        | 74/390 [04:02<17:08,  3.26s/it]
06/19/2024 01:36:07 - INFO - modeling_roberta - Training sub-loss: O 1.0937252044677734, C 1.0823603868484497, E 1.065571904182434, A 1.1302690505981445, N 1.1189031600952148
06/19/2024 01:36:07 - INFO - modeling_roberta - Training sub-loss: O 1.1300833225250244, C 1.0531567335128784, E 1.0960798263549805, A 1.1140397787094116, N 1.153925895690918
06/19/2024 01:36:09 - INFO - modeling_roberta - Training sub-loss: O 1.0759785175323486, C 1.1280994415283203, E 1.1318860054016113, A 1.1008169651031494, N 1.1028790473937988
06/19/2024 01:36:09 - INFO - modeling_roberta - Training sub-loss: O 1.103238821029663, C 1.1017168760299683, E 1.0874927043914795, A 1.1351184844970703, N 1.1051254272460938
06/19/2024 01:36:10 - ERROR - root -  19%|#9        | 75/390 [04:05<16:59,  3.24s/it]
06/19/2024 01:36:11 - INFO - modeling_roberta - Training sub-loss: O 1.0235928297042847, C 1.0854952335357666, E 1.1220407485961914, A 1.0710731744766235, N 1.11492121219635
06/19/2024 01:36:11 - INFO - modeling_roberta - Training sub-loss: O 1.1049840450286865, C 1.0708661079406738, E 1.10009765625, A 1.0391541719436646, N 1.0844309329986572
06/19/2024 01:36:12 - INFO - modeling_roberta - Training sub-loss: O 1.1328939199447632, C 1.112554669380188, E 1.1231513023376465, A 1.1628735065460205, N 1.1114122867584229
06/19/2024 01:36:12 - INFO - modeling_roberta - Training sub-loss: O 1.0883409976959229, C 1.123092770576477, E 1.0562114715576172, A 1.1510634422302246, N 1.1115524768829346
06/19/2024 01:36:13 - ERROR - root -  19%|#9        | 76/390 [04:08<16:52,  3.22s/it]
06/19/2024 01:36:14 - INFO - modeling_roberta - Training sub-loss: O 1.045924425125122, C 1.0885493755340576, E 1.1052899360656738, A 1.1062471866607666, N 1.071234941482544
06/19/2024 01:36:14 - INFO - modeling_roberta - Training sub-loss: O 1.0714507102966309, C 1.1031534671783447, E 1.1100490093231201, A 1.0359022617340088, N 1.118526577949524
06/19/2024 01:36:15 - INFO - modeling_roberta - Training sub-loss: O 1.1289653778076172, C 1.1113423109054565, E 1.1449297666549683, A 1.1410372257232666, N 1.109879970550537
06/19/2024 01:36:15 - INFO - modeling_roberta - Training sub-loss: O 1.0705054998397827, C 1.0706779956817627, E 1.13644540309906, A 1.1000758409500122, N 1.13015878200531
06/19/2024 01:36:16 - ERROR - root -  20%|#9        | 77/390 [04:11<16:47,  3.22s/it]
06/19/2024 01:36:17 - INFO - modeling_roberta - Training sub-loss: O 1.1128933429718018, C 1.1123523712158203, E 1.0685579776763916, A 1.102077603340149, N 1.0541682243347168
06/19/2024 01:36:17 - INFO - modeling_roberta - Training sub-loss: O 1.1470587253570557, C 1.060408115386963, E 1.2036503553390503, A 1.1054496765136719, N 1.122767448425293
06/19/2024 01:36:19 - INFO - modeling_roberta - Training sub-loss: O 1.0593523979187012, C 1.1246166229248047, E 1.122195839881897, A 1.0620808601379395, N 1.1012330055236816
06/19/2024 01:36:19 - INFO - modeling_roberta - Training sub-loss: O 1.0771794319152832, C 1.123005986213684, E 1.1297781467437744, A 1.1129238605499268, N 1.0573642253875732
06/19/2024 01:36:19 - ERROR - root -  20%|##        | 78/390 [04:15<16:43,  3.22s/it]
06/19/2024 01:36:20 - INFO - modeling_roberta - Training sub-loss: O 1.161268949508667, C 1.0877983570098877, E 1.1187371015548706, A 1.05935537815094, N 1.132015347480774
06/19/2024 01:36:20 - INFO - modeling_roberta - Training sub-loss: O 1.1035568714141846, C 1.1952154636383057, E 1.1292290687561035, A 1.093571424484253, N 1.0999512672424316
06/19/2024 01:36:22 - INFO - modeling_roberta - Training sub-loss: O 1.091629981994629, C 1.0690665245056152, E 1.1088064908981323, A 1.0516414642333984, N 1.0781207084655762
06/19/2024 01:36:22 - INFO - modeling_roberta - Training sub-loss: O 1.0633107423782349, C 1.1147853136062622, E 1.0467673540115356, A 1.123435139656067, N 1.1740443706512451
06/19/2024 01:36:23 - ERROR - root -  20%|##        | 79/390 [04:18<16:44,  3.23s/it]
06/19/2024 01:36:23 - INFO - modeling_roberta - Training sub-loss: O 1.135232925415039, C 1.0722386837005615, E 1.1818904876708984, A 1.1324269771575928, N 1.0533771514892578
06/19/2024 01:36:23 - INFO - modeling_roberta - Training sub-loss: O 1.149390697479248, C 1.1108776330947876, E 1.1575357913970947, A 1.162243127822876, N 1.1839503049850464
06/19/2024 01:36:25 - INFO - modeling_roberta - Training sub-loss: O 1.1170220375061035, C 1.0842561721801758, E 1.0870838165283203, A 1.0919489860534668, N 1.1471443176269531
06/19/2024 01:36:25 - INFO - modeling_roberta - Training sub-loss: O 1.1231225728988647, C 1.082890510559082, E 1.0715842247009277, A 1.0778671503067017, N 1.0001400709152222
06/19/2024 01:36:26 - ERROR - root -  21%|##        | 80/390 [04:21<16:38,  3.22s/it]
06/19/2024 01:36:26 - INFO - root - {'loss': 1.1077, 'grad_norm': 100513.3125, 'learning_rate': 7.948717948717948e-05, 'epoch': 1.02}
06/19/2024 01:36:26 - ERROR - root -  21%|##        | 80/390 [04:21<16:38,  3.22s/it]
06/19/2024 01:36:27 - INFO - modeling_roberta - Training sub-loss: O 1.057447910308838, C 1.1029536724090576, E 1.0866804122924805, A 1.1293648481369019, N 1.1218085289001465
06/19/2024 01:36:27 - INFO - modeling_roberta - Training sub-loss: O 1.1412209272384644, C 1.0661725997924805, E 1.1165351867675781, A 1.0728561878204346, N 1.0571763515472412
06/19/2024 01:36:28 - INFO - modeling_roberta - Training sub-loss: O 1.0443264245986938, C 1.2316017150878906, E 0.9971380233764648, A 1.1729817390441895, N 1.1323726177215576
06/19/2024 01:36:28 - INFO - modeling_roberta - Training sub-loss: O 1.0549466609954834, C 1.2334809303283691, E 1.1876925230026245, A 1.1531903743743896, N 1.1970387697219849
06/19/2024 01:36:29 - ERROR - root -  21%|##        | 81/390 [04:24<16:33,  3.22s/it]
06/19/2024 01:36:30 - INFO - modeling_roberta - Training sub-loss: O 1.0331051349639893, C 1.138302206993103, E 1.0573006868362427, A 1.1592915058135986, N 1.1508476734161377
06/19/2024 01:36:30 - INFO - modeling_roberta - Training sub-loss: O 1.0908129215240479, C 1.1290428638458252, E 1.1619136333465576, A 1.0824768543243408, N 1.1177960634231567
06/19/2024 01:36:31 - INFO - modeling_roberta - Training sub-loss: O 1.1288141012191772, C 1.0437262058258057, E 1.1495497226715088, A 1.1629538536071777, N 1.1651275157928467
06/19/2024 01:36:31 - INFO - modeling_roberta - Training sub-loss: O 1.0991184711456299, C 1.1030094623565674, E 1.1807678937911987, A 1.1289550065994263, N 1.1475095748901367
06/19/2024 01:36:32 - ERROR - root -  21%|##1       | 82/390 [04:27<16:32,  3.22s/it]
06/19/2024 01:36:33 - INFO - modeling_roberta - Training sub-loss: O 1.0937557220458984, C 1.1386687755584717, E 1.0942847728729248, A 1.156625509262085, N 1.0595225095748901
06/19/2024 01:36:33 - INFO - modeling_roberta - Training sub-loss: O 1.0931386947631836, C 1.1380655765533447, E 1.1243436336517334, A 1.105107307434082, N 1.1373848915100098
06/19/2024 01:36:35 - INFO - modeling_roberta - Training sub-loss: O 1.0198795795440674, C 1.0970666408538818, E 1.0789529085159302, A 1.0987019538879395, N 1.1010794639587402
06/19/2024 01:36:35 - INFO - modeling_roberta - Training sub-loss: O 1.1090855598449707, C 1.089489459991455, E 1.087648630142212, A 1.1275091171264648, N 1.0865085124969482
06/19/2024 01:36:36 - ERROR - root -  21%|##1       | 83/390 [04:31<16:27,  3.22s/it]
06/19/2024 01:36:36 - INFO - modeling_roberta - Training sub-loss: O 1.1347663402557373, C 1.1219184398651123, E 1.1288526058197021, A 1.0702017545700073, N 1.1219584941864014
06/19/2024 01:36:36 - INFO - modeling_roberta - Training sub-loss: O 1.0764076709747314, C 1.1508793830871582, E 1.0644314289093018, A 1.0967884063720703, N 1.1826951503753662
06/19/2024 01:36:38 - INFO - modeling_roberta - Training sub-loss: O 1.1292246580123901, C 1.0891058444976807, E 1.14119291305542, A 1.0852622985839844, N 1.1471809148788452
06/19/2024 01:36:38 - INFO - modeling_roberta - Training sub-loss: O 1.1134347915649414, C 1.1495938301086426, E 1.0778615474700928, A 1.1202515363693237, N 1.155135154724121
06/19/2024 01:36:39 - ERROR - root -  22%|##1       | 84/390 [04:34<16:23,  3.22s/it]
06/19/2024 01:36:39 - INFO - modeling_roberta - Training sub-loss: O 1.0756539106369019, C 1.079373836517334, E 1.131037950515747, A 1.0701991319656372, N 1.1138029098510742
06/19/2024 01:36:39 - INFO - modeling_roberta - Training sub-loss: O 1.0851179361343384, C 1.1463333368301392, E 1.119735598564148, A 1.1001365184783936, N 1.0952098369598389
06/19/2024 01:36:41 - INFO - modeling_roberta - Training sub-loss: O 1.0338473320007324, C 1.114283561706543, E 1.094719409942627, A 1.0919625759124756, N 1.089565634727478
06/19/2024 01:36:41 - INFO - modeling_roberta - Training sub-loss: O 1.142087697982788, C 1.0841193199157715, E 1.0977299213409424, A 1.0833103656768799, N 1.139533519744873
06/19/2024 01:36:42 - ERROR - root -  22%|##1       | 85/390 [04:37<16:17,  3.21s/it]
06/19/2024 01:36:43 - INFO - modeling_roberta - Training sub-loss: O 1.1329193115234375, C 1.1349554061889648, E 1.0974711179733276, A 1.0882073640823364, N 1.0318163633346558
06/19/2024 01:36:43 - INFO - modeling_roberta - Training sub-loss: O 1.1520769596099854, C 1.0826010704040527, E 1.1243889331817627, A 1.0981659889221191, N 1.1252683401107788
06/19/2024 01:36:44 - INFO - modeling_roberta - Training sub-loss: O 1.1166894435882568, C 1.1298120021820068, E 1.0934646129608154, A 1.1029881238937378, N 1.1068252325057983
06/19/2024 01:36:44 - INFO - modeling_roberta - Training sub-loss: O 1.1677662134170532, C 1.0951095819473267, E 1.1239838600158691, A 1.0562795400619507, N 1.115511178970337
06/19/2024 01:36:45 - ERROR - root -  22%|##2       | 86/390 [04:40<16:12,  3.20s/it]
06/19/2024 01:36:46 - INFO - modeling_roberta - Training sub-loss: O 1.0838451385498047, C 1.13177490234375, E 1.1338222026824951, A 1.154589056968689, N 1.070192813873291
06/19/2024 01:36:46 - INFO - modeling_roberta - Training sub-loss: O 1.0853990316390991, C 1.1071810722351074, E 1.0577846765518188, A 1.1346445083618164, N 1.095798134803772
06/19/2024 01:36:47 - INFO - modeling_roberta - Training sub-loss: O 1.0949965715408325, C 1.116801142692566, E 1.1186846494674683, A 1.136735200881958, N 1.1404483318328857
06/19/2024 01:36:47 - INFO - modeling_roberta - Training sub-loss: O 1.1151654720306396, C 1.142634630203247, E 1.0948365926742554, A 1.057314157485962, N 1.115286111831665
06/19/2024 01:36:48 - ERROR - root -  22%|##2       | 87/390 [04:43<16:08,  3.20s/it]
06/19/2024 01:36:49 - INFO - modeling_roberta - Training sub-loss: O 1.1129775047302246, C 1.1272271871566772, E 1.077441692352295, A 1.1098074913024902, N 1.0982303619384766
06/19/2024 01:36:49 - INFO - modeling_roberta - Training sub-loss: O 1.127555012702942, C 1.0646624565124512, E 1.086143970489502, A 1.0896021127700806, N 1.1076220273971558
06/19/2024 01:36:51 - INFO - modeling_roberta - Training sub-loss: O 1.1338701248168945, C 1.0313222408294678, E 1.0780315399169922, A 1.121387004852295, N 1.0930466651916504
06/19/2024 01:36:51 - INFO - modeling_roberta - Training sub-loss: O 1.1133875846862793, C 1.1063015460968018, E 1.0766243934631348, A 1.056628704071045, N 1.1065692901611328
06/19/2024 01:36:52 - ERROR - root -  23%|##2       | 88/390 [04:47<16:06,  3.20s/it]
06/19/2024 01:36:52 - INFO - modeling_roberta - Training sub-loss: O 1.0795480012893677, C 1.1065385341644287, E 1.1199835538864136, A 1.124373197555542, N 1.08424711227417
06/19/2024 01:36:52 - INFO - modeling_roberta - Training sub-loss: O 1.14217209815979, C 1.143465518951416, E 1.113908052444458, A 1.0395605564117432, N 1.1267259120941162
06/19/2024 01:36:54 - INFO - modeling_roberta - Training sub-loss: O 1.1326704025268555, C 1.1170454025268555, E 1.129814863204956, A 1.149167537689209, N 1.09767746925354
06/19/2024 01:36:54 - INFO - modeling_roberta - Training sub-loss: O 1.0902099609375, C 1.059436321258545, E 1.1180425882339478, A 1.1298201084136963, N 1.0849103927612305
06/19/2024 01:36:55 - ERROR - root -  23%|##2       | 89/390 [04:50<16:03,  3.20s/it]
06/19/2024 01:36:55 - INFO - modeling_roberta - Training sub-loss: O 1.0928665399551392, C 1.0505585670471191, E 1.0875449180603027, A 1.0729652643203735, N 1.1429193019866943
06/19/2024 01:36:55 - INFO - modeling_roberta - Training sub-loss: O 1.1119136810302734, C 1.1159350872039795, E 1.1035993099212646, A 1.0221233367919922, N 1.1504395008087158
06/19/2024 01:36:57 - INFO - modeling_roberta - Training sub-loss: O 1.1322319507598877, C 1.086304783821106, E 1.1034278869628906, A 1.1378328800201416, N 1.1047354936599731
06/19/2024 01:36:57 - INFO - modeling_roberta - Training sub-loss: O 1.2225195169448853, C 1.0807324647903442, E 1.113182544708252, A 1.0500895977020264, N 1.1003012657165527
06/19/2024 01:36:58 - ERROR - root -  23%|##3       | 90/390 [04:53<15:59,  3.20s/it]
06/19/2024 01:36:58 - INFO - root - {'loss': 1.1086, 'grad_norm': 94513.03125, 'learning_rate': 7.692307692307693e-05, 'epoch': 1.15}
06/19/2024 01:36:58 - ERROR - root -  23%|##3       | 90/390 [04:53<15:59,  3.20s/it]
06/19/2024 01:36:59 - INFO - modeling_roberta - Training sub-loss: O 1.158860206604004, C 1.1033284664154053, E 1.1136493682861328, A 1.1905224323272705, N 1.1329668760299683
06/19/2024 01:36:59 - INFO - modeling_roberta - Training sub-loss: O 1.1910676956176758, C 1.1267145872116089, E 1.0957679748535156, A 1.1076360940933228, N 1.0866990089416504
06/19/2024 01:37:00 - INFO - modeling_roberta - Training sub-loss: O 1.0921473503112793, C 1.1034836769104004, E 1.14076566696167, A 1.116416573524475, N 1.1559722423553467
06/19/2024 01:37:00 - INFO - modeling_roberta - Training sub-loss: O 1.1311795711517334, C 1.123652696609497, E 1.1260615587234497, A 1.0937764644622803, N 1.084848165512085
06/19/2024 01:37:01 - ERROR - root -  23%|##3       | 91/390 [04:56<16:14,  3.26s/it]
06/19/2024 01:37:02 - INFO - modeling_roberta - Training sub-loss: O 1.1511445045471191, C 1.1244676113128662, E 1.117608904838562, A 1.1535998582839966, N 1.1555919647216797
06/19/2024 01:37:02 - INFO - modeling_roberta - Training sub-loss: O 1.1505835056304932, C 1.0513290166854858, E 0.9908345937728882, A 1.1437225341796875, N 1.0859200954437256
06/19/2024 01:37:04 - INFO - modeling_roberta - Training sub-loss: O 1.1082475185394287, C 1.0329557657241821, E 1.111346960067749, A 1.1530463695526123, N 1.1356110572814941
06/19/2024 01:37:04 - INFO - modeling_roberta - Training sub-loss: O 1.1296466588974, C 1.0779303312301636, E 1.1331207752227783, A 1.0952017307281494, N 1.0992372035980225
06/19/2024 01:37:05 - ERROR - root -  24%|##3       | 92/390 [05:00<16:40,  3.36s/it]
06/19/2024 01:37:07 - INFO - modeling_roberta - Training sub-loss: O 1.1487046480178833, C 1.0627715587615967, E 1.070231318473816, A 1.0987268686294556, N 1.0718649625778198
06/19/2024 01:37:07 - INFO - modeling_roberta - Training sub-loss: O 1.0969164371490479, C 1.1243170499801636, E 1.1504926681518555, A 1.1058040857315063, N 1.1204017400741577
06/19/2024 01:37:09 - INFO - modeling_roberta - Training sub-loss: O 1.1200239658355713, C 1.0724108219146729, E 1.104076623916626, A 1.080723524093628, N 1.0572118759155273
06/19/2024 01:37:09 - INFO - modeling_roberta - Training sub-loss: O 1.100975751876831, C 1.0392900705337524, E 1.0930993556976318, A 1.097683072090149, N 1.089905023574829
06/19/2024 01:37:10 - ERROR - root -  24%|##3       | 93/390 [05:05<19:07,  3.86s/it]
06/19/2024 01:37:11 - INFO - modeling_roberta - Training sub-loss: O 1.1855037212371826, C 1.0928850173950195, E 1.1237194538116455, A 1.112295150756836, N 1.0924701690673828
06/19/2024 01:37:11 - INFO - modeling_roberta - Training sub-loss: O 1.1138231754302979, C 1.138459324836731, E 1.108107089996338, A 1.1288690567016602, N 1.0919570922851562
06/19/2024 01:37:12 - INFO - modeling_roberta - Training sub-loss: O 1.0747957229614258, C 1.1456806659698486, E 1.1285125017166138, A 1.0459340810775757, N 1.038087010383606
06/19/2024 01:37:12 - INFO - modeling_roberta - Training sub-loss: O 1.170985221862793, C 1.0667688846588135, E 1.1094934940338135, A 1.0842658281326294, N 0.959589421749115
06/19/2024 01:37:13 - ERROR - root -  24%|##4       | 94/390 [05:08<18:09,  3.68s/it]
06/19/2024 01:37:14 - INFO - modeling_roberta - Training sub-loss: O 1.0999419689178467, C 1.0793805122375488, E 1.1297547817230225, A 1.0809597969055176, N 1.0904927253723145
06/19/2024 01:37:14 - INFO - modeling_roberta - Training sub-loss: O 1.133892297744751, C 1.1332893371582031, E 1.1231000423431396, A 1.1004447937011719, N 1.0820963382720947
06/19/2024 01:37:16 - INFO - modeling_roberta - Training sub-loss: O 1.1629841327667236, C 1.1059703826904297, E 1.1480748653411865, A 1.080122709274292, N 1.096900463104248
06/19/2024 01:37:16 - INFO - modeling_roberta - Training sub-loss: O 1.1306082010269165, C 1.0488801002502441, E 1.0699585676193237, A 1.1289606094360352, N 1.109311580657959
06/19/2024 01:37:17 - ERROR - root -  24%|##4       | 95/390 [05:12<17:34,  3.57s/it]
06/19/2024 01:37:17 - INFO - modeling_roberta - Training sub-loss: O 1.0679969787597656, C 1.1253138780593872, E 1.1460273265838623, A 1.089733600616455, N 1.090230941772461
06/19/2024 01:37:17 - INFO - modeling_roberta - Training sub-loss: O 1.088529109954834, C 1.2020745277404785, E 1.1229057312011719, A 1.151404857635498, N 1.0786535739898682
06/19/2024 01:37:19 - INFO - modeling_roberta - Training sub-loss: O 1.0748541355133057, C 1.0831661224365234, E 1.1072611808776855, A 1.1578000783920288, N 1.1304677724838257
06/19/2024 01:37:19 - INFO - modeling_roberta - Training sub-loss: O 1.0854713916778564, C 1.1107630729675293, E 1.1369891166687012, A 1.1420254707336426, N 1.117067813873291
06/19/2024 01:37:20 - ERROR - root -  25%|##4       | 96/390 [05:15<17:02,  3.48s/it]
06/19/2024 01:37:21 - INFO - modeling_roberta - Training sub-loss: O 1.1416939496994019, C 1.0350879430770874, E 1.0726432800292969, A 1.068047046661377, N 1.0388070344924927
06/19/2024 01:37:21 - INFO - modeling_roberta - Training sub-loss: O 1.1601767539978027, C 1.099853754043579, E 1.1731383800506592, A 1.0989744663238525, N 1.159327507019043
06/19/2024 01:37:22 - INFO - modeling_roberta - Training sub-loss: O 1.0890161991119385, C 1.1530283689498901, E 1.1528522968292236, A 1.1295967102050781, N 1.167133092880249
06/19/2024 01:37:22 - INFO - modeling_roberta - Training sub-loss: O 1.1462180614471436, C 1.1612440347671509, E 1.0763745307922363, A 1.0788254737854004, N 1.1204192638397217
06/19/2024 01:37:23 - ERROR - root -  25%|##4       | 97/390 [05:18<16:38,  3.41s/it]
06/19/2024 01:37:24 - INFO - modeling_roberta - Training sub-loss: O 1.1344813108444214, C 1.132598638534546, E 1.146056890487671, A 1.1196990013122559, N 1.0959391593933105
06/19/2024 01:37:24 - INFO - modeling_roberta - Training sub-loss: O 1.1572086811065674, C 1.1042051315307617, E 1.1466388702392578, A 1.0593600273132324, N 1.0963811874389648
06/19/2024 01:37:25 - INFO - modeling_roberta - Training sub-loss: O 1.131953239440918, C 1.1812249422073364, E 1.149019718170166, A 1.1212127208709717, N 1.114227294921875
06/19/2024 01:37:25 - INFO - modeling_roberta - Training sub-loss: O 1.0195709466934204, C 1.152334213256836, E 1.0721899271011353, A 1.0972545146942139, N 1.0743367671966553
06/19/2024 01:37:26 - ERROR - root -  25%|##5       | 98/390 [05:21<16:17,  3.35s/it]
06/19/2024 01:37:27 - INFO - modeling_roberta - Training sub-loss: O 1.0610477924346924, C 1.1204290390014648, E 1.1269316673278809, A 1.089406967163086, N 1.0890169143676758
06/19/2024 01:37:27 - INFO - modeling_roberta - Training sub-loss: O 1.1049739122390747, C 1.1567754745483398, E 1.112878680229187, A 1.115720272064209, N 1.1720893383026123
06/19/2024 01:37:29 - INFO - modeling_roberta - Training sub-loss: O 1.1044293642044067, C 1.1011862754821777, E 1.1563481092453003, A 1.1103955507278442, N 1.1551666259765625
06/19/2024 01:37:29 - INFO - modeling_roberta - Training sub-loss: O 1.1042940616607666, C 1.0703611373901367, E 1.137627124786377, A 1.1186232566833496, N 1.0731415748596191
06/19/2024 01:37:30 - ERROR - root -  25%|##5       | 99/390 [05:25<16:09,  3.33s/it]
06/19/2024 01:37:30 - INFO - modeling_roberta - Training sub-loss: O 1.0632914304733276, C 1.1600464582443237, E 1.099257230758667, A 1.1320858001708984, N 1.0758965015411377
06/19/2024 01:37:30 - INFO - modeling_roberta - Training sub-loss: O 1.1058183908462524, C 1.1119911670684814, E 1.0848603248596191, A 1.070253610610962, N 1.098201036453247
06/19/2024 01:37:32 - INFO - modeling_roberta - Training sub-loss: O 1.1017462015151978, C 1.1216871738433838, E 1.0991086959838867, A 1.1172603368759155, N 1.0696344375610352
06/19/2024 01:37:32 - INFO - modeling_roberta - Training sub-loss: O 1.1261301040649414, C 1.1921093463897705, E 1.1612646579742432, A 1.0799107551574707, N 1.086464762687683
06/19/2024 01:37:33 - ERROR - root -  26%|##5       | 100/390 [05:28<15:58,  3.30s/it]
06/19/2024 01:37:33 - INFO - root - {'loss': 1.1105, 'grad_norm': 70650.3125, 'learning_rate': 7.435897435897436e-05, 'epoch': 1.27}
06/19/2024 01:37:33 - ERROR - root -  26%|##5       | 100/390 [05:28<15:58,  3.30s/it]
06/19/2024 01:37:34 - INFO - modeling_roberta - Training sub-loss: O 1.1042442321777344, C 1.0969810485839844, E 1.1679778099060059, A 1.073469877243042, N 1.0755488872528076
06/19/2024 01:37:34 - INFO - modeling_roberta - Training sub-loss: O 1.0367399454116821, C 1.0734994411468506, E 1.1061983108520508, A 1.1285068988800049, N 1.0781772136688232
06/19/2024 01:37:35 - INFO - modeling_roberta - Training sub-loss: O 1.1299819946289062, C 1.0470225811004639, E 1.0880889892578125, A 1.1336160898208618, N 1.1137582063674927
06/19/2024 01:37:35 - INFO - modeling_roberta - Training sub-loss: O 1.0684632062911987, C 1.1437106132507324, E 1.1152849197387695, A 1.0678048133850098, N 1.1270920038223267
06/19/2024 01:37:36 - ERROR - root -  26%|##5       | 101/390 [05:31<15:52,  3.29s/it]
06/19/2024 01:37:37 - INFO - modeling_roberta - Training sub-loss: O 1.1374804973602295, C 1.114119529724121, E 1.0599690675735474, A 1.0681729316711426, N 1.0696158409118652
06/19/2024 01:37:37 - INFO - modeling_roberta - Training sub-loss: O 1.151559591293335, C 1.1199798583984375, E 1.116642713546753, A 1.0915498733520508, N 1.0994369983673096
06/19/2024 01:37:38 - INFO - modeling_roberta - Training sub-loss: O 1.1385040283203125, C 1.126446008682251, E 1.0871448516845703, A 1.1016769409179688, N 1.098233938217163
06/19/2024 01:37:38 - INFO - modeling_roberta - Training sub-loss: O 1.1076769828796387, C 1.1399112939834595, E 1.0617526769638062, A 1.1238210201263428, N 1.148099660873413
06/19/2024 01:37:39 - ERROR - root -  26%|##6       | 102/390 [05:34<15:45,  3.28s/it]
06/19/2024 01:37:40 - INFO - modeling_roberta - Training sub-loss: O 0.9992114901542664, C 1.1337159872055054, E 1.0870335102081299, A 1.1588661670684814, N 1.1282212734222412
06/19/2024 01:37:40 - INFO - modeling_roberta - Training sub-loss: O 1.1711673736572266, C 1.0894460678100586, E 1.0839862823486328, A 1.0898606777191162, N 1.1241029500961304
06/19/2024 01:37:42 - INFO - modeling_roberta - Training sub-loss: O 1.1465169191360474, C 1.0770986080169678, E 1.0600526332855225, A 1.1034834384918213, N 1.1392791271209717
06/19/2024 01:37:42 - INFO - modeling_roberta - Training sub-loss: O 1.1094989776611328, C 1.1575632095336914, E 1.0817441940307617, A 1.0896936655044556, N 1.0801362991333008
06/19/2024 01:37:43 - ERROR - root -  26%|##6       | 103/390 [05:38<15:37,  3.27s/it]
06/19/2024 01:37:43 - INFO - modeling_roberta - Training sub-loss: O 1.0974454879760742, C 1.1255465745925903, E 1.071595549583435, A 1.12116277217865, N 1.1459102630615234
06/19/2024 01:37:43 - INFO - modeling_roberta - Training sub-loss: O 1.139914870262146, C 1.0868775844573975, E 1.086928367614746, A 1.0685398578643799, N 1.1105220317840576
06/19/2024 01:37:45 - INFO - modeling_roberta - Training sub-loss: O 1.0764440298080444, C 1.0848884582519531, E 1.129629135131836, A 1.1185745000839233, N 1.0889606475830078
06/19/2024 01:37:45 - INFO - modeling_roberta - Training sub-loss: O 1.1528735160827637, C 1.1223764419555664, E 1.0886977910995483, A 1.0939526557922363, N 1.0791957378387451
06/19/2024 01:37:46 - ERROR - root -  27%|##6       | 104/390 [05:41<15:30,  3.25s/it]
06/19/2024 01:37:46 - INFO - modeling_roberta - Training sub-loss: O 1.097713828086853, C 1.1204077005386353, E 1.0445536375045776, A 1.0824944972991943, N 1.1449933052062988
06/19/2024 01:37:46 - INFO - modeling_roberta - Training sub-loss: O 1.0695104598999023, C 1.0687092542648315, E 1.1065396070480347, A 1.0916393995285034, N 1.0962333679199219
06/19/2024 01:37:48 - INFO - modeling_roberta - Training sub-loss: O 1.0513577461242676, C 1.1001031398773193, E 1.1174941062927246, A 1.0914874076843262, N 1.0980260372161865
06/19/2024 01:37:48 - INFO - modeling_roberta - Training sub-loss: O 1.1526854038238525, C 1.1337029933929443, E 1.0765811204910278, A 1.1260958909988403, N 1.1355763673782349
06/19/2024 01:37:49 - ERROR - root -  27%|##6       | 105/390 [05:44<15:24,  3.24s/it]
06/19/2024 01:37:50 - INFO - modeling_roberta - Training sub-loss: O 1.079524278640747, C 1.1414406299591064, E 1.1695787906646729, A 1.1205358505249023, N 1.0687284469604492
06/19/2024 01:37:50 - INFO - modeling_roberta - Training sub-loss: O 1.065223217010498, C 1.1352458000183105, E 1.1395652294158936, A 1.126272439956665, N 1.1442270278930664
06/19/2024 01:37:51 - INFO - modeling_roberta - Training sub-loss: O 1.0494290590286255, C 1.105323314666748, E 1.0699262619018555, A 1.152633547782898, N 1.1338852643966675
06/19/2024 01:37:51 - INFO - modeling_roberta - Training sub-loss: O 1.1152980327606201, C 1.163050651550293, E 1.16740882396698, A 1.1306512355804443, N 1.0869476795196533
06/19/2024 01:37:52 - ERROR - root -  27%|##7       | 106/390 [05:47<15:16,  3.23s/it]
06/19/2024 01:37:53 - INFO - modeling_roberta - Training sub-loss: O 1.1258190870285034, C 1.107809066772461, E 1.051511287689209, A 1.088761329650879, N 1.1325111389160156
06/19/2024 01:37:53 - INFO - modeling_roberta - Training sub-loss: O 1.0956640243530273, C 1.0983120203018188, E 1.1297569274902344, A 1.1163511276245117, N 1.0667660236358643
06/19/2024 01:37:54 - INFO - modeling_roberta - Training sub-loss: O 1.1656780242919922, C 1.1203360557556152, E 1.0666965246200562, A 1.1040133237838745, N 1.150163173675537
06/19/2024 01:37:54 - INFO - modeling_roberta - Training sub-loss: O 1.0995543003082275, C 1.1193585395812988, E 1.1155266761779785, A 1.0955866575241089, N 1.0899699926376343
06/19/2024 01:37:55 - ERROR - root -  27%|##7       | 107/390 [05:50<15:13,  3.23s/it]
06/19/2024 01:37:56 - INFO - modeling_roberta - Training sub-loss: O 1.078476071357727, C 1.0641493797302246, E 1.091860055923462, A 1.0564135313034058, N 1.1306376457214355
06/19/2024 01:37:56 - INFO - modeling_roberta - Training sub-loss: O 1.1023154258728027, C 1.0652360916137695, E 1.1314003467559814, A 1.1003450155258179, N 1.0782017707824707
06/19/2024 01:37:58 - INFO - modeling_roberta - Training sub-loss: O 1.1332347393035889, C 1.1277629137039185, E 1.073616862297058, A 1.0828860998153687, N 1.124098539352417
06/19/2024 01:37:58 - INFO - modeling_roberta - Training sub-loss: O 1.071807622909546, C 1.0601112842559814, E 1.0798988342285156, A 1.0943809747695923, N 1.111601710319519
06/19/2024 01:37:59 - ERROR - root -  28%|##7       | 108/390 [05:54<15:06,  3.21s/it]
06/19/2024 01:37:59 - INFO - modeling_roberta - Training sub-loss: O 1.1196073293685913, C 1.0990351438522339, E 1.180368185043335, A 1.1595184803009033, N 1.1041802167892456
06/19/2024 01:37:59 - INFO - modeling_roberta - Training sub-loss: O 1.1195690631866455, C 1.1087605953216553, E 1.09769606590271, A 1.0889259576797485, N 1.0846781730651855
06/19/2024 01:38:01 - INFO - modeling_roberta - Training sub-loss: O 1.1372231245040894, C 1.0910589694976807, E 1.1559209823608398, A 1.1126430034637451, N 1.0937392711639404
06/19/2024 01:38:01 - INFO - modeling_roberta - Training sub-loss: O 1.172515630722046, C 1.1495246887207031, E 1.176548719406128, A 1.157427430152893, N 1.11992347240448
06/19/2024 01:38:02 - ERROR - root -  28%|##7       | 109/390 [05:57<15:03,  3.22s/it]
06/19/2024 01:38:03 - INFO - modeling_roberta - Training sub-loss: O 1.0906562805175781, C 1.0988078117370605, E 1.1030564308166504, A 1.0884311199188232, N 1.0835270881652832
06/19/2024 01:38:03 - INFO - modeling_roberta - Training sub-loss: O 1.136916160583496, C 1.074589729309082, E 1.01960027217865, A 1.1564898490905762, N 1.0916390419006348
06/19/2024 01:38:04 - INFO - modeling_roberta - Training sub-loss: O 1.0972318649291992, C 1.0657000541687012, E 1.181697964668274, A 1.0699406862258911, N 1.0974364280700684
06/19/2024 01:38:04 - INFO - modeling_roberta - Training sub-loss: O 1.1205607652664185, C 1.0746700763702393, E 1.2451698780059814, A 1.1267166137695312, N 1.0663907527923584
06/19/2024 01:38:05 - ERROR - root -  28%|##8       | 110/390 [06:00<15:04,  3.23s/it]
06/19/2024 01:38:05 - INFO - root - {'loss': 1.1066, 'grad_norm': 93378.3828125, 'learning_rate': 7.17948717948718e-05, 'epoch': 1.4}
06/19/2024 01:38:05 - ERROR - root -  28%|##8       | 110/390 [06:00<15:04,  3.23s/it]
06/19/2024 01:38:06 - INFO - modeling_roberta - Training sub-loss: O 1.096096396446228, C 1.1620512008666992, E 1.1146072149276733, A 1.0912270545959473, N 1.0891612768173218
06/19/2024 01:38:06 - INFO - modeling_roberta - Training sub-loss: O 1.099544644355774, C 1.147310495376587, E 1.1864774227142334, A 1.0663071870803833, N 1.0601763725280762
06/19/2024 01:38:07 - INFO - modeling_roberta - Training sub-loss: O 1.1057418584823608, C 1.0969147682189941, E 1.0711233615875244, A 1.1061909198760986, N 1.082878828048706
06/19/2024 01:38:07 - INFO - modeling_roberta - Training sub-loss: O 1.1301383972167969, C 1.1017818450927734, E 1.1300313472747803, A 1.0998910665512085, N 1.0912234783172607
06/19/2024 01:38:08 - ERROR - root -  28%|##8       | 111/390 [06:03<15:01,  3.23s/it]
06/19/2024 01:38:09 - INFO - modeling_roberta - Training sub-loss: O 1.0906503200531006, C 1.0969483852386475, E 1.0926427841186523, A 1.1420016288757324, N 1.0975223779678345
06/19/2024 01:38:09 - INFO - modeling_roberta - Training sub-loss: O 1.0776394605636597, C 1.1288247108459473, E 1.080374836921692, A 1.0706324577331543, N 1.0700644254684448
06/19/2024 01:38:11 - INFO - modeling_roberta - Training sub-loss: O 1.0979152917861938, C 1.1084922552108765, E 1.1616413593292236, A 1.1259033679962158, N 1.106738805770874
06/19/2024 01:38:11 - INFO - modeling_roberta - Training sub-loss: O 1.0757548809051514, C 1.0757123231887817, E 1.0751004219055176, A 1.109196662902832, N 1.1093580722808838
06/19/2024 01:38:12 - ERROR - root -  29%|##8       | 112/390 [06:07<14:55,  3.22s/it]
06/19/2024 01:38:12 - INFO - modeling_roberta - Training sub-loss: O 1.1206679344177246, C 1.0837762355804443, E 1.0548126697540283, A 1.0832842588424683, N 1.0825612545013428
06/19/2024 01:38:12 - INFO - modeling_roberta - Training sub-loss: O 1.0885941982269287, C 1.0874003171920776, E 1.0887360572814941, A 1.0875113010406494, N 1.1084468364715576
06/19/2024 01:38:14 - INFO - modeling_roberta - Training sub-loss: O 1.0882542133331299, C 1.1866830587387085, E 1.0300707817077637, A 1.08204984664917, N 1.121668815612793
06/19/2024 01:38:14 - INFO - modeling_roberta - Training sub-loss: O 1.082240104675293, C 1.1317014694213867, E 1.0867929458618164, A 1.1339952945709229, N 1.1311782598495483
06/19/2024 01:38:15 - ERROR - root -  29%|##8       | 113/390 [06:10<14:52,  3.22s/it]
06/19/2024 01:38:15 - INFO - modeling_roberta - Training sub-loss: O 1.1455755233764648, C 1.1242083311080933, E 1.0512030124664307, A 1.130342960357666, N 1.105224847793579
06/19/2024 01:38:15 - INFO - modeling_roberta - Training sub-loss: O 1.160693645477295, C 1.1500139236450195, E 1.16023588180542, A 1.1011879444122314, N 1.0645420551300049
06/19/2024 01:38:17 - INFO - modeling_roberta - Training sub-loss: O 1.0687891244888306, C 1.1191749572753906, E 1.1098954677581787, A 1.1230145692825317, N 1.0874300003051758
06/19/2024 01:38:17 - INFO - modeling_roberta - Training sub-loss: O 1.0740532875061035, C 1.1042671203613281, E 1.0973719358444214, A 1.0978233814239502, N 1.097864031791687
06/19/2024 01:38:18 - ERROR - root -  29%|##9       | 114/390 [06:13<14:53,  3.24s/it]
06/19/2024 01:38:19 - INFO - modeling_roberta - Training sub-loss: O 1.0967662334442139, C 1.1068261861801147, E 1.1543633937835693, A 1.100521206855774, N 1.0543664693832397
06/19/2024 01:38:19 - INFO - modeling_roberta - Training sub-loss: O 1.0938735008239746, C 1.0588815212249756, E 1.2129216194152832, A 1.0621073246002197, N 1.1017723083496094
06/19/2024 01:38:20 - INFO - modeling_roberta - Training sub-loss: O 1.092203140258789, C 1.1529642343521118, E 1.0817128419876099, A 1.0182785987854004, N 1.1201484203338623
06/19/2024 01:38:20 - INFO - modeling_roberta - Training sub-loss: O 1.0949695110321045, C 1.135758638381958, E 1.1898280382156372, A 1.1680347919464111, N 1.0931289196014404
06/19/2024 01:38:21 - ERROR - root -  29%|##9       | 115/390 [06:16<14:51,  3.24s/it]
06/19/2024 01:38:22 - INFO - modeling_roberta - Training sub-loss: O 1.063810110092163, C 1.0879703760147095, E 1.0852830410003662, A 1.1014602184295654, N 1.0769257545471191
06/19/2024 01:38:22 - INFO - modeling_roberta - Training sub-loss: O 1.0752043724060059, C 1.0891053676605225, E 1.076794147491455, A 1.119512677192688, N 1.1308200359344482
06/19/2024 01:38:24 - INFO - modeling_roberta - Training sub-loss: O 1.0860090255737305, C 1.107221007347107, E 1.1251113414764404, A 1.1188116073608398, N 1.105755090713501
06/19/2024 01:38:24 - INFO - modeling_roberta - Training sub-loss: O 1.104541301727295, C 1.151531457901001, E 1.103919267654419, A 1.0755020380020142, N 1.1405221223831177
06/19/2024 01:38:25 - ERROR - root -  30%|##9       | 116/390 [06:20<14:59,  3.28s/it]
06/19/2024 01:38:25 - INFO - modeling_roberta - Training sub-loss: O 1.1200337409973145, C 1.111417531967163, E 1.1718933582305908, A 1.1470144987106323, N 1.11561918258667
06/19/2024 01:38:25 - INFO - modeling_roberta - Training sub-loss: O 1.0771784782409668, C 1.1418464183807373, E 1.1040877103805542, A 1.1248058080673218, N 1.1002418994903564
06/19/2024 01:38:27 - INFO - modeling_roberta - Training sub-loss: O 1.135138988494873, C 1.067751169204712, E 1.1414735317230225, A 1.0675768852233887, N 1.1591796875
06/19/2024 01:38:27 - INFO - modeling_roberta - Training sub-loss: O 1.1222853660583496, C 1.0964851379394531, E 1.1177467107772827, A 1.1356592178344727, N 1.1156138181686401
06/19/2024 01:38:28 - ERROR - root -  30%|###       | 117/390 [06:23<14:51,  3.27s/it]
06/19/2024 01:38:29 - INFO - modeling_roberta - Training sub-loss: O 1.0636279582977295, C 1.0395063161849976, E 1.0640549659729004, A 1.154707908630371, N 1.1113080978393555
06/19/2024 01:38:29 - INFO - modeling_roberta - Training sub-loss: O 1.0906226634979248, C 1.0701663494110107, E 1.0886757373809814, A 1.162731409072876, N 1.1338317394256592
06/19/2024 01:38:30 - INFO - modeling_roberta - Training sub-loss: O 1.1318930387496948, C 1.1566790342330933, E 1.1272740364074707, A 1.092005729675293, N 1.1117591857910156
06/19/2024 01:38:30 - INFO - modeling_roberta - Training sub-loss: O 1.107257604598999, C 1.143843412399292, E 1.112479567527771, A 1.0849052667617798, N 1.1019961833953857
06/19/2024 01:38:31 - ERROR - root -  30%|###       | 118/390 [06:26<14:42,  3.25s/it]
06/19/2024 01:38:32 - INFO - modeling_roberta - Training sub-loss: O 1.1427018642425537, C 1.04009211063385, E 1.114041805267334, A 1.0935158729553223, N 1.1165955066680908
06/19/2024 01:38:32 - INFO - modeling_roberta - Training sub-loss: O 1.0759506225585938, C 1.1281195878982544, E 1.0866000652313232, A 1.109098196029663, N 1.0891023874282837
06/19/2024 01:38:33 - INFO - modeling_roberta - Training sub-loss: O 1.095170259475708, C 1.1728312969207764, E 1.1062825918197632, A 1.1744773387908936, N 1.0599987506866455
06/19/2024 01:38:33 - INFO - modeling_roberta - Training sub-loss: O 1.1786917448043823, C 1.077780842781067, E 1.1062369346618652, A 1.046989917755127, N 1.1242144107818604
06/19/2024 01:38:34 - ERROR - root -  31%|###       | 119/390 [06:29<14:35,  3.23s/it]
06/19/2024 01:38:35 - INFO - modeling_roberta - Training sub-loss: O 1.1240863800048828, C 1.149412989616394, E 1.115944266319275, A 1.1039071083068848, N 1.1320650577545166
06/19/2024 01:38:35 - INFO - modeling_roberta - Training sub-loss: O 1.0547568798065186, C 1.1564826965332031, E 1.0873439311981201, A 1.0978673696517944, N 1.0409947633743286
06/19/2024 01:38:36 - INFO - modeling_roberta - Training sub-loss: O 1.0810773372650146, C 1.0975635051727295, E 1.1153147220611572, A 1.028184175491333, N 1.1237417459487915
06/19/2024 01:38:37 - INFO - modeling_roberta - Training sub-loss: O 1.0728576183319092, C 1.0608372688293457, E 1.1575002670288086, A 1.0358481407165527, N 1.1458301544189453
06/19/2024 01:38:37 - ERROR - root -  31%|###       | 120/390 [06:33<14:31,  3.23s/it]
06/19/2024 01:38:37 - INFO - root - {'loss': 1.1056, 'grad_norm': 61797.16796875, 'learning_rate': 6.923076923076924e-05, 'epoch': 1.53}
06/19/2024 01:38:38 - ERROR - root -  31%|###       | 120/390 [06:33<14:31,  3.23s/it]
06/19/2024 01:38:38 - INFO - modeling_roberta - Training sub-loss: O 1.0791850090026855, C 1.0698678493499756, E 1.1435273885726929, A 1.1158301830291748, N 1.102921724319458
06/19/2024 01:38:38 - INFO - modeling_roberta - Training sub-loss: O 1.0593842267990112, C 1.1017569303512573, E 1.1305391788482666, A 1.112170696258545, N 1.1225805282592773
06/19/2024 01:38:40 - INFO - modeling_roberta - Training sub-loss: O 1.122449278831482, C 1.0846490859985352, E 1.10600745677948, A 1.1087501049041748, N 1.1278409957885742
06/19/2024 01:38:40 - INFO - modeling_roberta - Training sub-loss: O 1.1516200304031372, C 1.1003377437591553, E 1.1184700727462769, A 1.0828334093093872, N 1.1152859926223755
06/19/2024 01:38:41 - ERROR - root -  31%|###1      | 121/390 [06:36<14:28,  3.23s/it]
06/19/2024 01:38:41 - INFO - modeling_roberta - Training sub-loss: O 1.1277107000350952, C 1.1328421831130981, E 1.0816892385482788, A 1.1224431991577148, N 1.087533950805664
06/19/2024 01:38:41 - INFO - modeling_roberta - Training sub-loss: O 1.0698096752166748, C 1.068436622619629, E 1.0863362550735474, A 1.125678300857544, N 1.096294641494751
06/19/2024 01:38:43 - INFO - modeling_roberta - Training sub-loss: O 1.0789494514465332, C 1.1231259107589722, E 1.0889465808868408, A 1.1439701318740845, N 1.1182527542114258
06/19/2024 01:38:43 - INFO - modeling_roberta - Training sub-loss: O 1.155259609222412, C 1.0899004936218262, E 1.1484538316726685, A 1.102079153060913, N 1.1123380661010742
06/19/2024 01:38:44 - ERROR - root -  31%|###1      | 122/390 [06:39<14:23,  3.22s/it]
06/19/2024 01:38:45 - INFO - modeling_roberta - Training sub-loss: O 1.1415538787841797, C 1.054535150527954, E 1.1004128456115723, A 1.096860647201538, N 1.1066968441009521
06/19/2024 01:38:45 - INFO - modeling_roberta - Training sub-loss: O 1.0820680856704712, C 1.1384479999542236, E 1.1146347522735596, A 1.0958024263381958, N 1.1157703399658203
06/19/2024 01:38:46 - INFO - modeling_roberta - Training sub-loss: O 1.0662240982055664, C 1.1889004707336426, E 1.1161068677902222, A 1.1809279918670654, N 1.095620036125183
06/19/2024 01:38:46 - INFO - modeling_roberta - Training sub-loss: O 1.0863770246505737, C 1.0636768341064453, E 1.0953665971755981, A 1.1086862087249756, N 1.0782177448272705
06/19/2024 01:38:47 - ERROR - root -  32%|###1      | 123/390 [06:42<14:27,  3.25s/it]
06/19/2024 01:38:48 - INFO - modeling_roberta - Training sub-loss: O 1.2149643898010254, C 1.160593867301941, E 1.1356053352355957, A 1.2244434356689453, N 1.1149600744247437
06/19/2024 01:38:48 - INFO - modeling_roberta - Training sub-loss: O 1.0599822998046875, C 1.150153398513794, E 1.1261814832687378, A 1.0782521963119507, N 1.1210429668426514
06/19/2024 01:38:50 - INFO - modeling_roberta - Training sub-loss: O 1.1758897304534912, C 1.138784646987915, E 1.1009856462478638, A 1.1256320476531982, N 1.160647988319397
06/19/2024 01:38:50 - INFO - modeling_roberta - Training sub-loss: O 1.0930510759353638, C 1.0135958194732666, E 1.0870361328125, A 1.1302485466003418, N 1.0903282165527344
06/19/2024 01:38:51 - ERROR - root -  32%|###1      | 124/390 [06:46<14:34,  3.29s/it]
06/19/2024 01:38:51 - INFO - modeling_roberta - Training sub-loss: O 1.1327145099639893, C 1.1290849447250366, E 1.1144856214523315, A 1.1299188137054443, N 1.1042369604110718
06/19/2024 01:38:51 - INFO - modeling_roberta - Training sub-loss: O 1.0831297636032104, C 1.1530345678329468, E 1.0910749435424805, A 1.1289122104644775, N 1.0895357131958008
06/19/2024 01:38:53 - INFO - modeling_roberta - Training sub-loss: O 1.0681143999099731, C 1.183212161064148, E 1.1387587785720825, A 1.0457196235656738, N 1.1440675258636475
06/19/2024 01:38:53 - INFO - modeling_roberta - Training sub-loss: O 1.0897853374481201, C 1.00462007522583, E 1.0886385440826416, A 1.104907751083374, N 1.1085275411605835
06/19/2024 01:38:54 - ERROR - root -  32%|###2      | 125/390 [06:49<14:43,  3.33s/it]
06/19/2024 01:38:55 - INFO - modeling_roberta - Training sub-loss: O 1.137674331665039, C 1.1380953788757324, E 1.109501838684082, A 1.1093273162841797, N 1.091166615486145
06/19/2024 01:38:55 - INFO - modeling_roberta - Training sub-loss: O 1.1102358102798462, C 1.0923125743865967, E 1.1127595901489258, A 1.114241361618042, N 1.1279491186141968
06/19/2024 01:38:56 - INFO - modeling_roberta - Training sub-loss: O 1.101576805114746, C 1.0700256824493408, E 1.0809993743896484, A 1.141974925994873, N 1.061463713645935
06/19/2024 01:38:56 - INFO - modeling_roberta - Training sub-loss: O 1.16227388381958, C 1.0922671556472778, E 1.0810480117797852, A 1.116318702697754, N 1.1188833713531494
06/19/2024 01:38:57 - ERROR - root -  32%|###2      | 126/390 [06:52<14:39,  3.33s/it]
06/19/2024 01:38:58 - INFO - modeling_roberta - Training sub-loss: O 1.1344125270843506, C 1.0913007259368896, E 1.0724575519561768, A 1.1310629844665527, N 1.1094406843185425
06/19/2024 01:38:58 - INFO - modeling_roberta - Training sub-loss: O 1.0618488788604736, C 1.1010684967041016, E 1.1100893020629883, A 1.0895620584487915, N 1.1277363300323486
06/19/2024 01:39:00 - INFO - modeling_roberta - Training sub-loss: O 1.1320407390594482, C 1.0440272092819214, E 1.0628515481948853, A 1.1241341829299927, N 1.1046574115753174
06/19/2024 01:39:00 - INFO - modeling_roberta - Training sub-loss: O 1.1071102619171143, C 1.1134312152862549, E 1.1199626922607422, A 1.118774652481079, N 1.1059733629226685
06/19/2024 01:39:01 - ERROR - root -  33%|###2      | 127/390 [06:56<14:33,  3.32s/it]
06/19/2024 01:39:01 - INFO - modeling_roberta - Training sub-loss: O 1.1842927932739258, C 1.1535944938659668, E 1.1141895055770874, A 1.0932434797286987, N 1.098149299621582
06/19/2024 01:39:01 - INFO - modeling_roberta - Training sub-loss: O 1.1187620162963867, C 1.0716921091079712, E 1.0657775402069092, A 1.0805100202560425, N 1.091478705406189
06/19/2024 01:39:03 - INFO - modeling_roberta - Training sub-loss: O 1.0839452743530273, C 1.161202073097229, E 1.0890958309173584, A 1.1076195240020752, N 1.071368932723999
06/19/2024 01:39:03 - INFO - modeling_roberta - Training sub-loss: O 1.1030164957046509, C 1.0738747119903564, E 1.0905888080596924, A 1.0952767133712769, N 1.1281757354736328
06/19/2024 01:39:04 - ERROR - root -  33%|###2      | 128/390 [06:59<14:36,  3.35s/it]
06/19/2024 01:39:05 - INFO - modeling_roberta - Training sub-loss: O 1.1431913375854492, C 1.1531699895858765, E 1.1042416095733643, A 1.1220624446868896, N 1.0897884368896484
06/19/2024 01:39:05 - INFO - modeling_roberta - Training sub-loss: O 1.0624967813491821, C 1.1324193477630615, E 1.1378157138824463, A 1.1072790622711182, N 1.076892614364624
06/19/2024 01:39:06 - INFO - modeling_roberta - Training sub-loss: O 1.0979318618774414, C 1.1274404525756836, E 1.1270630359649658, A 1.1022826433181763, N 1.1183137893676758
06/19/2024 01:39:07 - INFO - modeling_roberta - Training sub-loss: O 1.1421090364456177, C 1.151648998260498, E 1.1276144981384277, A 1.128117322921753, N 1.122802972793579
06/19/2024 01:39:08 - ERROR - root -  33%|###3      | 129/390 [07:03<14:41,  3.38s/it]
06/19/2024 01:39:08 - INFO - modeling_roberta - Training sub-loss: O 1.1090492010116577, C 1.1191208362579346, E 1.1295251846313477, A 1.1083040237426758, N 1.0955805778503418
06/19/2024 01:39:08 - INFO - modeling_roberta - Training sub-loss: O 1.0627093315124512, C 1.0316696166992188, E 1.1120368242263794, A 1.0710358619689941, N 1.0807456970214844
06/19/2024 01:39:10 - INFO - modeling_roberta - Training sub-loss: O 1.1255888938903809, C 1.0965906381607056, E 1.1369447708129883, A 1.1527131795883179, N 1.1232128143310547
06/19/2024 01:39:10 - INFO - modeling_roberta - Training sub-loss: O 1.1013941764831543, C 1.0790642499923706, E 1.1513311862945557, A 1.054232120513916, N 1.0961925983428955
06/19/2024 01:39:11 - ERROR - root -  33%|###3      | 130/390 [07:06<14:41,  3.39s/it]
06/19/2024 01:39:11 - INFO - root - {'loss': 1.109, 'grad_norm': 78689.515625, 'learning_rate': 6.666666666666667e-05, 'epoch': 1.66}
06/19/2024 01:39:11 - ERROR - root -  33%|###3      | 130/390 [07:06<14:41,  3.39s/it]
06/19/2024 01:39:12 - INFO - modeling_roberta - Training sub-loss: O 1.099954605102539, C 1.068339467048645, E 1.1439272165298462, A 1.0740529298782349, N 1.1553977727890015
06/19/2024 01:39:12 - INFO - modeling_roberta - Training sub-loss: O 1.1286981105804443, C 1.1160578727722168, E 1.091439962387085, A 1.1323840618133545, N 1.0873357057571411
06/19/2024 01:39:13 - INFO - modeling_roberta - Training sub-loss: O 1.0638244152069092, C 1.092327356338501, E 1.1375467777252197, A 1.1008967161178589, N 1.1254353523254395
06/19/2024 01:39:13 - INFO - modeling_roberta - Training sub-loss: O 1.0725836753845215, C 1.0829885005950928, E 1.1082143783569336, A 1.126732587814331, N 1.065904140472412
06/19/2024 01:39:14 - ERROR - root -  34%|###3      | 131/390 [07:09<14:38,  3.39s/it]
06/19/2024 01:39:15 - INFO - modeling_roberta - Training sub-loss: O 1.1544013023376465, C 1.1079366207122803, E 1.1056814193725586, A 1.1028645038604736, N 1.1141715049743652
06/19/2024 01:39:15 - INFO - modeling_roberta - Training sub-loss: O 1.1314747333526611, C 1.129500389099121, E 1.0774266719818115, A 1.0709110498428345, N 1.1362158060073853
06/19/2024 01:39:17 - INFO - modeling_roberta - Training sub-loss: O 1.142939567565918, C 1.113836646080017, E 1.1255515813827515, A 1.1235815286636353, N 1.0394288301467896
06/19/2024 01:39:17 - INFO - modeling_roberta - Training sub-loss: O 1.112546682357788, C 1.0875524282455444, E 1.1320509910583496, A 1.1287603378295898, N 1.120184063911438
06/19/2024 01:39:18 - ERROR - root -  34%|###3      | 132/390 [07:13<14:39,  3.41s/it]
06/19/2024 01:39:19 - INFO - modeling_roberta - Training sub-loss: O 1.1573065519332886, C 1.1216020584106445, E 1.1048438549041748, A 1.1145694255828857, N 1.1698698997497559
06/19/2024 01:39:19 - INFO - modeling_roberta - Training sub-loss: O 1.0596022605895996, C 1.1234965324401855, E 1.1448673009872437, A 1.120879054069519, N 1.0721489191055298
06/19/2024 01:39:20 - INFO - modeling_roberta - Training sub-loss: O 1.0577583312988281, C 1.1154506206512451, E 1.0923359394073486, A 1.074084997177124, N 1.10935378074646
06/19/2024 01:39:20 - INFO - modeling_roberta - Training sub-loss: O 1.0700898170471191, C 1.0867085456848145, E 1.131467342376709, A 1.1190885305404663, N 1.07589590549469
06/19/2024 01:39:21 - ERROR - root -  34%|###4      | 133/390 [07:16<14:41,  3.43s/it]
06/19/2024 01:39:22 - INFO - modeling_roberta - Training sub-loss: O 1.142310380935669, C 1.0476027727127075, E 1.067779541015625, A 1.1577951908111572, N 1.1332905292510986
06/19/2024 01:39:22 - INFO - modeling_roberta - Training sub-loss: O 1.0411150455474854, C 1.0934228897094727, E 1.124626874923706, A 1.1063019037246704, N 1.086424708366394
06/19/2024 01:39:24 - INFO - modeling_roberta - Training sub-loss: O 1.0966205596923828, C 1.122999906539917, E 1.092646837234497, A 1.1293458938598633, N 1.0947743654251099
06/19/2024 01:39:24 - INFO - modeling_roberta - Training sub-loss: O 1.0486019849777222, C 1.0761164426803589, E 1.1112345457077026, A 1.1638184785842896, N 1.130445122718811
06/19/2024 01:39:25 - ERROR - root -  34%|###4      | 134/390 [07:20<14:31,  3.40s/it]
06/19/2024 01:39:25 - INFO - modeling_roberta - Training sub-loss: O 1.1037559509277344, C 1.1080546379089355, E 1.1112350225448608, A 1.111701488494873, N 1.1057902574539185
06/19/2024 01:39:25 - INFO - modeling_roberta - Training sub-loss: O 1.070768117904663, C 1.0733628273010254, E 1.087421178817749, A 1.0948235988616943, N 1.1009385585784912
06/19/2024 01:39:27 - INFO - modeling_roberta - Training sub-loss: O 1.0414905548095703, C 1.126084804534912, E 1.0911613702774048, A 1.0807645320892334, N 1.0878324508666992
06/19/2024 01:39:27 - INFO - modeling_roberta - Training sub-loss: O 1.1114115715026855, C 1.1104713678359985, E 1.0980759859085083, A 1.193535327911377, N 1.0823885202407837
06/19/2024 01:39:28 - ERROR - root -  35%|###4      | 135/390 [07:23<14:27,  3.40s/it]
06/19/2024 01:39:29 - INFO - modeling_roberta - Training sub-loss: O 1.0455785989761353, C 1.1121183633804321, E 1.1028671264648438, A 1.1152019500732422, N 1.087923288345337
06/19/2024 01:39:29 - INFO - modeling_roberta - Training sub-loss: O 1.114141821861267, C 1.0836877822875977, E 1.1216213703155518, A 1.1020770072937012, N 1.0883781909942627
06/19/2024 01:39:30 - INFO - modeling_roberta - Training sub-loss: O 1.1474148035049438, C 1.1573845148086548, E 1.1299103498458862, A 1.08730149269104, N 1.1160502433776855
06/19/2024 01:39:30 - INFO - modeling_roberta - Training sub-loss: O 1.0969371795654297, C 1.1472089290618896, E 1.0986130237579346, A 1.1245577335357666, N 1.1028112173080444
06/19/2024 01:39:31 - ERROR - root -  35%|###4      | 136/390 [07:26<14:16,  3.37s/it]
06/19/2024 01:39:32 - INFO - modeling_roberta - Training sub-loss: O 1.1178045272827148, C 1.10476553440094, E 1.1370015144348145, A 1.090609073638916, N 1.100210428237915
06/19/2024 01:39:32 - INFO - modeling_roberta - Training sub-loss: O 1.0607316493988037, C 1.0904206037521362, E 1.1165876388549805, A 1.1228907108306885, N 1.102219820022583
06/19/2024 01:39:34 - INFO - modeling_roberta - Training sub-loss: O 1.1190452575683594, C 1.1020851135253906, E 1.136583924293518, A 1.1034858226776123, N 1.1006298065185547
06/19/2024 01:39:34 - INFO - modeling_roberta - Training sub-loss: O 1.1584961414337158, C 1.1230108737945557, E 1.117248296737671, A 1.144946813583374, N 1.1384378671646118
06/19/2024 01:39:35 - ERROR - root -  35%|###5      | 137/390 [07:30<14:04,  3.34s/it]
06/19/2024 01:39:35 - INFO - modeling_roberta - Training sub-loss: O 1.1181021928787231, C 1.1204652786254883, E 1.1440327167510986, A 1.1464319229125977, N 1.0436286926269531
06/19/2024 01:39:35 - INFO - modeling_roberta - Training sub-loss: O 1.157280445098877, C 1.1366512775421143, E 1.0766123533248901, A 1.116279125213623, N 1.1148269176483154
06/19/2024 01:39:37 - INFO - modeling_roberta - Training sub-loss: O 1.1049270629882812, C 1.0472710132598877, E 1.1518590450286865, A 1.078421950340271, N 1.1319332122802734
06/19/2024 01:39:37 - INFO - modeling_roberta - Training sub-loss: O 1.1023435592651367, C 1.1185195446014404, E 1.1110594272613525, A 1.116459846496582, N 1.095503330230713
06/19/2024 01:39:38 - ERROR - root -  35%|###5      | 138/390 [07:33<13:51,  3.30s/it]
06/19/2024 01:39:39 - INFO - modeling_roberta - Training sub-loss: O 1.1187546253204346, C 1.0913476943969727, E 1.1355959177017212, A 1.102035403251648, N 1.1052539348602295
06/19/2024 01:39:39 - INFO - modeling_roberta - Training sub-loss: O 1.0604878664016724, C 1.0845141410827637, E 1.0474648475646973, A 1.1056396961212158, N 1.0452892780303955
06/19/2024 01:39:40 - INFO - modeling_roberta - Training sub-loss: O 1.083070158958435, C 1.087676763534546, E 1.1028361320495605, A 1.1083674430847168, N 1.0964148044586182
06/19/2024 01:39:40 - INFO - modeling_roberta - Training sub-loss: O 1.1546971797943115, C 1.1377296447753906, E 1.0737805366516113, A 1.0638149976730347, N 1.152539849281311
06/19/2024 01:39:41 - ERROR - root -  36%|###5      | 139/390 [07:36<14:02,  3.36s/it]
06/19/2024 01:39:42 - INFO - modeling_roberta - Training sub-loss: O 1.1061497926712036, C 1.0879764556884766, E 1.098475694656372, A 1.0903180837631226, N 1.0628973245620728
06/19/2024 01:39:42 - INFO - modeling_roberta - Training sub-loss: O 1.1154656410217285, C 1.1391451358795166, E 1.1409766674041748, A 1.1101038455963135, N 1.082161545753479
06/19/2024 01:39:44 - INFO - modeling_roberta - Training sub-loss: O 1.1790488958358765, C 1.1042388677597046, E 1.0819662809371948, A 1.0944188833236694, N 1.1216611862182617
06/19/2024 01:39:44 - INFO - modeling_roberta - Training sub-loss: O 1.0795574188232422, C 1.0633773803710938, E 1.1274094581604004, A 1.0727410316467285, N 1.121904969215393
06/19/2024 01:39:44 - ERROR - root -  36%|###5      | 140/390 [07:40<13:46,  3.31s/it]
06/19/2024 01:39:44 - INFO - root - {'loss': 1.1062, 'grad_norm': 78476.2734375, 'learning_rate': 6.410256410256412e-05, 'epoch': 1.78}
06/19/2024 01:39:44 - ERROR - root -  36%|###5      | 140/390 [07:40<13:46,  3.31s/it]
06/19/2024 01:39:45 - INFO - modeling_roberta - Training sub-loss: O 1.091612696647644, C 1.125267505645752, E 1.0716453790664673, A 1.0500514507293701, N 1.1141889095306396
06/19/2024 01:39:45 - INFO - modeling_roberta - Training sub-loss: O 1.1007261276245117, C 1.1465306282043457, E 1.1249760389328003, A 1.0969688892364502, N 1.058959722518921
06/19/2024 01:39:47 - INFO - modeling_roberta - Training sub-loss: O 1.1154160499572754, C 1.126810073852539, E 1.0567090511322021, A 1.1190719604492188, N 1.1428699493408203
06/19/2024 01:39:47 - INFO - modeling_roberta - Training sub-loss: O 1.0893168449401855, C 1.0781347751617432, E 1.1263010501861572, A 1.1033210754394531, N 1.1330474615097046
06/19/2024 01:39:48 - ERROR - root -  36%|###6      | 141/390 [07:43<13:34,  3.27s/it]
06/19/2024 01:39:48 - INFO - modeling_roberta - Training sub-loss: O 1.1470445394515991, C 1.1193767786026, E 1.0330196619033813, A 1.087080478668213, N 1.1155931949615479
06/19/2024 01:39:48 - INFO - modeling_roberta - Training sub-loss: O 1.0986199378967285, C 1.1564898490905762, E 1.1026511192321777, A 1.0725429058074951, N 1.069016933441162
06/19/2024 01:39:50 - INFO - modeling_roberta - Training sub-loss: O 1.1112133264541626, C 1.086677074432373, E 1.0751867294311523, A 1.0828360319137573, N 1.0900206565856934
06/19/2024 01:39:50 - INFO - modeling_roberta - Training sub-loss: O 1.0871682167053223, C 1.096845030784607, E 1.1016056537628174, A 1.1309564113616943, N 1.1182912588119507
06/19/2024 01:39:51 - ERROR - root -  36%|###6      | 142/390 [07:46<13:24,  3.24s/it]
06/19/2024 01:39:51 - INFO - modeling_roberta - Training sub-loss: O 1.145241379737854, C 1.1118190288543701, E 1.1024762392044067, A 1.1787474155426025, N 1.0928974151611328
06/19/2024 01:39:52 - INFO - modeling_roberta - Training sub-loss: O 1.081850528717041, C 1.091103434562683, E 1.085505723953247, A 1.1098856925964355, N 1.0803030729293823
06/19/2024 01:39:53 - INFO - modeling_roberta - Training sub-loss: O 1.0612831115722656, C 1.0902047157287598, E 1.0683002471923828, A 1.060093879699707, N 1.1364647150039673
06/19/2024 01:39:53 - INFO - modeling_roberta - Training sub-loss: O 1.0959889888763428, C 1.1157071590423584, E 1.1041338443756104, A 1.1141163110733032, N 1.0757123231887817
06/19/2024 01:39:54 - ERROR - root -  37%|###6      | 143/390 [07:49<13:17,  3.23s/it]
06/19/2024 01:39:55 - INFO - modeling_roberta - Training sub-loss: O 1.1301193237304688, C 1.102735161781311, E 1.0773744583129883, A 1.1175886392593384, N 1.1089686155319214
06/19/2024 01:39:55 - INFO - modeling_roberta - Training sub-loss: O 1.1096792221069336, C 1.1211574077606201, E 1.1327078342437744, A 1.1381704807281494, N 1.1065449714660645
06/19/2024 01:39:56 - INFO - modeling_roberta - Training sub-loss: O 1.0557401180267334, C 1.1356374025344849, E 1.1225285530090332, A 1.153841495513916, N 1.0652270317077637
06/19/2024 01:39:56 - INFO - modeling_roberta - Training sub-loss: O 1.0848441123962402, C 1.0776433944702148, E 1.1097911596298218, A 1.1049070358276367, N 1.0953880548477173
06/19/2024 01:39:57 - ERROR - root -  37%|###6      | 144/390 [07:52<13:13,  3.22s/it]
06/19/2024 01:39:58 - INFO - modeling_roberta - Training sub-loss: O 1.1394028663635254, C 1.0647252798080444, E 1.0829154253005981, A 1.0992568731307983, N 1.0981649160385132
06/19/2024 01:39:58 - INFO - modeling_roberta - Training sub-loss: O 1.1249380111694336, C 1.0574281215667725, E 1.1042468547821045, A 1.1129727363586426, N 1.1281349658966064
06/19/2024 01:39:59 - INFO - modeling_roberta - Training sub-loss: O 1.119910717010498, C 1.0595815181732178, E 1.0749231576919556, A 1.0755866765975952, N 1.094740390777588
06/19/2024 01:39:59 - INFO - modeling_roberta - Training sub-loss: O 1.1038892269134521, C 1.1091681718826294, E 1.1240347623825073, A 1.104601263999939, N 1.1140600442886353
06/19/2024 01:40:00 - ERROR - root -  37%|###7      | 145/390 [07:55<13:08,  3.22s/it]
06/19/2024 01:40:01 - INFO - modeling_roberta - Training sub-loss: O 1.0395090579986572, C 1.047587513923645, E 1.0802733898162842, A 1.0826224088668823, N 1.0765483379364014
06/19/2024 01:40:01 - INFO - modeling_roberta - Training sub-loss: O 1.0525438785552979, C 1.111302137374878, E 1.137641429901123, A 1.0782004594802856, N 1.1167188882827759
06/19/2024 01:40:03 - INFO - modeling_roberta - Training sub-loss: O 1.0834944248199463, C 1.082848310470581, E 1.1231091022491455, A 1.100538969039917, N 1.0635318756103516
06/19/2024 01:40:03 - INFO - modeling_roberta - Training sub-loss: O 1.1218900680541992, C 1.1545499563217163, E 1.1333216428756714, A 1.1076395511627197, N 1.1499717235565186
06/19/2024 01:40:04 - ERROR - root -  37%|###7      | 146/390 [07:59<13:03,  3.21s/it]
06/19/2024 01:40:04 - INFO - modeling_roberta - Training sub-loss: O 1.1196552515029907, C 1.0946818590164185, E 1.0687956809997559, A 1.1461496353149414, N 1.107999324798584
06/19/2024 01:40:04 - INFO - modeling_roberta - Training sub-loss: O 1.0899717807769775, C 1.0982978343963623, E 1.1149235963821411, A 1.0943105220794678, N 1.1200125217437744
06/19/2024 01:40:06 - INFO - modeling_roberta - Training sub-loss: O 1.0896624326705933, C 1.143792986869812, E 1.120672345161438, A 1.077533483505249, N 1.1011784076690674
06/19/2024 01:40:06 - INFO - modeling_roberta - Training sub-loss: O 1.1422152519226074, C 1.0997430086135864, E 1.1137959957122803, A 1.1877541542053223, N 1.0800561904907227
06/19/2024 01:40:07 - ERROR - root -  38%|###7      | 147/390 [08:02<12:59,  3.21s/it]
06/19/2024 01:40:08 - INFO - modeling_roberta - Training sub-loss: O 1.0906847715377808, C 1.1180698871612549, E 1.1026206016540527, A 1.1372590065002441, N 1.0335345268249512
06/19/2024 01:40:08 - INFO - modeling_roberta - Training sub-loss: O 1.0842769145965576, C 1.1393084526062012, E 1.0816336870193481, A 1.1483969688415527, N 1.1260040998458862
06/19/2024 01:40:09 - INFO - modeling_roberta - Training sub-loss: O 1.0924537181854248, C 1.0810540914535522, E 1.1315464973449707, A 1.1087522506713867, N 1.0718047618865967
06/19/2024 01:40:09 - INFO - modeling_roberta - Training sub-loss: O 1.150301218032837, C 1.1256370544433594, E 1.037366271018982, A 1.064507007598877, N 1.0864198207855225
06/19/2024 01:40:10 - ERROR - root -  38%|###7      | 148/390 [08:05<12:56,  3.21s/it]
06/19/2024 01:40:11 - INFO - modeling_roberta - Training sub-loss: O 1.118876576423645, C 1.081190824508667, E 1.1337251663208008, A 1.0871517658233643, N 1.131575345993042
06/19/2024 01:40:11 - INFO - modeling_roberta - Training sub-loss: O 1.1563156843185425, C 1.1131744384765625, E 1.0696767568588257, A 1.0955506563186646, N 1.116859793663025
06/19/2024 01:40:12 - INFO - modeling_roberta - Training sub-loss: O 1.1632992029190063, C 1.0916283130645752, E 1.1059892177581787, A 1.048736572265625, N 1.1349208354949951
06/19/2024 01:40:12 - INFO - modeling_roberta - Training sub-loss: O 1.1173193454742432, C 1.0801030397415161, E 1.085998773574829, A 1.1061214208602905, N 1.068284034729004
06/19/2024 01:40:13 - ERROR - root -  38%|###8      | 149/390 [08:08<12:52,  3.20s/it]
06/19/2024 01:40:14 - INFO - modeling_roberta - Training sub-loss: O 1.1285836696624756, C 1.164503812789917, E 1.128791332244873, A 1.138000726699829, N 1.1034166812896729
06/19/2024 01:40:14 - INFO - modeling_roberta - Training sub-loss: O 1.1595805883407593, C 1.0426549911499023, E 1.049985408782959, A 1.0760570764541626, N 1.1007543802261353
06/19/2024 01:40:15 - INFO - modeling_roberta - Training sub-loss: O 1.0522332191467285, C 1.1298059225082397, E 1.114580750465393, A 1.050826072692871, N 1.1211483478546143
06/19/2024 01:40:15 - INFO - modeling_roberta - Training sub-loss: O 1.121607780456543, C 1.1503551006317139, E 1.0940800905227661, A 1.115943193435669, N 1.0688227415084839
06/19/2024 01:40:16 - ERROR - root -  38%|###8      | 150/390 [08:11<12:47,  3.20s/it]
06/19/2024 01:40:16 - INFO - root - {'loss': 1.1029, 'grad_norm': 82933.125, 'learning_rate': 6.153846153846155e-05, 'epoch': 1.91}
06/19/2024 01:40:16 - ERROR - root -  38%|###8      | 150/390 [08:11<12:47,  3.20s/it]
06/19/2024 01:40:17 - INFO - modeling_roberta - Training sub-loss: O 1.108635663986206, C 1.0840284824371338, E 1.0766491889953613, A 1.0672106742858887, N 1.0390161275863647
06/19/2024 01:40:17 - INFO - modeling_roberta - Training sub-loss: O 1.1068083047866821, C 1.1119279861450195, E 1.1442232131958008, A 1.0973575115203857, N 1.0889612436294556
06/19/2024 01:40:19 - INFO - modeling_roberta - Training sub-loss: O 1.1599363088607788, C 1.1307517290115356, E 1.0695812702178955, A 1.1092568635940552, N 1.1215012073516846
06/19/2024 01:40:19 - INFO - modeling_roberta - Training sub-loss: O 1.1600637435913086, C 1.1326630115509033, E 1.0504733324050903, A 1.1032664775848389, N 1.120471477508545
06/19/2024 01:40:20 - ERROR - root -  39%|###8      | 151/390 [08:15<12:44,  3.20s/it]
06/19/2024 01:40:20 - INFO - modeling_roberta - Training sub-loss: O 1.012658953666687, C 1.1163396835327148, E 1.0411417484283447, A 1.094961166381836, N 1.1152682304382324
06/19/2024 01:40:20 - INFO - modeling_roberta - Training sub-loss: O 1.1240410804748535, C 1.0711033344268799, E 1.0633209943771362, A 1.0705764293670654, N 1.2399015426635742
06/19/2024 01:40:22 - INFO - modeling_roberta - Training sub-loss: O 1.135848045349121, C 1.0742312669754028, E 1.1053569316864014, A 1.0731490850448608, N 1.1390855312347412
06/19/2024 01:40:22 - INFO - modeling_roberta - Training sub-loss: O 1.150796890258789, C 1.0460022687911987, E 1.0912516117095947, A 1.0501961708068848, N 1.054377555847168
06/19/2024 01:40:23 - ERROR - root -  39%|###8      | 152/390 [08:18<12:40,  3.19s/it]
06/19/2024 01:40:23 - INFO - modeling_roberta - Training sub-loss: O 1.109303593635559, C 1.0873374938964844, E 1.0776463747024536, A 1.0717430114746094, N 1.113130807876587
06/19/2024 01:40:23 - INFO - modeling_roberta - Training sub-loss: O 1.1186769008636475, C 1.0559699535369873, E 1.1519083976745605, A 1.121530532836914, N 1.121251106262207
06/19/2024 01:40:25 - INFO - modeling_roberta - Training sub-loss: O 1.085606336593628, C 1.1141270399093628, E 1.0859352350234985, A 1.075888752937317, N 1.0958993434906006
06/19/2024 01:40:25 - INFO - modeling_roberta - Training sub-loss: O 1.1462769508361816, C 1.076823115348816, E 1.129836082458496, A 1.0996071100234985, N 1.1443427801132202
06/19/2024 01:40:26 - ERROR - root -  39%|###9      | 153/390 [08:21<12:36,  3.19s/it]
06/19/2024 01:40:27 - INFO - modeling_roberta - Training sub-loss: O 1.1732192039489746, C 1.1109046936035156, E 1.166517734527588, A 1.077892780303955, N 1.1139485836029053
06/19/2024 01:40:27 - INFO - modeling_roberta - Training sub-loss: O 1.1282219886779785, C 1.0916211605072021, E 1.0491983890533447, A 1.1273466348648071, N 1.105029582977295
06/19/2024 01:40:28 - INFO - modeling_roberta - Training sub-loss: O 1.0853185653686523, C 1.114325761795044, E 1.0430711507797241, A 1.0880829095840454, N 1.1017801761627197
06/19/2024 01:40:28 - INFO - modeling_roberta - Training sub-loss: O 1.1650209426879883, C 1.1208648681640625, E 1.0982043743133545, A 1.1372954845428467, N 1.123366355895996
06/19/2024 01:40:29 - ERROR - root -  39%|###9      | 154/390 [08:24<12:33,  3.19s/it]
06/19/2024 01:40:30 - INFO - modeling_roberta - Training sub-loss: O 1.131838083267212, C 1.158618450164795, E 1.1288330554962158, A 1.1377248764038086, N 1.1150091886520386
06/19/2024 01:40:30 - INFO - modeling_roberta - Training sub-loss: O 1.0897769927978516, C 1.1133174896240234, E 1.127862572669983, A 1.0988513231277466, N 1.0697574615478516
06/19/2024 01:40:31 - INFO - modeling_roberta - Training sub-loss: O 1.0844643115997314, C 1.0607891082763672, E 1.1015219688415527, A 1.1559996604919434, N 1.1190383434295654
06/19/2024 01:40:31 - INFO - modeling_roberta - Training sub-loss: O 1.0707716941833496, C 1.1022156476974487, E 1.116485357284546, A 1.1205594539642334, N 1.1396880149841309
06/19/2024 01:40:32 - ERROR - root -  40%|###9      | 155/390 [08:27<12:30,  3.19s/it]
06/19/2024 01:40:33 - INFO - modeling_roberta - Training sub-loss: O 1.141730546951294, C 1.113743782043457, E 1.1759700775146484, A 1.1024123430252075, N 1.127928376197815
06/19/2024 01:40:33 - INFO - modeling_roberta - Training sub-loss: O 1.0751490592956543, C 1.1139848232269287, E 1.144140362739563, A 1.0685949325561523, N 1.1004111766815186
06/19/2024 01:40:35 - INFO - modeling_roberta - Training sub-loss: O 1.0660566091537476, C 1.043789029121399, E 1.1094598770141602, A 1.0911500453948975, N 1.1461951732635498
06/19/2024 01:40:35 - INFO - modeling_roberta - Training sub-loss: O 1.1135209798812866, C 1.1264219284057617, E 1.0852007865905762, A 1.090778112411499, N 1.0913159847259521
06/19/2024 01:40:36 - ERROR - root -  40%|####      | 156/390 [08:31<12:26,  3.19s/it]
06/19/2024 01:40:36 - INFO - modeling_roberta - Training sub-loss: O 1.1546621322631836, C 1.0952796936035156, E 1.1164441108703613, A 1.1160235404968262, N 1.1510584354400635
06/19/2024 01:40:36 - INFO - modeling_roberta - Training sub-loss: O 1.103580117225647, C 1.0940147638320923, E 1.1554858684539795, A 1.1201577186584473, N 1.1228313446044922
06/19/2024 01:40:38 - INFO - modeling_roberta - Training sub-loss: O 1.1561906337738037, C 1.1359474658966064, E 1.2016704082489014, A 1.053520917892456, N 1.1556724309921265
06/19/2024 01:40:38 - INFO - modeling_roberta - Training sub-loss: O 1.0294206142425537, C 1.1243531703948975, E 1.0360298156738281, A 1.1398202180862427, N 1.0911122560501099
06/19/2024 01:40:38 - ERROR - root -  40%|####      | 157/390 [08:33<11:47,  3.03s/it]
06/19/2024 01:40:39 - INFO - modeling_roberta - Training sub-loss: O 1.0902831554412842, C 1.0877971649169922, E 1.1175203323364258, A 1.1353284120559692, N 1.1057307720184326
06/19/2024 01:40:39 - INFO - modeling_roberta - Training sub-loss: O 1.1234614849090576, C 1.1009695529937744, E 0.9951158761978149, A 1.07063627243042, N 1.123305320739746
06/19/2024 01:40:41 - INFO - modeling_roberta - Training sub-loss: O 1.1118414402008057, C 1.0550999641418457, E 1.1394293308258057, A 1.1165767908096313, N 1.092409610748291
06/19/2024 01:40:41 - INFO - modeling_roberta - Training sub-loss: O 1.1047050952911377, C 1.0792102813720703, E 1.1153584718704224, A 1.087767481803894, N 1.1374657154083252
06/19/2024 01:40:42 - ERROR - root -  41%|####      | 158/390 [08:37<12:33,  3.25s/it]
06/19/2024 01:40:43 - INFO - modeling_roberta - Training sub-loss: O 1.0297836065292358, C 1.1400041580200195, E 1.1070842742919922, A 1.097632646560669, N 1.1462175846099854
06/19/2024 01:40:43 - INFO - modeling_roberta - Training sub-loss: O 1.1542367935180664, C 1.070847988128662, E 1.1391942501068115, A 1.1206789016723633, N 1.139776349067688
06/19/2024 01:40:44 - INFO - modeling_roberta - Training sub-loss: O 1.0883667469024658, C 1.122018575668335, E 1.1429376602172852, A 1.1083025932312012, N 1.132051706314087
06/19/2024 01:40:44 - INFO - modeling_roberta - Training sub-loss: O 1.1126694679260254, C 1.0783663988113403, E 1.0901343822479248, A 1.1156812906265259, N 1.0953025817871094
06/19/2024 01:40:45 - ERROR - root -  41%|####      | 159/390 [08:40<12:27,  3.24s/it]
06/19/2024 01:40:46 - INFO - modeling_roberta - Training sub-loss: O 1.1194226741790771, C 1.0979499816894531, E 1.0728816986083984, A 1.1315594911575317, N 1.0936496257781982
06/19/2024 01:40:46 - INFO - modeling_roberta - Training sub-loss: O 1.0914514064788818, C 1.1106986999511719, E 1.1175750494003296, A 1.1110233068466187, N 1.1010626554489136
06/19/2024 01:40:47 - INFO - modeling_roberta - Training sub-loss: O 1.1134356260299683, C 1.0631227493286133, E 1.2016210556030273, A 1.0761239528656006, N 1.0987091064453125
06/19/2024 01:40:47 - INFO - modeling_roberta - Training sub-loss: O 1.1299986839294434, C 1.0620719194412231, E 1.0705639123916626, A 1.0934327840805054, N 1.0903022289276123
06/19/2024 01:40:48 - ERROR - root -  41%|####1     | 160/390 [08:43<12:21,  3.22s/it]
06/19/2024 01:40:48 - INFO - root - {'loss': 1.1062, 'grad_norm': 85521.53125, 'learning_rate': 5.897435897435898e-05, 'epoch': 2.04}
06/19/2024 01:40:48 - ERROR - root -  41%|####1     | 160/390 [08:43<12:21,  3.22s/it]
06/19/2024 01:40:49 - INFO - modeling_roberta - Training sub-loss: O 1.1171388626098633, C 1.1197062730789185, E 1.080000400543213, A 1.090688943862915, N 1.0835862159729004
06/19/2024 01:40:49 - INFO - modeling_roberta - Training sub-loss: O 1.0823047161102295, C 1.101509928703308, E 1.0752570629119873, A 1.1195882558822632, N 1.0799527168273926
06/19/2024 01:40:51 - INFO - modeling_roberta - Training sub-loss: O 1.0585808753967285, C 1.1095356941223145, E 1.1122276782989502, A 1.0734403133392334, N 1.0852775573730469
06/19/2024 01:40:51 - INFO - modeling_roberta - Training sub-loss: O 1.0940276384353638, C 1.0688363313674927, E 1.1036925315856934, A 1.148589015007019, N 1.087764024734497
06/19/2024 01:40:52 - ERROR - root -  41%|####1     | 161/390 [08:47<12:27,  3.26s/it]
06/19/2024 01:40:52 - INFO - modeling_roberta - Training sub-loss: O 1.1010210514068604, C 1.0974950790405273, E 1.079674482345581, A 1.0975944995880127, N 1.1230347156524658
06/19/2024 01:40:52 - INFO - modeling_roberta - Training sub-loss: O 1.0485727787017822, C 1.133237361907959, E 1.1056053638458252, A 1.0925637483596802, N 1.1052961349487305
06/19/2024 01:40:54 - INFO - modeling_roberta - Training sub-loss: O 1.086812973022461, C 1.1163592338562012, E 1.0343296527862549, A 1.1090693473815918, N 1.105675220489502
06/19/2024 01:40:54 - INFO - modeling_roberta - Training sub-loss: O 1.0975267887115479, C 1.0772287845611572, E 1.055760145187378, A 1.1013383865356445, N 1.0716769695281982
06/19/2024 01:40:55 - ERROR - root -  42%|####1     | 162/390 [08:50<12:24,  3.26s/it]
06/19/2024 01:40:56 - INFO - modeling_roberta - Training sub-loss: O 1.1261833906173706, C 1.0427769422531128, E 1.0961081981658936, A 1.1088322401046753, N 1.1203641891479492
06/19/2024 01:40:56 - INFO - modeling_roberta - Training sub-loss: O 1.1369330883026123, C 1.0991802215576172, E 1.1098365783691406, A 1.0710200071334839, N 1.0700255632400513
06/19/2024 01:40:57 - INFO - modeling_roberta - Training sub-loss: O 1.1695234775543213, C 1.1342322826385498, E 1.1765294075012207, A 1.1096289157867432, N 1.0777370929718018
06/19/2024 01:40:57 - INFO - modeling_roberta - Training sub-loss: O 1.071528434753418, C 1.122503638267517, E 1.0433743000030518, A 1.1280522346496582, N 1.089803695678711
06/19/2024 01:40:58 - ERROR - root -  42%|####1     | 163/390 [08:53<12:24,  3.28s/it]
06/19/2024 01:40:59 - INFO - modeling_roberta - Training sub-loss: O 1.1470993757247925, C 1.1138980388641357, E 1.1147048473358154, A 1.0685741901397705, N 1.0881314277648926
06/19/2024 01:40:59 - INFO - modeling_roberta - Training sub-loss: O 1.0860272645950317, C 1.0533294677734375, E 1.127990484237671, A 1.084575891494751, N 1.1269007921218872
06/19/2024 01:41:01 - INFO - modeling_roberta - Training sub-loss: O 1.1017827987670898, C 1.0787546634674072, E 1.131052851676941, A 1.119666337966919, N 1.1234432458877563
06/19/2024 01:41:01 - INFO - modeling_roberta - Training sub-loss: O 1.0535097122192383, C 1.1084526777267456, E 1.1150137186050415, A 1.0793375968933105, N 1.071359395980835
06/19/2024 01:41:02 - ERROR - root -  42%|####2     | 164/390 [08:57<12:17,  3.26s/it]
06/19/2024 01:41:03 - INFO - modeling_roberta - Training sub-loss: O 1.1119492053985596, C 1.135313630104065, E 1.0824966430664062, A 1.1228976249694824, N 1.0343620777130127
06/19/2024 01:41:03 - INFO - modeling_roberta - Training sub-loss: O 1.0971202850341797, C 1.1197690963745117, E 1.1052147150039673, A 1.095232605934143, N 1.128277063369751
06/19/2024 01:41:04 - INFO - modeling_roberta - Training sub-loss: O 1.1132102012634277, C 1.0908777713775635, E 1.1286611557006836, A 1.0869463682174683, N 1.1199573278427124
06/19/2024 01:41:04 - INFO - modeling_roberta - Training sub-loss: O 1.08597993850708, C 1.1086523532867432, E 1.0860956907272339, A 1.122479796409607, N 1.0764349699020386
06/19/2024 01:41:05 - ERROR - root -  42%|####2     | 165/390 [09:00<12:46,  3.41s/it]
06/19/2024 01:41:06 - INFO - modeling_roberta - Training sub-loss: O 1.1145472526550293, C 1.0648772716522217, E 1.1249208450317383, A 1.151308536529541, N 1.1475059986114502
06/19/2024 01:41:06 - INFO - modeling_roberta - Training sub-loss: O 1.0681750774383545, C 1.1473411321640015, E 1.015415906906128, A 1.1395165920257568, N 1.1383838653564453
06/19/2024 01:41:08 - INFO - modeling_roberta - Training sub-loss: O 1.105018138885498, C 1.0815651416778564, E 1.084712266921997, A 1.1040830612182617, N 1.0753576755523682
06/19/2024 01:41:08 - INFO - modeling_roberta - Training sub-loss: O 1.1516045331954956, C 1.082883358001709, E 1.1135060787200928, A 1.12008535861969, N 1.1031862497329712
06/19/2024 01:41:09 - ERROR - root -  43%|####2     | 166/390 [09:04<12:44,  3.41s/it]
06/19/2024 01:41:09 - INFO - modeling_roberta - Training sub-loss: O 1.061336636543274, C 1.1030528545379639, E 1.1048307418823242, A 1.0724681615829468, N 1.1157584190368652
06/19/2024 01:41:09 - INFO - modeling_roberta - Training sub-loss: O 1.0863534212112427, C 1.0803676843643188, E 1.1390516757965088, A 1.0854356288909912, N 1.0924324989318848
06/19/2024 01:41:11 - INFO - modeling_roberta - Training sub-loss: O 1.1224734783172607, C 1.09867525100708, E 1.074033260345459, A 1.105218529701233, N 1.1326408386230469
06/19/2024 01:41:11 - INFO - modeling_roberta - Training sub-loss: O 1.0192257165908813, C 1.1186178922653198, E 1.1463584899902344, A 1.0922131538391113, N 1.109657645225525
06/19/2024 01:41:12 - ERROR - root -  43%|####2     | 167/390 [09:07<12:36,  3.39s/it]
06/19/2024 01:41:13 - INFO - modeling_roberta - Training sub-loss: O 1.1113815307617188, C 1.0809333324432373, E 1.1276123523712158, A 1.0880085229873657, N 1.078222632408142
06/19/2024 01:41:13 - INFO - modeling_roberta - Training sub-loss: O 1.0787442922592163, C 1.0909159183502197, E 1.0888279676437378, A 1.0972609519958496, N 1.133802890777588
06/19/2024 01:41:14 - INFO - modeling_roberta - Training sub-loss: O 1.1374444961547852, C 1.1323782205581665, E 1.0999784469604492, A 1.1135388612747192, N 1.0434529781341553
06/19/2024 01:41:14 - INFO - modeling_roberta - Training sub-loss: O 1.089721441268921, C 1.1328105926513672, E 1.05812668800354, A 1.0910258293151855, N 1.096900463104248
06/19/2024 01:41:15 - ERROR - root -  43%|####3     | 168/390 [09:10<12:25,  3.36s/it]
06/19/2024 01:41:16 - INFO - modeling_roberta - Training sub-loss: O 1.1133366823196411, C 1.1185684204101562, E 1.1388559341430664, A 1.1002291440963745, N 1.1231091022491455
06/19/2024 01:41:16 - INFO - modeling_roberta - Training sub-loss: O 1.1154621839523315, C 1.1734073162078857, E 1.118830680847168, A 1.070589303970337, N 1.1257445812225342
06/19/2024 01:41:18 - INFO - modeling_roberta - Training sub-loss: O 1.0705734491348267, C 1.0998315811157227, E 1.0865983963012695, A 1.1020996570587158, N 1.1233314275741577
06/19/2024 01:41:18 - INFO - modeling_roberta - Training sub-loss: O 1.0618507862091064, C 1.0605134963989258, E 1.0716270208358765, A 1.0832746028900146, N 1.1221544742584229
06/19/2024 01:41:19 - ERROR - root -  43%|####3     | 169/390 [09:14<12:14,  3.33s/it]
06/19/2024 01:41:19 - INFO - modeling_roberta - Training sub-loss: O 1.0591952800750732, C 1.0833183526992798, E 1.1003119945526123, A 1.0901060104370117, N 1.0921268463134766
06/19/2024 01:41:19 - INFO - modeling_roberta - Training sub-loss: O 1.1016165018081665, C 1.104976773262024, E 1.140918254852295, A 1.1079803705215454, N 1.1091437339782715
06/19/2024 01:41:21 - INFO - modeling_roberta - Training sub-loss: O 1.0735384225845337, C 1.109916090965271, E 1.1354281902313232, A 1.0689140558242798, N 1.0800786018371582
06/19/2024 01:41:21 - INFO - modeling_roberta - Training sub-loss: O 1.0681705474853516, C 1.1619954109191895, E 1.0941393375396729, A 1.0976394414901733, N 1.0946261882781982
06/19/2024 01:41:22 - ERROR - root -  44%|####3     | 170/390 [09:17<12:07,  3.31s/it]
06/19/2024 01:41:22 - INFO - root - {'loss': 1.1, 'grad_norm': 90323.484375, 'learning_rate': 5.6410256410256414e-05, 'epoch': 2.17}
06/19/2024 01:41:22 - ERROR - root -  44%|####3     | 170/390 [09:17<12:07,  3.31s/it]
06/19/2024 01:41:23 - INFO - modeling_roberta - Training sub-loss: O 1.1105992794036865, C 1.0652917623519897, E 1.1209746599197388, A 1.1274099349975586, N 1.059349536895752
06/19/2024 01:41:23 - INFO - modeling_roberta - Training sub-loss: O 1.058193325996399, C 1.100994348526001, E 1.073345422744751, A 1.1076873540878296, N 1.0659923553466797
06/19/2024 01:41:24 - INFO - modeling_roberta - Training sub-loss: O 1.1330397129058838, C 1.1263234615325928, E 1.0674490928649902, A 1.1151206493377686, N 1.0609253644943237
06/19/2024 01:41:24 - INFO - modeling_roberta - Training sub-loss: O 1.1255950927734375, C 1.0964272022247314, E 1.11051607131958, A 1.0793648958206177, N 1.0935511589050293
06/19/2024 01:41:25 - ERROR - root -  44%|####3     | 171/390 [09:20<11:58,  3.28s/it]
06/19/2024 01:41:26 - INFO - modeling_roberta - Training sub-loss: O 1.0918035507202148, C 1.1275146007537842, E 1.084805965423584, A 1.12944757938385, N 1.0877974033355713
06/19/2024 01:41:26 - INFO - modeling_roberta - Training sub-loss: O 1.1229071617126465, C 1.1154468059539795, E 1.1113629341125488, A 1.089339256286621, N 1.1159954071044922
06/19/2024 01:41:27 - INFO - modeling_roberta - Training sub-loss: O 1.1499695777893066, C 1.076613426208496, E 1.1274092197418213, A 1.1373960971832275, N 1.125744104385376
06/19/2024 01:41:27 - INFO - modeling_roberta - Training sub-loss: O 1.0809342861175537, C 1.072886347770691, E 1.0754716396331787, A 1.1366660594940186, N 1.1089202165603638
06/19/2024 01:41:28 - ERROR - root -  44%|####4     | 172/390 [09:23<11:50,  3.26s/it]
06/19/2024 01:41:29 - INFO - modeling_roberta - Training sub-loss: O 1.154887318611145, C 1.0967789888381958, E 1.1101409196853638, A 1.1253037452697754, N 1.1202411651611328
06/19/2024 01:41:29 - INFO - modeling_roberta - Training sub-loss: O 1.1442689895629883, C 1.0629997253417969, E 1.1069934368133545, A 1.0916248559951782, N 1.1014628410339355
06/19/2024 01:41:31 - INFO - modeling_roberta - Training sub-loss: O 1.1273853778839111, C 1.0881989002227783, E 1.1442227363586426, A 1.074411153793335, N 1.099806785583496
06/19/2024 01:41:31 - INFO - modeling_roberta - Training sub-loss: O 1.082132339477539, C 1.0828967094421387, E 1.0861272811889648, A 1.1191070079803467, N 1.1244897842407227
06/19/2024 01:41:32 - ERROR - root -  44%|####4     | 173/390 [09:27<11:45,  3.25s/it]
06/19/2024 01:41:32 - INFO - modeling_roberta - Training sub-loss: O 1.0886023044586182, C 1.0826667547225952, E 1.1223347187042236, A 1.0778656005859375, N 1.089547038078308
06/19/2024 01:41:32 - INFO - modeling_roberta - Training sub-loss: O 1.0486633777618408, C 1.0996806621551514, E 1.1144267320632935, A 1.1543097496032715, N 1.1138759851455688
06/19/2024 01:41:34 - INFO - modeling_roberta - Training sub-loss: O 1.0330321788787842, C 1.1590774059295654, E 1.117018461227417, A 1.1499977111816406, N 1.0795137882232666
06/19/2024 01:41:34 - INFO - modeling_roberta - Training sub-loss: O 1.1497764587402344, C 1.0931625366210938, E 1.1452357769012451, A 1.203377604484558, N 1.194370985031128
06/19/2024 01:41:35 - ERROR - root -  45%|####4     | 174/390 [09:30<11:38,  3.24s/it]
06/19/2024 01:41:35 - INFO - modeling_roberta - Training sub-loss: O 1.1098499298095703, C 1.1081345081329346, E 1.0938440561294556, A 1.1071971654891968, N 1.1028501987457275
06/19/2024 01:41:35 - INFO - modeling_roberta - Training sub-loss: O 1.0652482509613037, C 1.1129179000854492, E 1.096455693244934, A 1.0695801973342896, N 1.1074249744415283
06/19/2024 01:41:37 - INFO - modeling_roberta - Training sub-loss: O 1.0858200788497925, C 1.1046723127365112, E 1.0849089622497559, A 1.1250765323638916, N 1.129960536956787
06/19/2024 01:41:37 - INFO - modeling_roberta - Training sub-loss: O 1.110363483428955, C 1.047839641571045, E 1.067724347114563, A 1.1122496128082275, N 1.1299455165863037
06/19/2024 01:41:38 - ERROR - root -  45%|####4     | 175/390 [09:33<11:32,  3.22s/it]
06/19/2024 01:41:39 - INFO - modeling_roberta - Training sub-loss: O 1.1169123649597168, C 1.1070101261138916, E 1.086480736732483, A 1.1102232933044434, N 1.0758273601531982
06/19/2024 01:41:39 - INFO - modeling_roberta - Training sub-loss: O 1.1072183847427368, C 1.089548110961914, E 1.1177031993865967, A 1.08726966381073, N 1.1188201904296875
06/19/2024 01:41:40 - INFO - modeling_roberta - Training sub-loss: O 1.108244776725769, C 1.0723947286605835, E 1.1243531703948975, A 1.0971912145614624, N 1.0590406656265259
06/19/2024 01:41:40 - INFO - modeling_roberta - Training sub-loss: O 1.1331812143325806, C 1.142874002456665, E 1.0681915283203125, A 1.062865972518921, N 1.0990679264068604
06/19/2024 01:41:41 - ERROR - root -  45%|####5     | 176/390 [09:36<11:27,  3.21s/it]
06/19/2024 01:41:42 - INFO - modeling_roberta - Training sub-loss: O 1.0546380281448364, C 1.0946117639541626, E 1.1552069187164307, A 1.1220885515213013, N 1.1039106845855713
06/19/2024 01:41:42 - INFO - modeling_roberta - Training sub-loss: O 1.0716283321380615, C 1.1190125942230225, E 1.0723270177841187, A 1.0996768474578857, N 1.0926718711853027
06/19/2024 01:41:43 - INFO - modeling_roberta - Training sub-loss: O 1.0489174127578735, C 1.131890058517456, E 1.0413875579833984, A 1.0684787034988403, N 1.1638038158416748
06/19/2024 01:41:43 - INFO - modeling_roberta - Training sub-loss: O 1.1123414039611816, C 1.0866131782531738, E 1.12124502658844, A 1.1074490547180176, N 1.100916862487793
06/19/2024 01:41:44 - ERROR - root -  45%|####5     | 177/390 [09:39<11:23,  3.21s/it]
06/19/2024 01:41:45 - INFO - modeling_roberta - Training sub-loss: O 1.0828444957733154, C 1.0599095821380615, E 1.1136590242385864, A 1.1420502662658691, N 1.1262109279632568
06/19/2024 01:41:45 - INFO - modeling_roberta - Training sub-loss: O 1.1226272583007812, C 1.1051514148712158, E 1.116332769393921, A 1.1052193641662598, N 1.1119798421859741
06/19/2024 01:41:47 - INFO - modeling_roberta - Training sub-loss: O 1.1061837673187256, C 1.0759395360946655, E 1.1313204765319824, A 1.1012214422225952, N 1.061389446258545
06/19/2024 01:41:47 - INFO - modeling_roberta - Training sub-loss: O 1.1024296283721924, C 1.0562444925308228, E 1.1285113096237183, A 1.0891098976135254, N 1.0874571800231934
06/19/2024 01:41:48 - ERROR - root -  46%|####5     | 178/390 [09:43<11:21,  3.22s/it]
06/19/2024 01:41:48 - INFO - modeling_roberta - Training sub-loss: O 1.1259733438491821, C 1.0849004983901978, E 1.1060001850128174, A 1.0976365804672241, N 1.0663014650344849
06/19/2024 01:41:48 - INFO - modeling_roberta - Training sub-loss: O 1.0799369812011719, C 1.1569774150848389, E 1.0668680667877197, A 1.129697561264038, N 1.0907198190689087
06/19/2024 01:41:50 - INFO - modeling_roberta - Training sub-loss: O 1.0869710445404053, C 1.1031863689422607, E 1.1931648254394531, A 1.0884958505630493, N 1.1083072423934937
06/19/2024 01:41:50 - INFO - modeling_roberta - Training sub-loss: O 1.0880687236785889, C 1.0851025581359863, E 1.096313238143921, A 1.1261910200119019, N 1.1558369398117065
06/19/2024 01:41:51 - ERROR - root -  46%|####5     | 179/390 [09:46<11:16,  3.21s/it]
06/19/2024 01:41:51 - INFO - modeling_roberta - Training sub-loss: O 1.0909597873687744, C 1.094738245010376, E 1.1579641103744507, A 1.08585786819458, N 1.1325856447219849
06/19/2024 01:41:51 - INFO - modeling_roberta - Training sub-loss: O 1.0599466562271118, C 1.0901662111282349, E 1.15376877784729, A 1.0631210803985596, N 1.1092243194580078
06/19/2024 01:41:53 - INFO - modeling_roberta - Training sub-loss: O 1.1291792392730713, C 1.1065973043441772, E 1.083589792251587, A 1.1206140518188477, N 1.1408805847167969
06/19/2024 01:41:53 - INFO - modeling_roberta - Training sub-loss: O 1.1240803003311157, C 1.0793602466583252, E 1.1602602005004883, A 1.1137901544570923, N 1.116866111755371
06/19/2024 01:41:54 - ERROR - root -  46%|####6     | 180/390 [09:49<11:14,  3.21s/it]
06/19/2024 01:41:54 - INFO - root - {'loss': 1.1041, 'grad_norm': 81515.0625, 'learning_rate': 5.384615384615385e-05, 'epoch': 2.29}
06/19/2024 01:41:54 - ERROR - root -  46%|####6     | 180/390 [09:49<11:14,  3.21s/it]
06/19/2024 01:41:55 - INFO - modeling_roberta - Training sub-loss: O 1.0931140184402466, C 1.10398530960083, E 1.1381056308746338, A 1.1284565925598145, N 1.0915095806121826
06/19/2024 01:41:55 - INFO - modeling_roberta - Training sub-loss: O 1.0984450578689575, C 1.0984712839126587, E 1.0694172382354736, A 1.0820386409759521, N 1.0945030450820923
06/19/2024 01:41:56 - INFO - modeling_roberta - Training sub-loss: O 1.1217780113220215, C 1.0909929275512695, E 1.1431357860565186, A 1.0822970867156982, N 1.139136552810669
06/19/2024 01:41:56 - INFO - modeling_roberta - Training sub-loss: O 1.1134172677993774, C 1.1086138486862183, E 1.0880768299102783, A 1.11448073387146, N 1.096203327178955
06/19/2024 01:41:57 - ERROR - root -  46%|####6     | 181/390 [09:52<11:13,  3.22s/it]
06/19/2024 01:41:58 - INFO - modeling_roberta - Training sub-loss: O 1.123293399810791, C 1.0813976526260376, E 1.12202787399292, A 1.1072487831115723, N 1.0920724868774414
06/19/2024 01:41:58 - INFO - modeling_roberta - Training sub-loss: O 1.1454899311065674, C 1.0903260707855225, E 1.1147139072418213, A 1.0798320770263672, N 1.0596362352371216
06/19/2024 01:41:59 - INFO - modeling_roberta - Training sub-loss: O 1.08461594581604, C 1.077221155166626, E 1.1784179210662842, A 1.1211912631988525, N 1.1558151245117188
06/19/2024 01:41:59 - INFO - modeling_roberta - Training sub-loss: O 1.1232917308807373, C 1.10297429561615, E 1.0824413299560547, A 1.103448510169983, N 1.1182122230529785
06/19/2024 01:42:00 - ERROR - root -  47%|####6     | 182/390 [09:55<11:10,  3.22s/it]
06/19/2024 01:42:01 - INFO - modeling_roberta - Training sub-loss: O 1.0788166522979736, C 1.0910472869873047, E 1.075883388519287, A 1.1438965797424316, N 1.0772426128387451
06/19/2024 01:42:01 - INFO - modeling_roberta - Training sub-loss: O 1.0643646717071533, C 1.0885331630706787, E 1.0623599290847778, A 1.1111329793930054, N 1.1480624675750732
06/19/2024 01:42:03 - INFO - modeling_roberta - Training sub-loss: O 1.1170387268066406, C 1.0999146699905396, E 1.143092393875122, A 1.0770436525344849, N 1.0525462627410889
06/19/2024 01:42:03 - INFO - modeling_roberta - Training sub-loss: O 1.1525578498840332, C 1.1041929721832275, E 1.1240026950836182, A 1.0602529048919678, N 1.0837011337280273
06/19/2024 01:42:04 - ERROR - root -  47%|####6     | 183/390 [09:59<11:05,  3.21s/it]
06/19/2024 01:42:04 - INFO - modeling_roberta - Training sub-loss: O 1.0940932035446167, C 1.0811944007873535, E 1.1218504905700684, A 1.1002709865570068, N 1.1470870971679688
06/19/2024 01:42:04 - INFO - modeling_roberta - Training sub-loss: O 1.1136583089828491, C 1.1111210584640503, E 1.0843416452407837, A 1.1121861934661865, N 1.1290137767791748
06/19/2024 01:42:06 - INFO - modeling_roberta - Training sub-loss: O 1.0666956901550293, C 1.097902536392212, E 1.0773649215698242, A 1.1068053245544434, N 1.0596892833709717
06/19/2024 01:42:06 - INFO - modeling_roberta - Training sub-loss: O 1.075966715812683, C 1.0476438999176025, E 1.0841104984283447, A 1.0741169452667236, N 1.101218342781067
06/19/2024 01:42:07 - ERROR - root -  47%|####7     | 184/390 [10:02<11:01,  3.21s/it]
06/19/2024 01:42:07 - INFO - modeling_roberta - Training sub-loss: O 1.112696886062622, C 1.0868504047393799, E 1.1612489223480225, A 1.1518898010253906, N 1.0812554359436035
06/19/2024 01:42:07 - INFO - modeling_roberta - Training sub-loss: O 1.1150038242340088, C 1.0936212539672852, E 1.0487351417541504, A 1.079677939414978, N 1.07050621509552
06/19/2024 01:42:09 - INFO - modeling_roberta - Training sub-loss: O 1.1008304357528687, C 1.145749807357788, E 1.101169466972351, A 1.0649430751800537, N 1.1136741638183594
06/19/2024 01:42:09 - INFO - modeling_roberta - Training sub-loss: O 1.1618735790252686, C 1.0598496198654175, E 1.1242607831954956, A 1.1114481687545776, N 1.0558462142944336
06/19/2024 01:42:10 - ERROR - root -  47%|####7     | 185/390 [10:05<10:57,  3.21s/it]
06/19/2024 01:42:11 - INFO - modeling_roberta - Training sub-loss: O 1.081553339958191, C 1.1332420110702515, E 1.111071228981018, A 1.1290110349655151, N 1.1006360054016113
06/19/2024 01:42:11 - INFO - modeling_roberta - Training sub-loss: O 1.0717740058898926, C 1.0846681594848633, E 1.1312997341156006, A 1.0998132228851318, N 1.101732850074768
06/19/2024 01:42:12 - INFO - modeling_roberta - Training sub-loss: O 1.098717212677002, C 1.085451364517212, E 1.054760217666626, A 1.0838074684143066, N 1.0987602472305298
06/19/2024 01:42:12 - INFO - modeling_roberta - Training sub-loss: O 1.0982106924057007, C 1.0527015924453735, E 1.1587868928909302, A 1.1545354127883911, N 1.1025454998016357
06/19/2024 01:42:13 - ERROR - root -  48%|####7     | 186/390 [10:08<10:55,  3.21s/it]
06/19/2024 01:42:14 - INFO - modeling_roberta - Training sub-loss: O 1.0957798957824707, C 1.1042226552963257, E 1.1250594854354858, A 1.1140556335449219, N 1.0826671123504639
06/19/2024 01:42:14 - INFO - modeling_roberta - Training sub-loss: O 1.109763264656067, C 1.1325007677078247, E 1.1122437715530396, A 1.1373450756072998, N 1.115936279296875
06/19/2024 01:42:15 - INFO - modeling_roberta - Training sub-loss: O 1.1194719076156616, C 1.097368597984314, E 1.1482406854629517, A 1.105886459350586, N 1.071038842201233
06/19/2024 01:42:15 - INFO - modeling_roberta - Training sub-loss: O 1.079991340637207, C 1.1390101909637451, E 1.1384755373001099, A 1.0912137031555176, N 1.1369729042053223
06/19/2024 01:42:16 - ERROR - root -  48%|####7     | 187/390 [10:12<10:52,  3.21s/it]
06/19/2024 01:42:17 - INFO - modeling_roberta - Training sub-loss: O 1.0626788139343262, C 1.1080366373062134, E 1.1084774732589722, A 1.0406666994094849, N 1.102139949798584
06/19/2024 01:42:17 - INFO - modeling_roberta - Training sub-loss: O 1.0795013904571533, C 1.0848584175109863, E 1.1420866250991821, A 1.1138606071472168, N 1.0844451189041138
06/19/2024 01:42:19 - INFO - modeling_roberta - Training sub-loss: O 1.0864589214324951, C 1.0640685558319092, E 1.1436707973480225, A 1.149889588356018, N 1.1440116167068481
06/19/2024 01:42:19 - INFO - modeling_roberta - Training sub-loss: O 1.118712306022644, C 1.0445938110351562, E 1.0273115634918213, A 1.1412088871002197, N 1.120049238204956
06/19/2024 01:42:20 - ERROR - root -  48%|####8     | 188/390 [10:15<11:01,  3.28s/it]
06/19/2024 01:42:21 - INFO - modeling_roberta - Training sub-loss: O 1.0766797065734863, C 1.1077302694320679, E 1.2171378135681152, A 1.1565452814102173, N 1.0864675045013428
06/19/2024 01:42:21 - INFO - modeling_roberta - Training sub-loss: O 1.1068017482757568, C 1.082546591758728, E 1.1927809715270996, A 1.1075515747070312, N 1.10676109790802
06/19/2024 01:42:22 - INFO - modeling_roberta - Training sub-loss: O 1.0496501922607422, C 1.1603727340698242, E 1.1828683614730835, A 1.1006877422332764, N 1.0713932514190674
06/19/2024 01:42:22 - INFO - modeling_roberta - Training sub-loss: O 1.100788950920105, C 0.9888871908187866, E 1.2094794511795044, A 1.089734435081482, N 1.1363331079483032
06/19/2024 01:42:23 - ERROR - root -  48%|####8     | 189/390 [10:18<10:54,  3.25s/it]
06/19/2024 01:42:24 - INFO - modeling_roberta - Training sub-loss: O 1.0902187824249268, C 1.0494294166564941, E 1.111411452293396, A 1.093349814414978, N 1.1177371740341187
06/19/2024 01:42:24 - INFO - modeling_roberta - Training sub-loss: O 1.053120732307434, C 1.1399281024932861, E 1.138214111328125, A 1.1689183712005615, N 1.0860188007354736
06/19/2024 01:42:25 - INFO - modeling_roberta - Training sub-loss: O 1.1109025478363037, C 1.1466801166534424, E 1.113415241241455, A 1.0310473442077637, N 1.0565574169158936
06/19/2024 01:42:25 - INFO - modeling_roberta - Training sub-loss: O 1.1245050430297852, C 1.1088865995407104, E 1.1671428680419922, A 1.1499820947647095, N 1.079953670501709
06/19/2024 01:42:26 - ERROR - root -  49%|####8     | 190/390 [10:21<10:47,  3.24s/it]
06/19/2024 01:42:26 - INFO - root - {'loss': 1.1043, 'grad_norm': 62378.20703125, 'learning_rate': 5.128205128205128e-05, 'epoch': 2.42}
06/19/2024 01:42:26 - ERROR - root -  49%|####8     | 190/390 [10:21<10:47,  3.24s/it]
06/19/2024 01:42:27 - INFO - modeling_roberta - Training sub-loss: O 1.139275312423706, C 1.0941290855407715, E 1.0827745199203491, A 1.109306812286377, N 1.0720019340515137
06/19/2024 01:42:27 - INFO - modeling_roberta - Training sub-loss: O 1.0901530981063843, C 1.1055943965911865, E 1.129751205444336, A 1.1232879161834717, N 1.0743143558502197
06/19/2024 01:42:29 - INFO - modeling_roberta - Training sub-loss: O 1.068159580230713, C 1.1373684406280518, E 1.09536612033844, A 1.1823225021362305, N 1.140984296798706
06/19/2024 01:42:29 - INFO - modeling_roberta - Training sub-loss: O 1.0927388668060303, C 1.2338380813598633, E 1.1177382469177246, A 1.1621699333190918, N 1.0522758960723877
06/19/2024 01:42:29 - ERROR - root -  49%|####8     | 191/390 [10:25<10:42,  3.23s/it]
06/19/2024 01:42:30 - INFO - modeling_roberta - Training sub-loss: O 1.1417958736419678, C 1.0549644231796265, E 1.096100091934204, A 1.1036009788513184, N 1.108849287033081
06/19/2024 01:42:30 - INFO - modeling_roberta - Training sub-loss: O 1.1219236850738525, C 1.0536566972732544, E 1.0961984395980835, A 1.0984052419662476, N 1.1016716957092285
06/19/2024 01:42:32 - INFO - modeling_roberta - Training sub-loss: O 1.1529868841171265, C 1.0898327827453613, E 1.1657780408859253, A 1.0991184711456299, N 1.077553391456604
06/19/2024 01:42:32 - INFO - modeling_roberta - Training sub-loss: O 1.1012375354766846, C 1.0752360820770264, E 1.1875653266906738, A 1.109447956085205, N 1.1228618621826172
06/19/2024 01:42:33 - ERROR - root -  49%|####9     | 192/390 [10:28<10:40,  3.24s/it]
06/19/2024 01:42:33 - INFO - modeling_roberta - Training sub-loss: O 1.1051557064056396, C 1.125378131866455, E 1.157172441482544, A 1.186877965927124, N 1.0463275909423828
06/19/2024 01:42:33 - INFO - modeling_roberta - Training sub-loss: O 1.036904215812683, C 1.1506556272506714, E 1.0747675895690918, A 1.0724899768829346, N 1.1081056594848633
06/19/2024 01:42:35 - INFO - modeling_roberta - Training sub-loss: O 1.1847856044769287, C 1.052957534790039, E 1.150073766708374, A 1.1330722570419312, N 1.1192139387130737
06/19/2024 01:42:35 - INFO - modeling_roberta - Training sub-loss: O 1.1412465572357178, C 1.1091655492782593, E 1.02597975730896, A 1.1449639797210693, N 1.1210079193115234
06/19/2024 01:42:36 - ERROR - root -  49%|####9     | 193/390 [10:31<10:50,  3.30s/it]
06/19/2024 01:42:37 - INFO - modeling_roberta - Training sub-loss: O 1.1238455772399902, C 1.069399356842041, E 1.179251790046692, A 1.1493170261383057, N 1.1009485721588135
06/19/2024 01:42:37 - INFO - modeling_roberta - Training sub-loss: O 1.0997833013534546, C 1.1429033279418945, E 1.1794710159301758, A 1.193894863128662, N 1.1178745031356812
06/19/2024 01:42:39 - INFO - modeling_roberta - Training sub-loss: O 1.172483205795288, C 1.1364699602127075, E 1.1102855205535889, A 1.1783528327941895, N 1.1473461389541626
06/19/2024 01:42:39 - INFO - modeling_roberta - Training sub-loss: O 1.0861027240753174, C 1.1918950080871582, E 1.1165189743041992, A 1.0972545146942139, N 1.118823528289795
06/19/2024 01:42:40 - ERROR - root -  50%|####9     | 194/390 [10:35<10:56,  3.35s/it]
06/19/2024 01:42:40 - INFO - modeling_roberta - Training sub-loss: O 1.0595569610595703, C 1.043628454208374, E 1.0935457944869995, A 1.1870852708816528, N 1.1271889209747314
06/19/2024 01:42:40 - INFO - modeling_roberta - Training sub-loss: O 1.1271445751190186, C 1.0892925262451172, E 1.1363791227340698, A 1.128495454788208, N 1.1365472078323364
06/19/2024 01:42:42 - INFO - modeling_roberta - Training sub-loss: O 1.1138663291931152, C 1.0744961500167847, E 1.1045305728912354, A 1.0902273654937744, N 1.1347248554229736
06/19/2024 01:42:42 - INFO - modeling_roberta - Training sub-loss: O 1.1196696758270264, C 1.1533739566802979, E 1.1056504249572754, A 1.0611116886138916, N 1.100523591041565
06/19/2024 01:42:43 - ERROR - root -  50%|#####     | 195/390 [10:38<10:58,  3.38s/it]
06/19/2024 01:42:44 - INFO - modeling_roberta - Training sub-loss: O 1.1104503870010376, C 1.154789924621582, E 1.112532377243042, A 1.1529693603515625, N 1.096148133277893
06/19/2024 01:42:44 - INFO - modeling_roberta - Training sub-loss: O 1.05343759059906, C 1.1412715911865234, E 1.0999256372451782, A 1.1356149911880493, N 1.0643322467803955
06/19/2024 01:42:45 - INFO - modeling_roberta - Training sub-loss: O 1.0783917903900146, C 1.0522211790084839, E 1.1248427629470825, A 1.1351444721221924, N 1.1397346258163452
06/19/2024 01:42:45 - INFO - modeling_roberta - Training sub-loss: O 1.094165325164795, C 1.1271159648895264, E 1.087116003036499, A 1.1381843090057373, N 1.1101479530334473
06/19/2024 01:42:46 - ERROR - root -  50%|#####     | 196/390 [10:42<10:56,  3.39s/it]
06/19/2024 01:42:47 - INFO - modeling_roberta - Training sub-loss: O 1.1226445436477661, C 1.1140340566635132, E 1.0921008586883545, A 1.1193777322769165, N 1.1024439334869385
06/19/2024 01:42:47 - INFO - modeling_roberta - Training sub-loss: O 1.049208164215088, C 1.108756422996521, E 1.0898480415344238, A 1.1151283979415894, N 1.1184301376342773
06/19/2024 01:42:49 - INFO - modeling_roberta - Training sub-loss: O 1.1035094261169434, C 1.109600305557251, E 1.1185362339019775, A 1.1062471866607666, N 1.1113320589065552
06/19/2024 01:42:49 - INFO - modeling_roberta - Training sub-loss: O 1.0718072652816772, C 1.1287139654159546, E 1.0920958518981934, A 1.1176460981369019, N 1.0796704292297363
06/19/2024 01:42:50 - ERROR - root -  51%|#####     | 197/390 [10:45<10:53,  3.39s/it]
06/19/2024 01:42:51 - INFO - modeling_roberta - Training sub-loss: O 1.079411268234253, C 1.1114215850830078, E 1.0374135971069336, A 1.107068657875061, N 1.10696280002594
06/19/2024 01:42:51 - INFO - modeling_roberta - Training sub-loss: O 1.0254030227661133, C 1.0683778524398804, E 1.1412631273269653, A 1.08967924118042, N 1.1076557636260986
06/19/2024 01:42:52 - INFO - modeling_roberta - Training sub-loss: O 1.1511540412902832, C 1.0967700481414795, E 1.0695675611495972, A 1.120208740234375, N 1.0704163312911987
06/19/2024 01:42:52 - INFO - modeling_roberta - Training sub-loss: O 1.1151597499847412, C 1.2086138725280762, E 1.112617015838623, A 1.1011207103729248, N 1.1439273357391357
06/19/2024 01:42:53 - ERROR - root -  51%|#####     | 198/390 [10:48<10:53,  3.40s/it]
06/19/2024 01:42:54 - INFO - modeling_roberta - Training sub-loss: O 1.106903314590454, C 1.0463446378707886, E 1.092909574508667, A 1.0736539363861084, N 1.083040475845337
06/19/2024 01:42:54 - INFO - modeling_roberta - Training sub-loss: O 1.0802080631256104, C 1.0693129301071167, E 1.1044081449508667, A 1.1273103952407837, N 1.093291997909546
06/19/2024 01:42:56 - INFO - modeling_roberta - Training sub-loss: O 1.0821059942245483, C 1.0368183851242065, E 1.163972020149231, A 1.0989875793457031, N 1.0966620445251465
06/19/2024 01:42:56 - INFO - modeling_roberta - Training sub-loss: O 1.0639677047729492, C 1.0609725713729858, E 1.1367484331130981, A 1.0636160373687744, N 1.1066501140594482
06/19/2024 01:42:57 - ERROR - root -  51%|#####1    | 199/390 [10:52<10:54,  3.43s/it]
06/19/2024 01:42:58 - INFO - modeling_roberta - Training sub-loss: O 1.1544699668884277, C 1.193001389503479, E 1.1099773645401, A 1.1392481327056885, N 1.0952943563461304
06/19/2024 01:42:58 - INFO - modeling_roberta - Training sub-loss: O 1.1120293140411377, C 0.9998881816864014, E 1.1377944946289062, A 1.113912582397461, N 1.1301615238189697
06/19/2024 01:42:59 - INFO - modeling_roberta - Training sub-loss: O 1.1740868091583252, C 1.0947203636169434, E 1.0853660106658936, A 1.1015963554382324, N 1.1067595481872559
06/19/2024 01:42:59 - INFO - modeling_roberta - Training sub-loss: O 1.1600605249404907, C 1.1252086162567139, E 1.0420305728912354, A 1.0693433284759521, N 1.0675851106643677
06/19/2024 01:43:00 - ERROR - root -  51%|#####1    | 200/390 [10:55<10:52,  3.44s/it]
06/19/2024 01:43:00 - INFO - root - {'loss': 1.1098, 'grad_norm': 95118.1328125, 'learning_rate': 4.871794871794872e-05, 'epoch': 2.55}
06/19/2024 01:43:00 - ERROR - root -  51%|#####1    | 200/390 [10:55<10:52,  3.44s/it]
06/19/2024 01:43:01 - INFO - modeling_roberta - Training sub-loss: O 1.081043004989624, C 1.1740552186965942, E 1.1208351850509644, A 1.1201037168502808, N 1.164381980895996
06/19/2024 01:43:01 - INFO - modeling_roberta - Training sub-loss: O 1.1721787452697754, C 1.1195963621139526, E 1.0883817672729492, A 1.0710082054138184, N 1.0940730571746826
06/19/2024 01:43:03 - INFO - modeling_roberta - Training sub-loss: O 1.0780200958251953, C 1.0534065961837769, E 1.1321635246276855, A 1.1208784580230713, N 1.0451041460037231
06/19/2024 01:43:03 - INFO - modeling_roberta - Training sub-loss: O 1.0868115425109863, C 1.1862998008728027, E 1.063126802444458, A 1.1039739847183228, N 1.1209343671798706
06/19/2024 01:43:04 - ERROR - root -  52%|#####1    | 201/390 [10:59<10:49,  3.44s/it]
06/19/2024 01:43:04 - INFO - modeling_roberta - Training sub-loss: O 1.1208560466766357, C 1.1098389625549316, E 1.0680660009384155, A 1.1153414249420166, N 1.1667630672454834
06/19/2024 01:43:04 - INFO - modeling_roberta - Training sub-loss: O 1.09792160987854, C 1.147173523902893, E 1.0813391208648682, A 1.1091458797454834, N 1.098706841468811
06/19/2024 01:43:06 - INFO - modeling_roberta - Training sub-loss: O 1.1471346616744995, C 1.1567773818969727, E 1.0815033912658691, A 1.1284286975860596, N 1.1000547409057617
06/19/2024 01:43:06 - INFO - modeling_roberta - Training sub-loss: O 1.1701741218566895, C 1.1285878419876099, E 1.097060203552246, A 1.1031794548034668, N 1.127365231513977
06/19/2024 01:43:07 - ERROR - root -  52%|#####1    | 202/390 [11:02<10:50,  3.46s/it]
06/19/2024 01:43:08 - INFO - modeling_roberta - Training sub-loss: O 1.1079435348510742, C 1.1086757183074951, E 1.086503505706787, A 1.130356788635254, N 1.0439987182617188
06/19/2024 01:43:08 - INFO - modeling_roberta - Training sub-loss: O 1.1443216800689697, C 1.1079516410827637, E 1.0867021083831787, A 1.0647947788238525, N 1.1542859077453613
06/19/2024 01:43:10 - INFO - modeling_roberta - Training sub-loss: O 1.0858263969421387, C 1.0697811841964722, E 1.1172575950622559, A 1.1213713884353638, N 1.1174407005310059
06/19/2024 01:43:10 - INFO - modeling_roberta - Training sub-loss: O 1.1321064233779907, C 1.1399438381195068, E 1.0607426166534424, A 1.0633487701416016, N 1.1386104822158813
06/19/2024 01:43:11 - ERROR - root -  52%|#####2    | 203/390 [11:06<10:51,  3.48s/it]
06/19/2024 01:43:11 - INFO - modeling_roberta - Training sub-loss: O 1.1316771507263184, C 1.1129940748214722, E 1.104684591293335, A 1.0939902067184448, N 1.0819487571716309
06/19/2024 01:43:11 - INFO - modeling_roberta - Training sub-loss: O 1.1176307201385498, C 1.0931628942489624, E 1.0931570529937744, A 1.0788202285766602, N 1.0864046812057495
06/19/2024 01:43:13 - INFO - modeling_roberta - Training sub-loss: O 1.0479347705841064, C 1.1063499450683594, E 1.0925965309143066, A 1.0982497930526733, N 1.096189260482788
06/19/2024 01:43:13 - INFO - modeling_roberta - Training sub-loss: O 1.0904861688613892, C 1.0680875778198242, E 1.1355359554290771, A 1.1255056858062744, N 1.0896031856536865
06/19/2024 01:43:14 - ERROR - root -  52%|#####2    | 204/390 [11:09<10:48,  3.49s/it]
06/19/2024 01:43:15 - INFO - modeling_roberta - Training sub-loss: O 1.1132594347000122, C 1.1233747005462646, E 1.1507360935211182, A 1.1283071041107178, N 1.093385934829712
06/19/2024 01:43:15 - INFO - modeling_roberta - Training sub-loss: O 1.1114399433135986, C 1.1100633144378662, E 1.0970656871795654, A 1.0903732776641846, N 1.1128501892089844
06/19/2024 01:43:17 - INFO - modeling_roberta - Training sub-loss: O 1.062563419342041, C 1.1537317037582397, E 1.1317718029022217, A 1.1141550540924072, N 1.1561613082885742
06/19/2024 01:43:17 - INFO - modeling_roberta - Training sub-loss: O 1.0806286334991455, C 1.1022017002105713, E 1.097003698348999, A 1.0460821390151978, N 1.055476427078247
06/19/2024 01:43:18 - ERROR - root -  53%|#####2    | 205/390 [11:13<10:47,  3.50s/it]
06/19/2024 01:43:19 - INFO - modeling_roberta - Training sub-loss: O 1.1145250797271729, C 1.1080631017684937, E 1.0829410552978516, A 1.124667763710022, N 1.1171841621398926
06/19/2024 01:43:19 - INFO - modeling_roberta - Training sub-loss: O 1.1016267538070679, C 1.1204030513763428, E 1.1022961139678955, A 1.086761713027954, N 1.1059184074401855
06/19/2024 01:43:20 - INFO - modeling_roberta - Training sub-loss: O 1.0860848426818848, C 1.0902296304702759, E 1.0665059089660645, A 1.0581670999526978, N 1.1369986534118652
06/19/2024 01:43:20 - INFO - modeling_roberta - Training sub-loss: O 1.133739709854126, C 1.1252766847610474, E 1.1044038534164429, A 1.115470290184021, N 1.131300687789917
06/19/2024 01:43:21 - ERROR - root -  53%|#####2    | 206/390 [11:16<10:41,  3.48s/it]
06/19/2024 01:43:22 - INFO - modeling_roberta - Training sub-loss: O 1.137390375137329, C 1.0978903770446777, E 1.1330149173736572, A 1.0993597507476807, N 1.0985252857208252
06/19/2024 01:43:22 - INFO - modeling_roberta - Training sub-loss: O 1.072100281715393, C 1.0990841388702393, E 1.0845770835876465, A 1.1146236658096313, N 1.093991756439209
06/19/2024 01:43:24 - INFO - modeling_roberta - Training sub-loss: O 1.1341838836669922, C 1.0975165367126465, E 1.0636930465698242, A 1.1133711338043213, N 1.0689442157745361
06/19/2024 01:43:24 - INFO - modeling_roberta - Training sub-loss: O 1.0776755809783936, C 1.0795605182647705, E 1.0682742595672607, A 1.0759748220443726, N 1.1341519355773926
06/19/2024 01:43:25 - ERROR - root -  53%|#####3    | 207/390 [11:20<10:29,  3.44s/it]
06/19/2024 01:43:25 - INFO - modeling_roberta - Training sub-loss: O 1.1178576946258545, C 1.1348499059677124, E 1.1098169088363647, A 1.116217851638794, N 1.1192710399627686
06/19/2024 01:43:25 - INFO - modeling_roberta - Training sub-loss: O 1.1056236028671265, C 1.1230168342590332, E 1.0957750082015991, A 1.111697793006897, N 1.090539813041687
06/19/2024 01:43:27 - INFO - modeling_roberta - Training sub-loss: O 1.0769119262695312, C 1.093630313873291, E 1.1291258335113525, A 1.134286880493164, N 1.127342700958252
06/19/2024 01:43:27 - INFO - modeling_roberta - Training sub-loss: O 1.0870232582092285, C 1.0799894332885742, E 1.096624493598938, A 1.1381090879440308, N 1.1254911422729492
06/19/2024 01:43:28 - ERROR - root -  53%|#####3    | 208/390 [11:23<10:18,  3.40s/it]
06/19/2024 01:43:29 - INFO - modeling_roberta - Training sub-loss: O 1.128279447555542, C 1.070996880531311, E 1.0938754081726074, A 1.0621914863586426, N 1.11109459400177
06/19/2024 01:43:29 - INFO - modeling_roberta - Training sub-loss: O 1.0513219833374023, C 1.1036688089370728, E 1.1418678760528564, A 1.02970552444458, N 1.1201541423797607
06/19/2024 01:43:30 - INFO - modeling_roberta - Training sub-loss: O 1.122685432434082, C 1.1092908382415771, E 1.070448637008667, A 1.1198880672454834, N 1.0837277173995972
06/19/2024 01:43:30 - INFO - modeling_roberta - Training sub-loss: O 1.0903537273406982, C 1.0968605279922485, E 1.1493033170700073, A 1.0824577808380127, N 1.098758578300476
06/19/2024 01:43:31 - ERROR - root -  54%|#####3    | 209/390 [11:26<10:07,  3.36s/it]
06/19/2024 01:43:32 - INFO - modeling_roberta - Training sub-loss: O 1.0840178728103638, C 1.093996286392212, E 1.1236318349838257, A 1.079888939857483, N 1.0917068719863892
06/19/2024 01:43:32 - INFO - modeling_roberta - Training sub-loss: O 1.1036564111709595, C 1.1194835901260376, E 1.110838532447815, A 1.0875447988510132, N 1.1174509525299072
06/19/2024 01:43:33 - INFO - modeling_roberta - Training sub-loss: O 1.11143159866333, C 1.0804723501205444, E 1.0710458755493164, A 1.1702568531036377, N 1.156715750694275
06/19/2024 01:43:33 - INFO - modeling_roberta - Training sub-loss: O 1.0722720623016357, C 1.0851972103118896, E 1.0681411027908325, A 1.0523079633712769, N 1.0880801677703857
06/19/2024 01:43:34 - ERROR - root -  54%|#####3    | 210/390 [11:29<09:57,  3.32s/it]
06/19/2024 01:43:34 - INFO - root - {'loss': 1.1044, 'grad_norm': 52948.96875, 'learning_rate': 4.615384615384616e-05, 'epoch': 2.68}
06/19/2024 01:43:34 - ERROR - root -  54%|#####3    | 210/390 [11:29<09:57,  3.32s/it]
06/19/2024 01:43:35 - INFO - modeling_roberta - Training sub-loss: O 1.0764174461364746, C 1.1234862804412842, E 1.0793054103851318, A 1.0882368087768555, N 1.1065747737884521
06/19/2024 01:43:35 - INFO - modeling_roberta - Training sub-loss: O 1.1012556552886963, C 1.1029601097106934, E 1.0974373817443848, A 1.0676567554473877, N 1.105342149734497
06/19/2024 01:43:37 - INFO - modeling_roberta - Training sub-loss: O 1.1296579837799072, C 1.0910464525222778, E 1.1216658353805542, A 1.0885062217712402, N 1.1447350978851318
06/19/2024 01:43:37 - INFO - modeling_roberta - Training sub-loss: O 1.1012156009674072, C 1.0930589437484741, E 1.0979338884353638, A 1.1046521663665771, N 1.1171305179595947
06/19/2024 01:43:38 - ERROR - root -  54%|#####4    | 211/390 [11:33<09:58,  3.35s/it]
06/19/2024 01:43:38 - INFO - modeling_roberta - Training sub-loss: O 1.1642580032348633, C 1.1365694999694824, E 1.08920156955719, A 1.1024096012115479, N 1.0875756740570068
06/19/2024 01:43:38 - INFO - modeling_roberta - Training sub-loss: O 1.1331591606140137, C 1.1789257526397705, E 1.105797290802002, A 1.1060433387756348, N 1.0826103687286377
06/19/2024 01:43:40 - INFO - modeling_roberta - Training sub-loss: O 1.12054443359375, C 1.0825039148330688, E 1.1066343784332275, A 1.1461350917816162, N 1.0999689102172852
06/19/2024 01:43:40 - INFO - modeling_roberta - Training sub-loss: O 1.0757988691329956, C 1.1162667274475098, E 1.0738472938537598, A 1.133676528930664, N 1.1570398807525635
06/19/2024 01:43:41 - ERROR - root -  54%|#####4    | 212/390 [11:36<09:47,  3.30s/it]
06/19/2024 01:43:42 - INFO - modeling_roberta - Training sub-loss: O 1.1625171899795532, C 1.178805947303772, E 1.0927174091339111, A 1.1181950569152832, N 1.1467702388763428
06/19/2024 01:43:42 - INFO - modeling_roberta - Training sub-loss: O 1.1309148073196411, C 1.0902070999145508, E 1.1313705444335938, A 1.1511309146881104, N 1.0858051776885986
06/19/2024 01:43:43 - INFO - modeling_roberta - Training sub-loss: O 1.0753763914108276, C 1.0791854858398438, E 1.061126470565796, A 1.1239484548568726, N 1.0976582765579224
06/19/2024 01:43:43 - INFO - modeling_roberta - Training sub-loss: O 1.1043224334716797, C 1.0755598545074463, E 1.0665045976638794, A 1.089921236038208, N 1.1013259887695312
06/19/2024 01:43:44 - ERROR - root -  55%|#####4    | 213/390 [11:39<09:38,  3.27s/it]
06/19/2024 01:43:45 - INFO - modeling_roberta - Training sub-loss: O 1.0951497554779053, C 1.102193832397461, E 1.1483033895492554, A 1.0926721096038818, N 1.0902179479599
06/19/2024 01:43:45 - INFO - modeling_roberta - Training sub-loss: O 1.1924896240234375, C 1.0897135734558105, E 1.1042728424072266, A 1.032886028289795, N 1.1082981824874878
06/19/2024 01:43:46 - INFO - modeling_roberta - Training sub-loss: O 1.0986485481262207, C 1.119373083114624, E 1.0491747856140137, A 1.1310418844223022, N 1.1356817483901978
06/19/2024 01:43:46 - INFO - modeling_roberta - Training sub-loss: O 1.0953786373138428, C 1.1058058738708496, E 1.0753722190856934, A 1.1657278537750244, N 1.0865099430084229
06/19/2024 01:43:47 - ERROR - root -  55%|#####4    | 214/390 [11:42<09:31,  3.25s/it]
06/19/2024 01:43:48 - INFO - modeling_roberta - Training sub-loss: O 1.1280627250671387, C 1.1653294563293457, E 1.1291378736495972, A 1.131784439086914, N 1.1234513521194458
06/19/2024 01:43:48 - INFO - modeling_roberta - Training sub-loss: O 1.0985796451568604, C 1.1231516599655151, E 1.0889801979064941, A 1.1065709590911865, N 1.064537525177002
06/19/2024 01:43:50 - INFO - modeling_roberta - Training sub-loss: O 1.1242579221725464, C 1.0813336372375488, E 1.159040927886963, A 1.1143816709518433, N 1.077213168144226
06/19/2024 01:43:50 - INFO - modeling_roberta - Training sub-loss: O 1.1357083320617676, C 1.0894173383712769, E 1.1098260879516602, A 1.0545601844787598, N 1.1479711532592773
06/19/2024 01:43:51 - ERROR - root -  55%|#####5    | 215/390 [11:46<09:27,  3.24s/it]
06/19/2024 01:43:51 - INFO - modeling_roberta - Training sub-loss: O 1.0860247611999512, C 1.0913176536560059, E 1.0921581983566284, A 1.130007266998291, N 1.1234205961227417
06/19/2024 01:43:51 - INFO - modeling_roberta - Training sub-loss: O 1.1849703788757324, C 1.188550591468811, E 1.1412768363952637, A 1.0722436904907227, N 1.1009089946746826
06/19/2024 01:43:53 - INFO - modeling_roberta - Training sub-loss: O 1.103279948234558, C 1.1403610706329346, E 1.1588985919952393, A 1.1075037717819214, N 1.1090946197509766
06/19/2024 01:43:53 - INFO - modeling_roberta - Training sub-loss: O 1.1518833637237549, C 1.113584280014038, E 1.0807915925979614, A 1.0890581607818604, N 1.1066327095031738
06/19/2024 01:43:54 - ERROR - root -  55%|#####5    | 216/390 [11:49<09:23,  3.24s/it]
06/19/2024 01:43:55 - INFO - modeling_roberta - Training sub-loss: O 1.114250659942627, C 1.1349213123321533, E 1.0983715057373047, A 1.0727133750915527, N 1.1384912729263306
06/19/2024 01:43:55 - INFO - modeling_roberta - Training sub-loss: O 1.114069938659668, C 1.1502470970153809, E 1.079851508140564, A 1.098302960395813, N 1.0982121229171753
06/19/2024 01:43:56 - INFO - modeling_roberta - Training sub-loss: O 1.0574445724487305, C 1.10746431350708, E 1.0779342651367188, A 1.1863435506820679, N 1.117485523223877
06/19/2024 01:43:56 - INFO - modeling_roberta - Training sub-loss: O 1.1192100048065186, C 1.0893471240997314, E 1.0877079963684082, A 1.105201244354248, N 1.0807385444641113
06/19/2024 01:43:57 - ERROR - root -  56%|#####5    | 217/390 [11:52<09:18,  3.23s/it]
06/19/2024 01:43:58 - INFO - modeling_roberta - Training sub-loss: O 1.0783497095108032, C 1.0998913049697876, E 1.0583157539367676, A 1.1724989414215088, N 1.1363470554351807
06/19/2024 01:43:58 - INFO - modeling_roberta - Training sub-loss: O 1.1187670230865479, C 1.1477577686309814, E 1.1160529851913452, A 1.0827131271362305, N 1.0497617721557617
06/19/2024 01:43:59 - INFO - modeling_roberta - Training sub-loss: O 1.1361143589019775, C 1.0692121982574463, E 1.0958833694458008, A 1.1270577907562256, N 1.1003087759017944
06/19/2024 01:43:59 - INFO - modeling_roberta - Training sub-loss: O 1.0719492435455322, C 1.1351064443588257, E 1.0863664150238037, A 1.1151423454284668, N 1.0805671215057373
06/19/2024 01:44:00 - ERROR - root -  56%|#####5    | 218/390 [11:55<09:13,  3.22s/it]
06/19/2024 01:44:01 - INFO - modeling_roberta - Training sub-loss: O 1.1137171983718872, C 1.0851263999938965, E 1.0642284154891968, A 1.092237949371338, N 1.0914430618286133
06/19/2024 01:44:01 - INFO - modeling_roberta - Training sub-loss: O 1.037320852279663, C 1.1176893711090088, E 1.1086549758911133, A 1.120086431503296, N 1.05530846118927
06/19/2024 01:44:02 - INFO - modeling_roberta - Training sub-loss: O 1.1128308773040771, C 1.1288187503814697, E 1.1690514087677002, A 1.121699333190918, N 1.1090681552886963
06/19/2024 01:44:02 - INFO - modeling_roberta - Training sub-loss: O 1.0641779899597168, C 1.1029776334762573, E 1.1254420280456543, A 1.1246006488800049, N 1.1289628744125366
06/19/2024 01:44:03 - ERROR - root -  56%|#####6    | 219/390 [11:58<09:08,  3.21s/it]
06/19/2024 01:44:04 - INFO - modeling_roberta - Training sub-loss: O 1.1063703298568726, C 1.1058835983276367, E 1.1224908828735352, A 1.0809528827667236, N 1.0640661716461182
06/19/2024 01:44:04 - INFO - modeling_roberta - Training sub-loss: O 1.1219128370285034, C 1.1248823404312134, E 1.093459129333496, A 1.0871416330337524, N 1.0968610048294067
06/19/2024 01:44:06 - INFO - modeling_roberta - Training sub-loss: O 1.0990266799926758, C 1.1202075481414795, E 1.1182467937469482, A 1.053787112236023, N 1.1623519659042358
06/19/2024 01:44:06 - INFO - modeling_roberta - Training sub-loss: O 1.0941977500915527, C 1.1154237985610962, E 1.082146406173706, A 1.1075530052185059, N 1.1171064376831055
06/19/2024 01:44:07 - ERROR - root -  56%|#####6    | 220/390 [12:02<09:04,  3.20s/it]
06/19/2024 01:44:07 - INFO - root - {'loss': 1.108, 'grad_norm': 70821.421875, 'learning_rate': 4.358974358974359e-05, 'epoch': 2.8}
06/19/2024 01:44:07 - ERROR - root -  56%|#####6    | 220/390 [12:02<09:04,  3.20s/it]
06/19/2024 01:44:07 - INFO - modeling_roberta - Training sub-loss: O 1.055312991142273, C 1.074058175086975, E 1.116965413093567, A 1.1109991073608398, N 1.1060000658035278
06/19/2024 01:44:07 - INFO - modeling_roberta - Training sub-loss: O 1.0929486751556396, C 1.0878719091415405, E 1.1181607246398926, A 1.1701147556304932, N 1.11348295211792
06/19/2024 01:44:09 - INFO - modeling_roberta - Training sub-loss: O 1.0192197561264038, C 1.0924761295318604, E 1.111565351486206, A 1.0974068641662598, N 1.0749704837799072
06/19/2024 01:44:09 - INFO - modeling_roberta - Training sub-loss: O 1.087551236152649, C 1.103245496749878, E 1.124849796295166, A 1.070417881011963, N 1.1255371570587158
06/19/2024 01:44:10 - ERROR - root -  57%|#####6    | 221/390 [12:05<09:03,  3.22s/it]
06/19/2024 01:44:11 - INFO - modeling_roberta - Training sub-loss: O 1.0987470149993896, C 1.1057095527648926, E 1.1145617961883545, A 1.1061427593231201, N 1.0966871976852417
06/19/2024 01:44:11 - INFO - modeling_roberta - Training sub-loss: O 1.0795643329620361, C 1.1470955610275269, E 1.121614933013916, A 1.1162700653076172, N 1.1043877601623535
06/19/2024 01:44:12 - INFO - modeling_roberta - Training sub-loss: O 1.0819759368896484, C 1.1293785572052002, E 1.1173951625823975, A 1.0711097717285156, N 1.0911794900894165
06/19/2024 01:44:12 - INFO - modeling_roberta - Training sub-loss: O 1.0610406398773193, C 1.0958393812179565, E 1.099317193031311, A 1.1160893440246582, N 1.1172561645507812
06/19/2024 01:44:13 - ERROR - root -  57%|#####6    | 222/390 [12:08<08:59,  3.21s/it]
06/19/2024 01:44:14 - INFO - modeling_roberta - Training sub-loss: O 1.089249849319458, C 1.0890722274780273, E 1.0791027545928955, A 1.129468560218811, N 1.1210520267486572
06/19/2024 01:44:14 - INFO - modeling_roberta - Training sub-loss: O 1.1742441654205322, C 1.0912657976150513, E 1.1376392841339111, A 1.094163179397583, N 1.1192104816436768
06/19/2024 01:44:15 - INFO - modeling_roberta - Training sub-loss: O 1.1016086339950562, C 1.1292322874069214, E 1.0877901315689087, A 1.06681489944458, N 1.0789084434509277
06/19/2024 01:44:15 - INFO - modeling_roberta - Training sub-loss: O 1.0965135097503662, C 1.1419105529785156, E 1.0790371894836426, A 1.077092170715332, N 1.1308951377868652
06/19/2024 01:44:16 - ERROR - root -  57%|#####7    | 223/390 [12:11<08:55,  3.20s/it]
06/19/2024 01:44:17 - INFO - modeling_roberta - Training sub-loss: O 1.1655545234680176, C 1.1065700054168701, E 1.111688256263733, A 1.1236252784729004, N 1.122342824935913
06/19/2024 01:44:17 - INFO - modeling_roberta - Training sub-loss: O 1.123875617980957, C 1.033550500869751, E 1.1528887748718262, A 1.0982533693313599, N 1.1497031450271606
06/19/2024 01:44:18 - INFO - modeling_roberta - Training sub-loss: O 1.114466667175293, C 1.092276692390442, E 1.1434621810913086, A 1.1180204153060913, N 1.0771571397781372
06/19/2024 01:44:18 - INFO - modeling_roberta - Training sub-loss: O 1.1896783113479614, C 1.0787934064865112, E 1.115923523902893, A 1.0928198099136353, N 1.0460419654846191
06/19/2024 01:44:19 - ERROR - root -  57%|#####7    | 224/390 [12:14<08:51,  3.20s/it]
06/19/2024 01:44:20 - INFO - modeling_roberta - Training sub-loss: O 1.0860824584960938, C 1.0658222436904907, E 1.0487982034683228, A 1.1158437728881836, N 1.162229061126709
06/19/2024 01:44:20 - INFO - modeling_roberta - Training sub-loss: O 1.131234049797058, C 1.1079649925231934, E 1.0750768184661865, A 1.1258070468902588, N 1.0868871212005615
06/19/2024 01:44:22 - INFO - modeling_roberta - Training sub-loss: O 1.1463282108306885, C 1.1291134357452393, E 1.1380672454833984, A 1.091064214706421, N 1.107118844985962
06/19/2024 01:44:22 - INFO - modeling_roberta - Training sub-loss: O 1.1188719272613525, C 1.1105674505233765, E 1.1405677795410156, A 1.0751926898956299, N 1.0919088125228882
06/19/2024 01:44:23 - ERROR - root -  58%|#####7    | 225/390 [12:18<08:47,  3.20s/it]
06/19/2024 01:44:23 - INFO - modeling_roberta - Training sub-loss: O 1.0849449634552002, C 1.1539386510849, E 1.070957064628601, A 1.1250958442687988, N 1.1185256242752075
06/19/2024 01:44:23 - INFO - modeling_roberta - Training sub-loss: O 1.1116318702697754, C 1.1678524017333984, E 1.0976861715316772, A 1.2001266479492188, N 1.1132234334945679
06/19/2024 01:44:25 - INFO - modeling_roberta - Training sub-loss: O 1.062204360961914, C 1.0997674465179443, E 1.0873818397521973, A 1.0883570909500122, N 1.1172151565551758
06/19/2024 01:44:25 - INFO - modeling_roberta - Training sub-loss: O 1.1043782234191895, C 1.1130456924438477, E 1.0790387392044067, A 1.104079008102417, N 1.115581750869751
06/19/2024 01:44:26 - ERROR - root -  58%|#####7    | 226/390 [12:21<08:45,  3.20s/it]
06/19/2024 01:44:27 - INFO - modeling_roberta - Training sub-loss: O 1.1659741401672363, C 1.074357032775879, E 1.0902446508407593, A 1.0925482511520386, N 1.1033873558044434
06/19/2024 01:44:27 - INFO - modeling_roberta - Training sub-loss: O 1.108888864517212, C 1.1880723237991333, E 1.0869842767715454, A 1.0658650398254395, N 1.112177848815918
06/19/2024 01:44:28 - INFO - modeling_roberta - Training sub-loss: O 1.1139212846755981, C 1.1140921115875244, E 1.064328670501709, A 1.1379948854446411, N 1.1312313079833984
06/19/2024 01:44:28 - INFO - modeling_roberta - Training sub-loss: O 1.1178600788116455, C 1.1034480333328247, E 1.1019282341003418, A 1.083133578300476, N 1.1263272762298584
06/19/2024 01:44:29 - ERROR - root -  58%|#####8    | 227/390 [12:24<08:41,  3.20s/it]
06/19/2024 01:44:30 - INFO - modeling_roberta - Training sub-loss: O 1.0464438199996948, C 1.1460386514663696, E 1.1048083305358887, A 1.117157220840454, N 1.099474310874939
06/19/2024 01:44:30 - INFO - modeling_roberta - Training sub-loss: O 1.145127534866333, C 1.0609474182128906, E 1.1205165386199951, A 1.1231870651245117, N 1.1065468788146973
06/19/2024 01:44:31 - INFO - modeling_roberta - Training sub-loss: O 1.1164677143096924, C 1.0618150234222412, E 1.174272060394287, A 1.0618562698364258, N 1.128309965133667
06/19/2024 01:44:31 - INFO - modeling_roberta - Training sub-loss: O 1.100847601890564, C 1.112686276435852, E 1.1021196842193604, A 1.0854671001434326, N 1.070847511291504
06/19/2024 01:44:32 - ERROR - root -  58%|#####8    | 228/390 [12:27<08:38,  3.20s/it]
06/19/2024 01:44:33 - INFO - modeling_roberta - Training sub-loss: O 1.1186528205871582, C 1.1123864650726318, E 1.1022207736968994, A 1.150247573852539, N 1.065272569656372
06/19/2024 01:44:33 - INFO - modeling_roberta - Training sub-loss: O 1.0961310863494873, C 1.1003763675689697, E 1.0780162811279297, A 1.1055684089660645, N 1.1005606651306152
06/19/2024 01:44:35 - INFO - modeling_roberta - Training sub-loss: O 1.134148359298706, C 1.1025032997131348, E 1.1317410469055176, A 1.1256160736083984, N 1.0236730575561523
06/19/2024 01:44:35 - INFO - modeling_roberta - Training sub-loss: O 1.0359083414077759, C 1.1125030517578125, E 1.076349139213562, A 1.1560837030410767, N 1.095224142074585
06/19/2024 01:44:35 - ERROR - root -  59%|#####8    | 229/390 [12:31<08:36,  3.21s/it]
06/19/2024 01:44:36 - INFO - modeling_roberta - Training sub-loss: O 1.1254358291625977, C 1.1006958484649658, E 1.1102967262268066, A 1.1097832918167114, N 1.0653648376464844
06/19/2024 01:44:36 - INFO - modeling_roberta - Training sub-loss: O 1.094975471496582, C 1.1086034774780273, E 1.0988452434539795, A 1.0915181636810303, N 1.1174583435058594
06/19/2024 01:44:38 - INFO - modeling_roberta - Training sub-loss: O 1.119478464126587, C 1.1068651676177979, E 1.1250932216644287, A 1.1107146739959717, N 1.094264030456543
06/19/2024 01:44:38 - INFO - modeling_roberta - Training sub-loss: O 1.1152801513671875, C 1.1556942462921143, E 1.0889960527420044, A 1.1388273239135742, N 1.1239111423492432
06/19/2024 01:44:39 - ERROR - root -  59%|#####8    | 230/390 [12:34<08:39,  3.25s/it]
06/19/2024 01:44:39 - INFO - root - {'loss': 1.1063, 'grad_norm': 81688.90625, 'learning_rate': 4.1025641025641023e-05, 'epoch': 2.93}
06/19/2024 01:44:39 - ERROR - root -  59%|#####8    | 230/390 [12:34<08:39,  3.25s/it]
06/19/2024 01:44:40 - INFO - modeling_roberta - Training sub-loss: O 1.0734822750091553, C 1.1282861232757568, E 1.063204050064087, A 1.1168549060821533, N 1.096517562866211
06/19/2024 01:44:40 - INFO - modeling_roberta - Training sub-loss: O 1.0995022058486938, C 1.0774112939834595, E 1.1216647624969482, A 1.0349915027618408, N 1.1363627910614014
06/19/2024 01:44:41 - INFO - modeling_roberta - Training sub-loss: O 1.1046512126922607, C 1.0644627809524536, E 1.11098051071167, A 1.0914926528930664, N 1.1690908670425415
06/19/2024 01:44:41 - INFO - modeling_roberta - Training sub-loss: O 1.1058013439178467, C 1.1250945329666138, E 1.0945674180984497, A 1.1448123455047607, N 1.146677851676941
06/19/2024 01:44:42 - ERROR - root -  59%|#####9    | 231/390 [12:37<08:44,  3.30s/it]
06/19/2024 01:44:43 - INFO - modeling_roberta - Training sub-loss: O 1.0485827922821045, C 1.1158974170684814, E 1.0835814476013184, A 1.0870121717453003, N 1.1023478507995605
06/19/2024 01:44:43 - INFO - modeling_roberta - Training sub-loss: O 1.102204442024231, C 1.1163294315338135, E 1.1009324789047241, A 1.1344401836395264, N 1.0791857242584229
06/19/2024 01:44:45 - INFO - modeling_roberta - Training sub-loss: O 1.1138044595718384, C 1.086490273475647, E 1.1555190086364746, A 1.1845673322677612, N 1.1357996463775635
06/19/2024 01:44:45 - INFO - modeling_roberta - Training sub-loss: O 1.115173578262329, C 1.1635382175445557, E 1.084546446800232, A 1.1508266925811768, N 1.0694537162780762
06/19/2024 01:44:45 - ERROR - root -  59%|#####9    | 232/390 [12:41<08:39,  3.29s/it]
06/19/2024 01:44:46 - INFO - modeling_roberta - Training sub-loss: O 1.0840153694152832, C 1.0825453996658325, E 1.0345773696899414, A 1.066925287246704, N 1.1033594608306885
06/19/2024 01:44:46 - INFO - modeling_roberta - Training sub-loss: O 1.1125099658966064, C 1.133897304534912, E 1.1547691822052002, A 1.0691161155700684, N 1.0879888534545898
06/19/2024 01:44:48 - INFO - modeling_roberta - Training sub-loss: O 1.1344579458236694, C 1.138235330581665, E 1.122825264930725, A 1.0923426151275635, N 1.0957168340682983
06/19/2024 01:44:48 - INFO - modeling_roberta - Training sub-loss: O 1.0689401626586914, C 1.0938552618026733, E 1.0978819131851196, A 1.1048563718795776, N 1.13466477394104
06/19/2024 01:44:49 - ERROR - root -  60%|#####9    | 233/390 [12:44<08:34,  3.28s/it]
06/19/2024 01:44:49 - INFO - modeling_roberta - Training sub-loss: O 1.012847661972046, C 1.128130555152893, E 1.0957045555114746, A 1.112813115119934, N 1.094099760055542
06/19/2024 01:44:49 - INFO - modeling_roberta - Training sub-loss: O 1.1571686267852783, C 1.0660679340362549, E 1.0845450162887573, A 1.0494160652160645, N 1.0975972414016724
06/19/2024 01:44:51 - INFO - modeling_roberta - Training sub-loss: O 1.0994539260864258, C 1.1379287242889404, E 1.0814090967178345, A 1.0725922584533691, N 1.1380678415298462
06/19/2024 01:44:51 - INFO - modeling_roberta - Training sub-loss: O 1.2147027254104614, C 1.1083322763442993, E 1.0903974771499634, A 1.1054463386535645, N 1.1531879901885986
06/19/2024 01:44:52 - ERROR - root -  60%|######    | 234/390 [12:47<08:30,  3.27s/it]
06/19/2024 01:44:53 - INFO - modeling_roberta - Training sub-loss: O 1.1236416101455688, C 1.1010329723358154, E 1.150553584098816, A 1.1017706394195557, N 1.1006540060043335
06/19/2024 01:44:53 - INFO - modeling_roberta - Training sub-loss: O 1.1528347730636597, C 1.1388704776763916, E 1.0738142728805542, A 1.0811699628829956, N 1.0840139389038086
06/19/2024 01:44:54 - INFO - modeling_roberta - Training sub-loss: O 1.0748701095581055, C 1.1261547803878784, E 1.0976556539535522, A 1.0761677026748657, N 1.1138126850128174
06/19/2024 01:44:54 - INFO - modeling_roberta - Training sub-loss: O 1.060067892074585, C 1.0721523761749268, E 1.137373685836792, A 1.0828803777694702, N 1.136792540550232
06/19/2024 01:44:55 - ERROR - root -  60%|######    | 235/390 [12:50<08:24,  3.25s/it]
06/19/2024 01:44:56 - INFO - modeling_roberta - Training sub-loss: O 1.1365001201629639, C 1.0952012538909912, E 1.072005271911621, A 1.2179806232452393, N 1.0781739950180054
06/19/2024 01:44:56 - INFO - modeling_roberta - Training sub-loss: O 1.082995891571045, C 1.1222702264785767, E 1.0900466442108154, A 1.157530665397644, N 1.0935099124908447
06/19/2024 01:44:58 - INFO - modeling_roberta - Training sub-loss: O 1.196274757385254, C 1.0569263696670532, E 1.1331517696380615, A 1.086315393447876, N 1.1255106925964355
06/19/2024 01:44:58 - INFO - modeling_roberta - Training sub-loss: O 1.0391693115234375, C 1.130496621131897, E 1.102869987487793, A 1.109931230545044, N 1.1004503965377808
06/19/2024 01:44:59 - ERROR - root -  61%|######    | 236/390 [12:54<09:04,  3.53s/it]
06/19/2024 01:45:00 - INFO - modeling_roberta - Training sub-loss: O 1.1115524768829346, C 1.1165212392807007, E 1.1002438068389893, A 1.12586510181427, N 1.0963584184646606
06/19/2024 01:45:00 - INFO - modeling_roberta - Training sub-loss: O 1.164894938468933, C 1.1065664291381836, E 1.0618754625320435, A 1.078355312347412, N 1.1304751634597778
06/19/2024 01:45:02 - INFO - modeling_roberta - Training sub-loss: O 1.1402597427368164, C 1.0895532369613647, E 1.0785768032073975, A 1.0592281818389893, N 1.138756275177002
06/19/2024 01:45:02 - INFO - modeling_roberta - Training sub-loss: O 1.070754885673523, C 1.1061815023422241, E 1.093139410018921, A 1.116624355316162, N 1.0795875787734985
06/19/2024 01:45:03 - ERROR - root -  61%|######    | 237/390 [12:58<08:53,  3.49s/it]
06/19/2024 01:45:03 - INFO - modeling_roberta - Training sub-loss: O 1.181619644165039, C 1.0689282417297363, E 1.1401684284210205, A 1.1265910863876343, N 1.0631470680236816
06/19/2024 01:45:03 - INFO - modeling_roberta - Training sub-loss: O 1.1103423833847046, C 1.1257874965667725, E 1.0945420265197754, A 1.0774996280670166, N 1.1541014909744263
06/19/2024 01:45:05 - INFO - modeling_roberta - Training sub-loss: O 1.136733055114746, C 1.1225056648254395, E 1.0804553031921387, A 1.12867271900177, N 1.1640971899032593
06/19/2024 01:45:05 - INFO - modeling_roberta - Training sub-loss: O 1.145538091659546, C 1.1008684635162354, E 1.106846809387207, A 1.0499682426452637, N 1.1785461902618408
06/19/2024 01:45:06 - ERROR - root -  61%|######1   | 238/390 [13:01<08:40,  3.42s/it]
06/19/2024 01:45:07 - INFO - modeling_roberta - Training sub-loss: O 1.144065260887146, C 1.0679399967193604, E 1.0500309467315674, A 1.0581226348876953, N 1.1632426977157593
06/19/2024 01:45:07 - INFO - modeling_roberta - Training sub-loss: O 1.1066313982009888, C 1.0635733604431152, E 1.0842399597167969, A 1.1331995725631714, N 1.0586892366409302
06/19/2024 01:45:08 - INFO - modeling_roberta - Training sub-loss: O 1.0651869773864746, C 1.070717215538025, E 1.1149975061416626, A 1.1025311946868896, N 1.162639856338501
06/19/2024 01:45:08 - INFO - modeling_roberta - Training sub-loss: O 1.098214864730835, C 1.1403025388717651, E 1.0839931964874268, A 1.1037877798080444, N 1.1001029014587402
06/19/2024 01:45:09 - ERROR - root -  61%|######1   | 239/390 [13:04<08:30,  3.38s/it]
06/19/2024 01:45:10 - INFO - modeling_roberta - Training sub-loss: O 1.108260989189148, C 1.182002305984497, E 1.0931825637817383, A 1.1221778392791748, N 1.085458755493164
06/19/2024 01:45:10 - INFO - modeling_roberta - Training sub-loss: O 1.101696252822876, C 1.085984468460083, E 1.080464482307434, A 1.0813992023468018, N 1.097328782081604
06/19/2024 01:45:12 - INFO - modeling_roberta - Training sub-loss: O 1.10675048828125, C 1.1061651706695557, E 1.121891975402832, A 1.0903594493865967, N 1.0829623937606812
06/19/2024 01:45:12 - INFO - modeling_roberta - Training sub-loss: O 1.0508513450622559, C 1.125890851020813, E 1.1512316465377808, A 1.0719897747039795, N 1.1227970123291016
06/19/2024 01:45:13 - ERROR - root -  62%|######1   | 240/390 [13:08<08:19,  3.33s/it]
06/19/2024 01:45:13 - INFO - root - {'loss': 1.1061, 'grad_norm': 67843.0390625, 'learning_rate': 3.846153846153846e-05, 'epoch': 3.06}
06/19/2024 01:45:13 - ERROR - root -  62%|######1   | 240/390 [13:08<08:19,  3.33s/it]
06/19/2024 01:45:13 - INFO - modeling_roberta - Training sub-loss: O 1.086948275566101, C 1.1358709335327148, E 1.0799016952514648, A 1.0569219589233398, N 1.0741569995880127
06/19/2024 01:45:13 - INFO - modeling_roberta - Training sub-loss: O 1.1217143535614014, C 1.1496050357818604, E 1.1422353982925415, A 1.0917906761169434, N 1.1725029945373535
06/19/2024 01:45:15 - INFO - modeling_roberta - Training sub-loss: O 1.0825231075286865, C 1.1516717672348022, E 1.1495517492294312, A 1.1046994924545288, N 1.0262963771820068
06/19/2024 01:45:15 - INFO - modeling_roberta - Training sub-loss: O 1.1203804016113281, C 1.1305224895477295, E 1.111870288848877, A 1.129698395729065, N 1.0658700466156006
06/19/2024 01:45:16 - ERROR - root -  62%|######1   | 241/390 [13:11<08:12,  3.31s/it]
06/19/2024 01:45:16 - INFO - modeling_roberta - Training sub-loss: O 1.1560882329940796, C 1.0932468175888062, E 1.1406702995300293, A 1.1196997165679932, N 1.1845214366912842
06/19/2024 01:45:16 - INFO - modeling_roberta - Training sub-loss: O 1.0587228536605835, C 1.099910020828247, E 1.185943365097046, A 1.0703718662261963, N 1.0655611753463745
06/19/2024 01:45:18 - INFO - modeling_roberta - Training sub-loss: O 1.1528226137161255, C 1.0845153331756592, E 1.083781123161316, A 1.133954405784607, N 1.1146162748336792
06/19/2024 01:45:18 - INFO - modeling_roberta - Training sub-loss: O 1.0411450862884521, C 1.1252033710479736, E 1.0663098096847534, A 1.0550854206085205, N 1.1710052490234375
06/19/2024 01:45:19 - ERROR - root -  62%|######2   | 242/390 [13:14<08:04,  3.27s/it]
06/19/2024 01:45:20 - INFO - modeling_roberta - Training sub-loss: O 1.111952781677246, C 1.1489288806915283, E 1.0709569454193115, A 1.13921320438385, N 1.0876882076263428
06/19/2024 01:45:20 - INFO - modeling_roberta - Training sub-loss: O 1.1092339754104614, C 1.1482913494110107, E 1.1388884782791138, A 1.109226942062378, N 1.122566819190979
06/19/2024 01:45:21 - INFO - modeling_roberta - Training sub-loss: O 1.092442274093628, C 1.0805268287658691, E 1.0573639869689941, A 1.1419875621795654, N 1.0847159624099731
06/19/2024 01:45:21 - INFO - modeling_roberta - Training sub-loss: O 1.1217498779296875, C 1.0441642999649048, E 1.1720449924468994, A 1.0948894023895264, N 1.06614089012146
06/19/2024 01:45:22 - ERROR - root -  62%|######2   | 243/390 [13:17<07:57,  3.25s/it]
06/19/2024 01:45:23 - INFO - modeling_roberta - Training sub-loss: O 1.1032339334487915, C 1.1992038488388062, E 1.104087233543396, A 1.1531434059143066, N 1.094834804534912
06/19/2024 01:45:23 - INFO - modeling_roberta - Training sub-loss: O 1.0972048044204712, C 1.0614280700683594, E 1.1060067415237427, A 1.1271419525146484, N 1.0756564140319824
06/19/2024 01:45:24 - INFO - modeling_roberta - Training sub-loss: O 1.1122052669525146, C 1.0964666604995728, E 1.1090912818908691, A 1.1185835599899292, N 1.1356011629104614
06/19/2024 01:45:24 - INFO - modeling_roberta - Training sub-loss: O 1.1072038412094116, C 1.0573571920394897, E 1.1146435737609863, A 1.1142873764038086, N 1.1246452331542969
06/19/2024 01:45:25 - ERROR - root -  63%|######2   | 244/390 [13:20<07:52,  3.23s/it]
06/19/2024 01:45:26 - INFO - modeling_roberta - Training sub-loss: O 1.0969518423080444, C 1.0741169452667236, E 1.117647647857666, A 1.1081410646438599, N 1.1055021286010742
06/19/2024 01:45:26 - INFO - modeling_roberta - Training sub-loss: O 1.1090412139892578, C 1.0195232629776, E 1.0610313415527344, A 1.1491353511810303, N 1.1393773555755615
06/19/2024 01:45:28 - INFO - modeling_roberta - Training sub-loss: O 1.1015498638153076, C 1.0830779075622559, E 1.1192710399627686, A 1.0930601358413696, N 1.084932804107666
06/19/2024 01:45:28 - INFO - modeling_roberta - Training sub-loss: O 1.159277081489563, C 1.1338448524475098, E 1.0588445663452148, A 1.0745606422424316, N 1.1420248746871948
06/19/2024 01:45:29 - ERROR - root -  63%|######2   | 245/390 [13:24<07:47,  3.22s/it]
06/19/2024 01:45:29 - INFO - modeling_roberta - Training sub-loss: O 1.1131606101989746, C 1.062609076499939, E 1.132555603981018, A 1.095555067062378, N 1.1228036880493164
06/19/2024 01:45:29 - INFO - modeling_roberta - Training sub-loss: O 1.1125462055206299, C 1.0874590873718262, E 1.1371358633041382, A 1.0885846614837646, N 1.1211539506912231
06/19/2024 01:45:31 - INFO - modeling_roberta - Training sub-loss: O 1.0942012071609497, C 1.0859060287475586, E 1.103545069694519, A 1.1058237552642822, N 1.0969529151916504
06/19/2024 01:45:31 - INFO - modeling_roberta - Training sub-loss: O 1.1087121963500977, C 1.1434285640716553, E 1.0924009084701538, A 1.1054394245147705, N 1.0891603231430054
06/19/2024 01:45:32 - ERROR - root -  63%|######3   | 246/390 [13:27<07:42,  3.21s/it]
06/19/2024 01:45:32 - INFO - modeling_roberta - Training sub-loss: O 1.111143708229065, C 1.1070141792297363, E 1.0823200941085815, A 1.1168851852416992, N 1.1335623264312744
06/19/2024 01:45:32 - INFO - modeling_roberta - Training sub-loss: O 1.1264041662216187, C 1.1393020153045654, E 1.0951576232910156, A 1.0749719142913818, N 1.083237648010254
06/19/2024 01:45:34 - INFO - modeling_roberta - Training sub-loss: O 1.0875365734100342, C 1.087627649307251, E 1.079900860786438, A 1.1285048723220825, N 1.0986405611038208
06/19/2024 01:45:34 - INFO - modeling_roberta - Training sub-loss: O 1.0966811180114746, C 1.0940299034118652, E 1.0968029499053955, A 1.1784062385559082, N 1.0317366123199463
06/19/2024 01:45:35 - ERROR - root -  63%|######3   | 247/390 [13:30<07:38,  3.21s/it]
06/19/2024 01:45:36 - INFO - modeling_roberta - Training sub-loss: O 1.0691672563552856, C 1.1052472591400146, E 1.1198948621749878, A 1.1003289222717285, N 1.1413878202438354
06/19/2024 01:45:36 - INFO - modeling_roberta - Training sub-loss: O 1.0928648710250854, C 1.1106023788452148, E 1.136612892150879, A 1.0981817245483398, N 1.1113395690917969
06/19/2024 01:45:37 - INFO - modeling_roberta - Training sub-loss: O 1.117616891860962, C 1.1085443496704102, E 1.1292545795440674, A 1.1272776126861572, N 1.069887638092041
06/19/2024 01:45:37 - INFO - modeling_roberta - Training sub-loss: O 1.0731083154678345, C 1.1212421655654907, E 1.150774598121643, A 1.1231505870819092, N 1.10007643699646
06/19/2024 01:45:38 - ERROR - root -  64%|######3   | 248/390 [13:33<07:35,  3.20s/it]
06/19/2024 01:45:39 - INFO - modeling_roberta - Training sub-loss: O 1.1201839447021484, C 1.0945470333099365, E 1.1258244514465332, A 1.1495686769485474, N 1.0829226970672607
06/19/2024 01:45:39 - INFO - modeling_roberta - Training sub-loss: O 1.1133803129196167, C 1.1520006656646729, E 1.1150590181350708, A 1.0649619102478027, N 1.1368913650512695
06/19/2024 01:45:40 - INFO - modeling_roberta - Training sub-loss: O 1.1016709804534912, C 1.0962896347045898, E 1.0941632986068726, A 1.118374228477478, N 1.1181550025939941
06/19/2024 01:45:40 - INFO - modeling_roberta - Training sub-loss: O 1.127119779586792, C 1.0860838890075684, E 1.1264870166778564, A 1.0896496772766113, N 1.1231753826141357
06/19/2024 01:45:41 - ERROR - root -  64%|######3   | 249/390 [13:36<07:30,  3.20s/it]
06/19/2024 01:45:42 - INFO - modeling_roberta - Training sub-loss: O 1.0866280794143677, C 1.072345495223999, E 1.1035680770874023, A 1.119640588760376, N 1.1170966625213623
06/19/2024 01:45:42 - INFO - modeling_roberta - Training sub-loss: O 1.1164302825927734, C 1.0895954370498657, E 1.057860016822815, A 1.1277823448181152, N 1.1502817869186401
06/19/2024 01:45:44 - INFO - modeling_roberta - Training sub-loss: O 1.0766175985336304, C 1.0742201805114746, E 1.1198196411132812, A 1.0858772993087769, N 1.1153109073638916
06/19/2024 01:45:44 - INFO - modeling_roberta - Training sub-loss: O 1.1624550819396973, C 1.0882371664047241, E 1.0846542119979858, A 1.0754270553588867, N 1.113759994506836
06/19/2024 01:45:45 - ERROR - root -  64%|######4   | 250/390 [13:40<07:27,  3.20s/it]
06/19/2024 01:45:45 - INFO - root - {'loss': 1.107, 'grad_norm': 70980.34375, 'learning_rate': 3.58974358974359e-05, 'epoch': 3.18}
06/19/2024 01:45:45 - ERROR - root -  64%|######4   | 250/390 [13:40<07:27,  3.20s/it]
06/19/2024 01:45:45 - INFO - modeling_roberta - Training sub-loss: O 1.1194392442703247, C 1.070508599281311, E 1.0847892761230469, A 1.1270033121109009, N 1.095255970954895
06/19/2024 01:45:45 - INFO - modeling_roberta - Training sub-loss: O 1.0986907482147217, C 1.035003900527954, E 1.1325019598007202, A 1.097912311553955, N 1.1060541868209839
06/19/2024 01:45:47 - INFO - modeling_roberta - Training sub-loss: O 1.1032466888427734, C 1.059870958328247, E 1.0700186491012573, A 1.1580511331558228, N 1.0713478326797485
06/19/2024 01:45:47 - INFO - modeling_roberta - Training sub-loss: O 1.0752203464508057, C 1.1476246118545532, E 1.1166504621505737, A 1.1604130268096924, N 1.1445163488388062
06/19/2024 01:45:48 - ERROR - root -  64%|######4   | 251/390 [13:43<07:25,  3.21s/it]
06/19/2024 01:45:48 - INFO - modeling_roberta - Training sub-loss: O 1.0891772508621216, C 1.0748441219329834, E 1.1256085634231567, A 1.15179443359375, N 1.1360219717025757
06/19/2024 01:45:48 - INFO - modeling_roberta - Training sub-loss: O 1.095075011253357, C 1.1448993682861328, E 1.093440055847168, A 1.0767576694488525, N 1.0859155654907227
06/19/2024 01:45:50 - INFO - modeling_roberta - Training sub-loss: O 1.1094751358032227, C 1.0971240997314453, E 1.0119659900665283, A 1.1075750589370728, N 1.1218628883361816
06/19/2024 01:45:50 - INFO - modeling_roberta - Training sub-loss: O 1.1388553380966187, C 1.0936996936798096, E 1.1018295288085938, A 1.0427311658859253, N 1.1092888116836548
06/19/2024 01:45:51 - ERROR - root -  65%|######4   | 252/390 [13:46<07:22,  3.20s/it]
06/19/2024 01:45:52 - INFO - modeling_roberta - Training sub-loss: O 1.1125946044921875, C 1.0943278074264526, E 1.1257293224334717, A 1.1017470359802246, N 1.1134952306747437
06/19/2024 01:45:52 - INFO - modeling_roberta - Training sub-loss: O 1.122713565826416, C 1.0978786945343018, E 1.0822553634643555, A 1.0949959754943848, N 1.1180284023284912
06/19/2024 01:45:53 - INFO - modeling_roberta - Training sub-loss: O 1.0999600887298584, C 1.1526479721069336, E 1.0594549179077148, A 1.1306231021881104, N 1.1388146877288818
06/19/2024 01:45:53 - INFO - modeling_roberta - Training sub-loss: O 1.0993876457214355, C 1.1503229141235352, E 1.137729287147522, A 1.1459574699401855, N 1.1011511087417603
06/19/2024 01:45:54 - ERROR - root -  65%|######4   | 253/390 [13:49<07:18,  3.20s/it]
06/19/2024 01:45:55 - INFO - modeling_roberta - Training sub-loss: O 1.1172255277633667, C 1.1619760990142822, E 1.0672798156738281, A 1.0955405235290527, N 1.0980088710784912
06/19/2024 01:45:55 - INFO - modeling_roberta - Training sub-loss: O 1.11359441280365, C 1.123741865158081, E 1.0722163915634155, A 1.1278554201126099, N 1.1154241561889648
06/19/2024 01:45:56 - INFO - modeling_roberta - Training sub-loss: O 1.083669900894165, C 1.1354743242263794, E 1.0907517671585083, A 1.1328074932098389, N 1.1611616611480713
06/19/2024 01:45:56 - INFO - modeling_roberta - Training sub-loss: O 1.0753741264343262, C 1.1064543724060059, E 1.0881307125091553, A 1.1256229877471924, N 1.1130919456481934
06/19/2024 01:45:57 - ERROR - root -  65%|######5   | 254/390 [13:52<07:15,  3.20s/it]
06/19/2024 01:45:58 - INFO - modeling_roberta - Training sub-loss: O 1.0720419883728027, C 1.1551306247711182, E 1.0881264209747314, A 1.108802080154419, N 1.0718449354171753
06/19/2024 01:45:58 - INFO - modeling_roberta - Training sub-loss: O 1.0569744110107422, C 1.0914950370788574, E 1.1155771017074585, A 1.094137191772461, N 1.0993123054504395
06/19/2024 01:46:00 - INFO - modeling_roberta - Training sub-loss: O 1.106704831123352, C 1.0828955173492432, E 1.1055066585540771, A 1.124076247215271, N 1.0878779888153076
06/19/2024 01:46:00 - INFO - modeling_roberta - Training sub-loss: O 1.0729329586029053, C 1.1021095514297485, E 1.0818827152252197, A 1.1260725259780884, N 1.1262538433074951
06/19/2024 01:46:01 - ERROR - root -  65%|######5   | 255/390 [13:56<07:33,  3.36s/it]
06/19/2024 01:46:02 - INFO - modeling_roberta - Training sub-loss: O 1.105715036392212, C 1.0605285167694092, E 1.1104426383972168, A 1.0809531211853027, N 1.1067639589309692
06/19/2024 01:46:02 - INFO - modeling_roberta - Training sub-loss: O 1.105358362197876, C 1.076676845550537, E 1.0976347923278809, A 1.143078327178955, N 1.0642993450164795
06/19/2024 01:46:03 - INFO - modeling_roberta - Training sub-loss: O 1.0898914337158203, C 1.1240475177764893, E 1.0947515964508057, A 1.0775588750839233, N 1.127963900566101
06/19/2024 01:46:03 - INFO - modeling_roberta - Training sub-loss: O 1.1251016855239868, C 1.07601797580719, E 1.138572335243225, A 1.0890758037567139, N 1.087782859802246
06/19/2024 01:46:04 - ERROR - root -  66%|######5   | 256/390 [13:59<07:23,  3.31s/it]
06/19/2024 01:46:05 - INFO - modeling_roberta - Training sub-loss: O 1.1254732608795166, C 1.099599838256836, E 1.110690712928772, A 1.1274988651275635, N 1.0922316312789917
06/19/2024 01:46:05 - INFO - modeling_roberta - Training sub-loss: O 1.1034111976623535, C 1.0745493173599243, E 1.0964784622192383, A 1.087634801864624, N 1.1081106662750244
06/19/2024 01:46:07 - INFO - modeling_roberta - Training sub-loss: O 1.111399531364441, C 1.1380391120910645, E 1.0665310621261597, A 1.130448341369629, N 1.1168112754821777
06/19/2024 01:46:07 - INFO - modeling_roberta - Training sub-loss: O 1.086796522140503, C 1.1712915897369385, E 1.10155189037323, A 1.0929696559906006, N 1.0784459114074707
06/19/2024 01:46:07 - ERROR - root -  66%|######5   | 257/390 [14:03<07:15,  3.28s/it]
06/19/2024 01:46:08 - INFO - modeling_roberta - Training sub-loss: O 1.0793483257293701, C 1.1388850212097168, E 1.0967350006103516, A 1.1266582012176514, N 1.1157371997833252
06/19/2024 01:46:08 - INFO - modeling_roberta - Training sub-loss: O 1.119429349899292, C 1.0785231590270996, E 1.0910162925720215, A 1.1226940155029297, N 1.1077165603637695
06/19/2024 01:46:10 - INFO - modeling_roberta - Training sub-loss: O 1.0850664377212524, C 1.1626909971237183, E 1.0888642072677612, A 1.089708685874939, N 1.149366855621338
06/19/2024 01:46:10 - INFO - modeling_roberta - Training sub-loss: O 1.0912225246429443, C 1.1175475120544434, E 1.0864856243133545, A 1.0957376956939697, N 1.1053080558776855
06/19/2024 01:46:11 - ERROR - root -  66%|######6   | 258/390 [14:06<07:09,  3.25s/it]
06/19/2024 01:46:11 - INFO - modeling_roberta - Training sub-loss: O 1.0697216987609863, C 1.0822153091430664, E 1.1353040933609009, A 1.096085786819458, N 1.080223798751831
06/19/2024 01:46:11 - INFO - modeling_roberta - Training sub-loss: O 1.088312029838562, C 1.0935779809951782, E 1.1509079933166504, A 1.1234593391418457, N 1.1187721490859985
06/19/2024 01:46:13 - INFO - modeling_roberta - Training sub-loss: O 1.1089285612106323, C 1.1197949647903442, E 1.154731273651123, A 1.1000014543533325, N 1.09776771068573
06/19/2024 01:46:13 - INFO - modeling_roberta - Training sub-loss: O 1.1312172412872314, C 1.0789175033569336, E 1.0384047031402588, A 1.0796297788619995, N 1.10337233543396
06/19/2024 01:46:14 - ERROR - root -  66%|######6   | 259/390 [14:09<07:04,  3.24s/it]
06/19/2024 01:46:15 - INFO - modeling_roberta - Training sub-loss: O 1.080593466758728, C 1.1297178268432617, E 1.0874284505844116, A 1.120936393737793, N 1.0971192121505737
06/19/2024 01:46:15 - INFO - modeling_roberta - Training sub-loss: O 1.0874228477478027, C 1.110337734222412, E 1.1054813861846924, A 1.1166224479675293, N 1.1450995206832886
06/19/2024 01:46:16 - INFO - modeling_roberta - Training sub-loss: O 1.1254955530166626, C 1.0877389907836914, E 1.0884387493133545, A 1.0891934633255005, N 1.171640396118164
06/19/2024 01:46:16 - INFO - modeling_roberta - Training sub-loss: O 1.1157243251800537, C 1.1479933261871338, E 1.081477403640747, A 1.0788261890411377, N 1.1922494173049927
06/19/2024 01:46:17 - ERROR - root -  67%|######6   | 260/390 [14:12<07:02,  3.25s/it]
06/19/2024 01:46:17 - INFO - root - {'loss': 1.1055, 'grad_norm': 55941.1171875, 'learning_rate': 3.3333333333333335e-05, 'epoch': 3.31}
06/19/2024 01:46:17 - ERROR - root -  67%|######6   | 260/390 [14:12<07:02,  3.25s/it]
06/19/2024 01:46:18 - INFO - modeling_roberta - Training sub-loss: O 1.1021790504455566, C 1.0888298749923706, E 1.0638149976730347, A 1.1177341938018799, N 1.061198353767395
06/19/2024 01:46:18 - INFO - modeling_roberta - Training sub-loss: O 1.0872340202331543, C 1.1018986701965332, E 1.0848488807678223, A 1.1319169998168945, N 1.0879671573638916
06/19/2024 01:46:19 - INFO - modeling_roberta - Training sub-loss: O 1.1034579277038574, C 1.1134324073791504, E 1.104102373123169, A 1.1318341493606567, N 1.1588795185089111
06/19/2024 01:46:19 - INFO - modeling_roberta - Training sub-loss: O 1.0468201637268066, C 1.0995525121688843, E 1.1545915603637695, A 1.0754868984222412, N 1.1021230220794678
06/19/2024 01:46:20 - ERROR - root -  67%|######6   | 261/390 [14:16<07:02,  3.27s/it]
06/19/2024 01:46:21 - INFO - modeling_roberta - Training sub-loss: O 1.1154544353485107, C 1.1125073432922363, E 1.0987180471420288, A 1.093191385269165, N 1.0742390155792236
06/19/2024 01:46:21 - INFO - modeling_roberta - Training sub-loss: O 1.0872855186462402, C 1.1121670007705688, E 1.0779845714569092, A 1.0610110759735107, N 1.0970486402511597
06/19/2024 01:46:23 - INFO - modeling_roberta - Training sub-loss: O 1.0555553436279297, C 1.063154697418213, E 1.1036028861999512, A 1.0936086177825928, N 1.1146957874298096
06/19/2024 01:46:23 - INFO - modeling_roberta - Training sub-loss: O 1.0988960266113281, C 1.0859153270721436, E 1.0659055709838867, A 1.126237392425537, N 1.1187748908996582
06/19/2024 01:46:24 - ERROR - root -  67%|######7   | 262/390 [14:19<07:04,  3.32s/it]
06/19/2024 01:46:25 - INFO - modeling_roberta - Training sub-loss: O 1.0804979801177979, C 1.1021748781204224, E 1.0873208045959473, A 1.1172772645950317, N 1.1240136623382568
06/19/2024 01:46:25 - INFO - modeling_roberta - Training sub-loss: O 1.095401406288147, C 1.0896196365356445, E 1.1000841856002808, A 1.1185721158981323, N 1.0837351083755493
06/19/2024 01:46:26 - INFO - modeling_roberta - Training sub-loss: O 1.0734014511108398, C 1.1359707117080688, E 1.0731552839279175, A 1.1133947372436523, N 1.0511051416397095
06/19/2024 01:46:26 - INFO - modeling_roberta - Training sub-loss: O 1.1114330291748047, C 1.1087660789489746, E 1.1031708717346191, A 1.130752682685852, N 1.1317088603973389
06/19/2024 01:46:27 - ERROR - root -  67%|######7   | 263/390 [14:22<07:07,  3.36s/it]
06/19/2024 01:46:28 - INFO - modeling_roberta - Training sub-loss: O 1.1633610725402832, C 1.1024819612503052, E 1.113186001777649, A 1.0653221607208252, N 1.1126328706741333
06/19/2024 01:46:28 - INFO - modeling_roberta - Training sub-loss: O 1.1415801048278809, C 1.0750271081924438, E 1.1105952262878418, A 1.1418381929397583, N 1.0983545780181885
06/19/2024 01:46:30 - INFO - modeling_roberta - Training sub-loss: O 1.122334599494934, C 1.114762783050537, E 1.0949069261550903, A 1.0904144048690796, N 1.0960408449172974
06/19/2024 01:46:30 - INFO - modeling_roberta - Training sub-loss: O 1.0464394092559814, C 1.10247802734375, E 1.1225782632827759, A 1.1122698783874512, N 1.0564526319503784
06/19/2024 01:46:31 - ERROR - root -  68%|######7   | 264/390 [14:26<07:09,  3.41s/it]
06/19/2024 01:46:32 - INFO - modeling_roberta - Training sub-loss: O 1.117928147315979, C 1.094932198524475, E 1.1843724250793457, A 1.1527066230773926, N 1.1035492420196533
06/19/2024 01:46:32 - INFO - modeling_roberta - Training sub-loss: O 1.1349085569381714, C 1.166583776473999, E 1.0733141899108887, A 1.060614824295044, N 1.1318773031234741
06/19/2024 01:46:33 - INFO - modeling_roberta - Training sub-loss: O 1.0750396251678467, C 1.0978248119354248, E 1.119511365890503, A 1.0727512836456299, N 1.1177490949630737
06/19/2024 01:46:33 - INFO - modeling_roberta - Training sub-loss: O 1.0719146728515625, C 1.0798444747924805, E 1.1238917112350464, A 1.1136226654052734, N 1.1155706644058228
06/19/2024 01:46:34 - ERROR - root -  68%|######7   | 265/390 [14:29<07:03,  3.39s/it]
06/19/2024 01:46:35 - INFO - modeling_roberta - Training sub-loss: O 1.1146066188812256, C 1.1462022066116333, E 1.103840947151184, A 1.1107208728790283, N 1.0826570987701416
06/19/2024 01:46:35 - INFO - modeling_roberta - Training sub-loss: O 1.0843130350112915, C 1.1564829349517822, E 1.0855276584625244, A 1.110764503479004, N 1.11289644241333
06/19/2024 01:46:37 - INFO - modeling_roberta - Training sub-loss: O 1.145950436592102, C 1.0976452827453613, E 1.0692954063415527, A 1.0995986461639404, N 1.0795154571533203
06/19/2024 01:46:37 - INFO - modeling_roberta - Training sub-loss: O 1.1305131912231445, C 1.090130090713501, E 1.1391947269439697, A 1.1050605773925781, N 1.0809171199798584
06/19/2024 01:46:38 - ERROR - root -  68%|######8   | 266/390 [14:33<07:04,  3.42s/it]
06/19/2024 01:46:38 - INFO - modeling_roberta - Training sub-loss: O 1.1010390520095825, C 1.110236644744873, E 1.1668970584869385, A 1.121964693069458, N 1.1237502098083496
06/19/2024 01:46:38 - INFO - modeling_roberta - Training sub-loss: O 1.1370657682418823, C 1.139472484588623, E 1.0849885940551758, A 1.1345480680465698, N 1.0863456726074219
06/19/2024 01:46:40 - INFO - modeling_roberta - Training sub-loss: O 1.0968533754348755, C 1.0815539360046387, E 1.091552972793579, A 1.0504424571990967, N 1.1289303302764893
06/19/2024 01:46:40 - INFO - modeling_roberta - Training sub-loss: O 1.082146406173706, C 1.0839825868606567, E 1.1403486728668213, A 1.1265267133712769, N 1.1194994449615479
06/19/2024 01:46:41 - ERROR - root -  68%|######8   | 267/390 [14:36<07:01,  3.43s/it]
06/19/2024 01:46:42 - INFO - modeling_roberta - Training sub-loss: O 1.0621832609176636, C 1.134877324104309, E 1.1102094650268555, A 1.1424452066421509, N 1.0860453844070435
06/19/2024 01:46:42 - INFO - modeling_roberta - Training sub-loss: O 1.091806411743164, C 1.1279499530792236, E 1.1045525074005127, A 1.1523183584213257, N 1.0984656810760498
06/19/2024 01:46:44 - INFO - modeling_roberta - Training sub-loss: O 1.0844597816467285, C 1.120171070098877, E 1.0670130252838135, A 1.1007471084594727, N 1.1233668327331543
06/19/2024 01:46:44 - INFO - modeling_roberta - Training sub-loss: O 1.047532081604004, C 1.039024829864502, E 1.0710633993148804, A 1.117492914199829, N 1.1186463832855225
06/19/2024 01:46:45 - ERROR - root -  69%|######8   | 268/390 [14:40<06:58,  3.43s/it]
06/19/2024 01:46:45 - INFO - modeling_roberta - Training sub-loss: O 1.0620691776275635, C 1.11275315284729, E 1.096434235572815, A 1.1097264289855957, N 1.1313841342926025
06/19/2024 01:46:45 - INFO - modeling_roberta - Training sub-loss: O 1.1302216053009033, C 1.1255040168762207, E 1.0684809684753418, A 1.0888043642044067, N 1.078530192375183
06/19/2024 01:46:47 - INFO - modeling_roberta - Training sub-loss: O 1.0600652694702148, C 1.0930516719818115, E 1.0816645622253418, A 1.1236138343811035, N 1.0994532108306885
06/19/2024 01:46:47 - INFO - modeling_roberta - Training sub-loss: O 1.0953764915466309, C 1.115939736366272, E 1.1108360290527344, A 1.0938506126403809, N 1.1311265230178833
06/19/2024 01:46:48 - ERROR - root -  69%|######8   | 269/390 [14:43<06:56,  3.44s/it]
06/19/2024 01:46:49 - INFO - modeling_roberta - Training sub-loss: O 1.117238998413086, C 1.105056881904602, E 1.1013562679290771, A 1.0845216512680054, N 1.0534560680389404
06/19/2024 01:46:49 - INFO - modeling_roberta - Training sub-loss: O 1.1617313623428345, C 1.1561627388000488, E 1.0964288711547852, A 1.1075105667114258, N 1.0917503833770752
06/19/2024 01:46:50 - INFO - modeling_roberta - Training sub-loss: O 1.1081559658050537, C 1.089858055114746, E 1.0965447425842285, A 1.081400990486145, N 1.108946442604065
06/19/2024 01:46:50 - INFO - modeling_roberta - Training sub-loss: O 1.089577317237854, C 1.122408390045166, E 1.0949959754943848, A 1.0604114532470703, N 1.1432921886444092
06/19/2024 01:46:52 - ERROR - root -  69%|######9   | 270/390 [14:47<06:53,  3.45s/it]
06/19/2024 01:46:52 - INFO - root - {'loss': 1.1032, 'grad_norm': 48495.9375, 'learning_rate': 3.0769230769230774e-05, 'epoch': 3.44}
06/19/2024 01:46:52 - ERROR - root -  69%|######9   | 270/390 [14:47<06:53,  3.45s/it]
06/19/2024 01:46:52 - INFO - modeling_roberta - Training sub-loss: O 1.0550391674041748, C 1.1041617393493652, E 1.099312424659729, A 1.0993107557296753, N 1.0954936742782593
06/19/2024 01:46:52 - INFO - modeling_roberta - Training sub-loss: O 1.0971879959106445, C 1.1027581691741943, E 1.128525972366333, A 1.1160387992858887, N 1.1025209426879883
06/19/2024 01:46:54 - INFO - modeling_roberta - Training sub-loss: O 1.1172435283660889, C 1.1012537479400635, E 1.1220784187316895, A 1.0881972312927246, N 1.1068017482757568
06/19/2024 01:46:54 - INFO - modeling_roberta - Training sub-loss: O 1.0955990552902222, C 1.1173603534698486, E 1.1555190086364746, A 1.0906373262405396, N 1.051174521446228
06/19/2024 01:46:55 - ERROR - root -  69%|######9   | 271/390 [14:50<06:57,  3.51s/it]
06/19/2024 01:46:56 - INFO - modeling_roberta - Training sub-loss: O 1.0683685541152954, C 1.072045922279358, E 1.1326496601104736, A 1.08535635471344, N 1.0719881057739258
06/19/2024 01:46:56 - INFO - modeling_roberta - Training sub-loss: O 1.1428333520889282, C 1.0732965469360352, E 1.0969940423965454, A 1.0985450744628906, N 1.0865795612335205
06/19/2024 01:46:58 - INFO - modeling_roberta - Training sub-loss: O 1.111979365348816, C 1.1235017776489258, E 1.1060749292373657, A 1.0906498432159424, N 1.1122336387634277
06/19/2024 01:46:58 - INFO - modeling_roberta - Training sub-loss: O 1.1738746166229248, C 1.0938096046447754, E 1.0862314701080322, A 1.1501991748809814, N 1.157127022743225
06/19/2024 01:46:59 - ERROR - root -  70%|######9   | 272/390 [14:54<06:53,  3.50s/it]
06/19/2024 01:46:59 - INFO - modeling_roberta - Training sub-loss: O 1.102512240409851, C 1.1385104656219482, E 1.1178455352783203, A 1.0704858303070068, N 1.0770323276519775
06/19/2024 01:46:59 - INFO - modeling_roberta - Training sub-loss: O 1.1187026500701904, C 1.1260993480682373, E 1.0912034511566162, A 1.0948048830032349, N 1.1037707328796387
06/19/2024 01:47:01 - INFO - modeling_roberta - Training sub-loss: O 1.150825023651123, C 1.1294841766357422, E 1.1171903610229492, A 1.0477943420410156, N 1.133737564086914
06/19/2024 01:47:01 - INFO - modeling_roberta - Training sub-loss: O 1.1293585300445557, C 1.1336414813995361, E 1.070694923400879, A 1.0784533023834229, N 1.0936182737350464
06/19/2024 01:47:02 - ERROR - root -  70%|#######   | 273/390 [14:57<06:47,  3.48s/it]
06/19/2024 01:47:03 - INFO - modeling_roberta - Training sub-loss: O 1.0945980548858643, C 1.098488688468933, E 1.0603524446487427, A 1.1001746654510498, N 1.1224091053009033
06/19/2024 01:47:03 - INFO - modeling_roberta - Training sub-loss: O 1.1030254364013672, C 1.1265993118286133, E 1.1013264656066895, A 1.0335915088653564, N 1.090862512588501
06/19/2024 01:47:05 - INFO - modeling_roberta - Training sub-loss: O 1.1096444129943848, C 1.0946003198623657, E 1.082680106163025, A 1.0436049699783325, N 1.100531816482544
06/19/2024 01:47:05 - INFO - modeling_roberta - Training sub-loss: O 1.1303901672363281, C 1.0975931882858276, E 1.129862904548645, A 1.0949270725250244, N 1.112468957901001
06/19/2024 01:47:06 - ERROR - root -  70%|#######   | 274/390 [15:01<06:50,  3.54s/it]
06/19/2024 01:47:06 - INFO - modeling_roberta - Training sub-loss: O 1.1501771211624146, C 1.0993766784667969, E 1.0923641920089722, A 1.12369704246521, N 1.1165331602096558
06/19/2024 01:47:06 - INFO - modeling_roberta - Training sub-loss: O 1.1066951751708984, C 1.108321189880371, E 1.1040534973144531, A 1.0556819438934326, N 1.0747731924057007
06/19/2024 01:47:08 - INFO - modeling_roberta - Training sub-loss: O 1.1115812063217163, C 1.103520154953003, E 1.110062599182129, A 1.0759975910186768, N 1.11590576171875
06/19/2024 01:47:08 - INFO - modeling_roberta - Training sub-loss: O 1.0790002346038818, C 1.1009516716003418, E 1.1085517406463623, A 1.0902506113052368, N 1.092727541923523
06/19/2024 01:47:09 - ERROR - root -  71%|#######   | 275/390 [15:04<06:42,  3.50s/it]
06/19/2024 01:47:10 - INFO - modeling_roberta - Training sub-loss: O 1.0460807085037231, C 1.06787109375, E 1.0789179801940918, A 1.0998945236206055, N 1.103511095046997
06/19/2024 01:47:10 - INFO - modeling_roberta - Training sub-loss: O 1.088970422744751, C 1.0906453132629395, E 1.104608416557312, A 1.119649052619934, N 1.0508263111114502
06/19/2024 01:47:12 - INFO - modeling_roberta - Training sub-loss: O 1.1005444526672363, C 1.0991871356964111, E 1.1010031700134277, A 1.0720291137695312, N 1.104820966720581
06/19/2024 01:47:12 - INFO - modeling_roberta - Training sub-loss: O 1.0847313404083252, C 1.0942847728729248, E 1.1268812417984009, A 1.0889732837677002, N 1.113807201385498
06/19/2024 01:47:13 - ERROR - root -  71%|#######   | 276/390 [15:08<06:36,  3.48s/it]
06/19/2024 01:47:13 - INFO - modeling_roberta - Training sub-loss: O 1.1273609399795532, C 1.117291808128357, E 1.0887521505355835, A 1.054794192314148, N 1.0858896970748901
06/19/2024 01:47:13 - INFO - modeling_roberta - Training sub-loss: O 1.0988373756408691, C 1.1330112218856812, E 1.0831873416900635, A 1.110142469406128, N 1.1051466464996338
06/19/2024 01:47:15 - INFO - modeling_roberta - Training sub-loss: O 1.1112947463989258, C 1.0765841007232666, E 1.066515326499939, A 1.0618339776992798, N 1.078052282333374
06/19/2024 01:47:15 - INFO - modeling_roberta - Training sub-loss: O 1.1140170097351074, C 1.1344115734100342, E 1.056779384613037, A 1.0777028799057007, N 1.117547869682312
06/19/2024 01:47:16 - ERROR - root -  71%|#######1  | 277/390 [15:12<06:46,  3.60s/it]
06/19/2024 01:47:17 - INFO - modeling_roberta - Training sub-loss: O 1.084861159324646, C 1.1333967447280884, E 1.1202998161315918, A 1.0993685722351074, N 1.0975360870361328
06/19/2024 01:47:17 - INFO - modeling_roberta - Training sub-loss: O 1.1513375043869019, C 1.1015347242355347, E 1.0934725999832153, A 1.0648293495178223, N 1.1014978885650635
06/19/2024 01:47:19 - INFO - modeling_roberta - Training sub-loss: O 1.098839521408081, C 1.1308982372283936, E 1.1000993251800537, A 1.0975373983383179, N 1.1165130138397217
06/19/2024 01:47:19 - INFO - modeling_roberta - Training sub-loss: O 1.0967234373092651, C 1.1293995380401611, E 1.109968662261963, A 1.1157417297363281, N 1.0992625951766968
06/19/2024 01:47:20 - ERROR - root -  71%|#######1  | 278/390 [15:15<06:35,  3.53s/it]
06/19/2024 01:47:21 - INFO - modeling_roberta - Training sub-loss: O 1.1039164066314697, C 1.0868785381317139, E 1.1373622417449951, A 1.1254369020462036, N 1.1110329627990723
06/19/2024 01:47:21 - INFO - modeling_roberta - Training sub-loss: O 1.0972836017608643, C 1.1300549507141113, E 1.080505132675171, A 1.1297847032546997, N 1.1091837882995605
06/19/2024 01:47:22 - INFO - modeling_roberta - Training sub-loss: O 1.12948739528656, C 1.1085009574890137, E 1.111943244934082, A 1.1702220439910889, N 1.1156476736068726
06/19/2024 01:47:22 - INFO - modeling_roberta - Training sub-loss: O 1.0210249423980713, C 1.1278325319290161, E 1.1146782636642456, A 1.1293177604675293, N 1.0972377061843872
06/19/2024 01:47:23 - ERROR - root -  72%|#######1  | 279/390 [15:18<06:27,  3.49s/it]
06/19/2024 01:47:24 - INFO - modeling_roberta - Training sub-loss: O 1.0649378299713135, C 1.1465649604797363, E 1.0984413623809814, A 1.0767477750778198, N 1.0804113149642944
06/19/2024 01:47:24 - INFO - modeling_roberta - Training sub-loss: O 1.1242034435272217, C 1.153389811515808, E 1.1040091514587402, A 1.1387956142425537, N 1.1195743083953857
06/19/2024 01:47:26 - INFO - modeling_roberta - Training sub-loss: O 1.112659215927124, C 1.11738920211792, E 1.0981366634368896, A 1.1110379695892334, N 1.1042760610580444
06/19/2024 01:47:26 - INFO - modeling_roberta - Training sub-loss: O 1.1394180059432983, C 1.1039555072784424, E 1.096198558807373, A 1.123203992843628, N 1.1107094287872314
06/19/2024 01:47:27 - ERROR - root -  72%|#######1  | 280/390 [15:22<06:20,  3.46s/it]
06/19/2024 01:47:27 - INFO - root - {'loss': 1.103, 'grad_norm': 71479.796875, 'learning_rate': 2.8205128205128207e-05, 'epoch': 3.57}
06/19/2024 01:47:27 - ERROR - root -  72%|#######1  | 280/390 [15:22<06:20,  3.46s/it]
06/19/2024 01:47:27 - INFO - modeling_roberta - Training sub-loss: O 1.0668224096298218, C 1.0924670696258545, E 1.1078999042510986, A 1.109635591506958, N 1.091293215751648
06/19/2024 01:47:27 - INFO - modeling_roberta - Training sub-loss: O 1.109442114830017, C 1.0864803791046143, E 1.0764403343200684, A 1.05659818649292, N 1.1293708086013794
06/19/2024 01:47:29 - INFO - modeling_roberta - Training sub-loss: O 1.092073917388916, C 1.133939504623413, E 1.096571683883667, A 1.1161136627197266, N 1.0927363634109497
06/19/2024 01:47:29 - INFO - modeling_roberta - Training sub-loss: O 1.0849778652191162, C 1.0814242362976074, E 1.100795030593872, A 1.084062099456787, N 1.0728554725646973
06/19/2024 01:47:30 - ERROR - root -  72%|#######2  | 281/390 [15:25<06:09,  3.39s/it]
06/19/2024 01:47:31 - INFO - modeling_roberta - Training sub-loss: O 1.1155887842178345, C 1.1170165538787842, E 1.1129429340362549, A 1.141918420791626, N 1.0899640321731567
06/19/2024 01:47:31 - INFO - modeling_roberta - Training sub-loss: O 1.0720964670181274, C 1.0970771312713623, E 1.0988794565200806, A 1.0983266830444336, N 1.1152364015579224
06/19/2024 01:47:32 - INFO - modeling_roberta - Training sub-loss: O 1.085670828819275, C 1.109579086303711, E 1.126482605934143, A 1.1321768760681152, N 1.1274023056030273
06/19/2024 01:47:32 - INFO - modeling_roberta - Training sub-loss: O 1.0754057168960571, C 1.1313929557800293, E 1.1136773824691772, A 1.1132405996322632, N 1.1026852130889893
06/19/2024 01:47:33 - ERROR - root -  72%|#######2  | 282/390 [15:28<06:06,  3.39s/it]
06/19/2024 01:47:34 - INFO - modeling_roberta - Training sub-loss: O 1.0730916261672974, C 1.1228218078613281, E 1.1422690153121948, A 1.144760012626648, N 1.0649328231811523
06/19/2024 01:47:34 - INFO - modeling_roberta - Training sub-loss: O 1.1264342069625854, C 1.0811384916305542, E 1.140023946762085, A 1.0943814516067505, N 1.0928720235824585
06/19/2024 01:47:36 - INFO - modeling_roberta - Training sub-loss: O 1.0998417139053345, C 1.1195292472839355, E 1.074979305267334, A 1.1740492582321167, N 1.1141685247421265
06/19/2024 01:47:36 - INFO - modeling_roberta - Training sub-loss: O 1.0660741329193115, C 1.077327847480774, E 1.14012610912323, A 1.1355435848236084, N 1.0910606384277344
06/19/2024 01:47:37 - ERROR - root -  73%|#######2  | 283/390 [15:32<06:02,  3.39s/it]
06/19/2024 01:47:37 - INFO - modeling_roberta - Training sub-loss: O 1.0949095487594604, C 1.0962597131729126, E 1.0993884801864624, A 1.0998018980026245, N 1.1000378131866455
06/19/2024 01:47:37 - INFO - modeling_roberta - Training sub-loss: O 1.086229681968689, C 1.0833040475845337, E 1.0889861583709717, A 1.1154993772506714, N 1.127960205078125
06/19/2024 01:47:39 - INFO - modeling_roberta - Training sub-loss: O 1.091628074645996, C 1.151415228843689, E 1.1082773208618164, A 1.125715732574463, N 1.0912821292877197
06/19/2024 01:47:39 - INFO - modeling_roberta - Training sub-loss: O 1.1122767925262451, C 1.1238126754760742, E 1.13557767868042, A 1.1277990341186523, N 1.1021621227264404
06/19/2024 01:47:40 - ERROR - root -  73%|#######2  | 284/390 [15:35<05:54,  3.34s/it]
06/19/2024 01:47:41 - INFO - modeling_roberta - Training sub-loss: O 1.0807826519012451, C 1.0529632568359375, E 1.1257219314575195, A 1.1347198486328125, N 1.12217116355896
06/19/2024 01:47:41 - INFO - modeling_roberta - Training sub-loss: O 1.1222800016403198, C 1.1198533773422241, E 1.1179349422454834, A 1.1030964851379395, N 1.0722239017486572
06/19/2024 01:47:42 - INFO - modeling_roberta - Training sub-loss: O 1.1144939661026, C 1.1228141784667969, E 1.1024497747421265, A 1.0885112285614014, N 1.1206433773040771
06/19/2024 01:47:42 - INFO - modeling_roberta - Training sub-loss: O 1.1280101537704468, C 1.1054513454437256, E 1.1057441234588623, A 1.0989032983779907, N 1.1255640983581543
06/19/2024 01:47:43 - ERROR - root -  73%|#######3  | 285/390 [15:38<05:46,  3.30s/it]
06/19/2024 01:47:44 - INFO - modeling_roberta - Training sub-loss: O 1.0997716188430786, C 1.0757553577423096, E 1.1079679727554321, A 1.1117349863052368, N 1.0848186016082764
06/19/2024 01:47:44 - INFO - modeling_roberta - Training sub-loss: O 1.100589394569397, C 1.1568220853805542, E 1.1274442672729492, A 1.0901670455932617, N 1.1186059713363647
06/19/2024 01:47:45 - INFO - modeling_roberta - Training sub-loss: O 1.073559284210205, C 1.074653148651123, E 1.0968577861785889, A 1.099527359008789, N 1.0985753536224365
06/19/2024 01:47:45 - INFO - modeling_roberta - Training sub-loss: O 1.0632658004760742, C 1.1547236442565918, E 1.0645153522491455, A 1.0720889568328857, N 1.1226625442504883
06/19/2024 01:47:46 - ERROR - root -  73%|#######3  | 286/390 [15:41<05:39,  3.27s/it]
06/19/2024 01:47:47 - INFO - modeling_roberta - Training sub-loss: O 1.1158185005187988, C 1.0899033546447754, E 1.076026439666748, A 1.116776466369629, N 1.0841236114501953
06/19/2024 01:47:47 - INFO - modeling_roberta - Training sub-loss: O 1.1066855192184448, C 1.127792477607727, E 1.1527588367462158, A 1.1103496551513672, N 1.100029706954956
06/19/2024 01:47:49 - INFO - modeling_roberta - Training sub-loss: O 1.1060720682144165, C 1.1429418325424194, E 1.0887105464935303, A 1.0967309474945068, N 1.093611478805542
06/19/2024 01:47:49 - INFO - modeling_roberta - Training sub-loss: O 1.1170552968978882, C 1.2036021947860718, E 1.0997453927993774, A 1.1015034914016724, N 1.1195392608642578
06/19/2024 01:47:49 - ERROR - root -  74%|#######3  | 287/390 [15:45<05:35,  3.25s/it]
06/19/2024 01:47:50 - INFO - modeling_roberta - Training sub-loss: O 1.1164839267730713, C 1.1632064580917358, E 1.1163363456726074, A 1.1012271642684937, N 1.0914363861083984
06/19/2024 01:47:50 - INFO - modeling_roberta - Training sub-loss: O 1.1118624210357666, C 1.121882677078247, E 1.1482477188110352, A 1.0997471809387207, N 1.107374906539917
06/19/2024 01:47:52 - INFO - modeling_roberta - Training sub-loss: O 1.0831024646759033, C 1.121382713317871, E 1.120672345161438, A 1.1073143482208252, N 1.1166349649429321
06/19/2024 01:47:52 - INFO - modeling_roberta - Training sub-loss: O 1.0982093811035156, C 1.1193714141845703, E 1.0811479091644287, A 1.0931127071380615, N 1.0738002061843872
06/19/2024 01:47:53 - ERROR - root -  74%|#######3  | 288/390 [15:48<05:29,  3.23s/it]
06/19/2024 01:47:53 - INFO - modeling_roberta - Training sub-loss: O 1.0851569175720215, C 1.1145274639129639, E 1.100311279296875, A 1.1081563234329224, N 1.149919033050537
06/19/2024 01:47:53 - INFO - modeling_roberta - Training sub-loss: O 1.0720274448394775, C 1.1341575384140015, E 1.082888126373291, A 1.1403781175613403, N 1.0847010612487793
06/19/2024 01:47:55 - INFO - modeling_roberta - Training sub-loss: O 1.1445810794830322, C 1.130061388015747, E 1.1179327964782715, A 1.079819917678833, N 1.1096081733703613
06/19/2024 01:47:55 - INFO - modeling_roberta - Training sub-loss: O 1.0880579948425293, C 1.1116070747375488, E 1.1042277812957764, A 1.114725112915039, N 1.1077299118041992
06/19/2024 01:47:56 - ERROR - root -  74%|#######4  | 289/390 [15:51<05:24,  3.22s/it]
06/19/2024 01:47:57 - INFO - modeling_roberta - Training sub-loss: O 1.0756981372833252, C 1.1126905679702759, E 1.1439720392227173, A 1.1257119178771973, N 1.0956279039382935
06/19/2024 01:47:57 - INFO - modeling_roberta - Training sub-loss: O 1.0927643775939941, C 1.1121264696121216, E 1.124588966369629, A 1.0717155933380127, N 1.1222593784332275
06/19/2024 01:47:58 - INFO - modeling_roberta - Training sub-loss: O 1.1149541139602661, C 1.1237356662750244, E 1.114518404006958, A 1.1813958883285522, N 1.114894151687622
06/19/2024 01:47:58 - INFO - modeling_roberta - Training sub-loss: O 1.0606507062911987, C 1.0769596099853516, E 1.1002987623214722, A 1.1043686866760254, N 1.100075364112854
06/19/2024 01:47:59 - ERROR - root -  74%|#######4  | 290/390 [15:54<05:20,  3.21s/it]
06/19/2024 01:47:59 - INFO - root - {'loss': 1.1067, 'grad_norm': 65567.1484375, 'learning_rate': 2.564102564102564e-05, 'epoch': 3.69}
06/19/2024 01:47:59 - ERROR - root -  74%|#######4  | 290/390 [15:54<05:20,  3.21s/it]
06/19/2024 01:48:00 - INFO - modeling_roberta - Training sub-loss: O 1.1053075790405273, C 1.0832490921020508, E 1.138103723526001, A 1.1047319173812866, N 1.1014983654022217
06/19/2024 01:48:00 - INFO - modeling_roberta - Training sub-loss: O 1.1403357982635498, C 1.1213488578796387, E 1.1176859140396118, A 1.0895510911941528, N 1.0983059406280518
06/19/2024 01:48:01 - INFO - modeling_roberta - Training sub-loss: O 1.1120977401733398, C 1.1157031059265137, E 1.0840383768081665, A 1.1146528720855713, N 1.1079976558685303
06/19/2024 01:48:01 - INFO - modeling_roberta - Training sub-loss: O 1.1022298336029053, C 1.0955588817596436, E 1.1158900260925293, A 1.1162534952163696, N 1.05694580078125
06/19/2024 01:48:02 - ERROR - root -  75%|#######4  | 291/390 [15:57<05:17,  3.20s/it]
06/19/2024 01:48:03 - INFO - modeling_roberta - Training sub-loss: O 1.0956388711929321, C 1.1318717002868652, E 1.1374009847640991, A 1.0942902565002441, N 1.0997763872146606
06/19/2024 01:48:03 - INFO - modeling_roberta - Training sub-loss: O 1.101363182067871, C 1.0780961513519287, E 1.094153642654419, A 1.097731590270996, N 1.063278317451477
06/19/2024 01:48:05 - INFO - modeling_roberta - Training sub-loss: O 1.1065442562103271, C 1.1225013732910156, E 1.0892671346664429, A 1.0708802938461304, N 1.0981615781784058
06/19/2024 01:48:05 - INFO - modeling_roberta - Training sub-loss: O 1.0872151851654053, C 1.075352430343628, E 1.1406999826431274, A 1.1232213973999023, N 1.0581519603729248
06/19/2024 01:48:05 - ERROR - root -  75%|#######4  | 292/390 [16:01<05:14,  3.21s/it]
06/19/2024 01:48:06 - INFO - modeling_roberta - Training sub-loss: O 1.0624934434890747, C 1.08247709274292, E 1.1245546340942383, A 1.1034141778945923, N 1.093867301940918
06/19/2024 01:48:06 - INFO - modeling_roberta - Training sub-loss: O 1.0748188495635986, C 1.0581679344177246, E 1.1683083772659302, A 1.1198968887329102, N 1.0942237377166748
06/19/2024 01:48:08 - INFO - modeling_roberta - Training sub-loss: O 1.0723448991775513, C 1.0988274812698364, E 1.1421797275543213, A 1.0568733215332031, N 1.093088150024414
06/19/2024 01:48:08 - INFO - modeling_roberta - Training sub-loss: O 1.1144508123397827, C 1.1222641468048096, E 1.0698200464248657, A 1.1252245903015137, N 1.0712491273880005
06/19/2024 01:48:09 - ERROR - root -  75%|#######5  | 293/390 [16:04<05:11,  3.21s/it]
06/19/2024 01:48:09 - INFO - modeling_roberta - Training sub-loss: O 1.1062756776809692, C 1.0933423042297363, E 1.116745948791504, A 1.0935642719268799, N 1.090503454208374
06/19/2024 01:48:09 - INFO - modeling_roberta - Training sub-loss: O 1.0752915143966675, C 1.1121679544448853, E 1.0971355438232422, A 1.1095225811004639, N 1.118950605392456
06/19/2024 01:48:11 - INFO - modeling_roberta - Training sub-loss: O 1.1353228092193604, C 1.0952068567276, E 1.1016931533813477, A 1.0950686931610107, N 1.0834484100341797
06/19/2024 01:48:11 - INFO - modeling_roberta - Training sub-loss: O 1.121804118156433, C 1.105520486831665, E 1.1228992938995361, A 1.100470781326294, N 1.1113728284835815
06/19/2024 01:48:12 - ERROR - root -  75%|#######5  | 294/390 [16:07<05:07,  3.21s/it]
06/19/2024 01:48:13 - INFO - modeling_roberta - Training sub-loss: O 1.1020013093948364, C 1.0896973609924316, E 1.1318217515945435, A 1.128914713859558, N 1.0872507095336914
06/19/2024 01:48:13 - INFO - modeling_roberta - Training sub-loss: O 1.105151653289795, C 1.132295846939087, E 1.1136322021484375, A 1.1412372589111328, N 1.0913348197937012
06/19/2024 01:48:14 - INFO - modeling_roberta - Training sub-loss: O 1.118102788925171, C 1.1254472732543945, E 1.0680015087127686, A 1.143763780593872, N 1.0885614156723022
06/19/2024 01:48:14 - INFO - modeling_roberta - Training sub-loss: O 1.1541533470153809, C 1.0879724025726318, E 1.1226856708526611, A 1.093901515007019, N 1.1019288301467896
06/19/2024 01:48:15 - ERROR - root -  76%|#######5  | 295/390 [16:10<05:04,  3.21s/it]
06/19/2024 01:48:16 - INFO - modeling_roberta - Training sub-loss: O 1.100949764251709, C 1.1099566221237183, E 1.1191763877868652, A 1.115020990371704, N 1.1455464363098145
06/19/2024 01:48:16 - INFO - modeling_roberta - Training sub-loss: O 1.0649843215942383, C 1.105315923690796, E 1.088501214981079, A 1.1037354469299316, N 1.1189007759094238
06/19/2024 01:48:17 - INFO - modeling_roberta - Training sub-loss: O 1.0886101722717285, C 1.0563995838165283, E 1.0876268148422241, A 1.089019536972046, N 1.1303331851959229
06/19/2024 01:48:17 - INFO - modeling_roberta - Training sub-loss: O 1.0674446821212769, C 1.0625689029693604, E 1.0911345481872559, A 1.1234184503555298, N 1.08462655544281
06/19/2024 01:48:18 - ERROR - root -  76%|#######5  | 296/390 [16:13<05:01,  3.21s/it]
06/19/2024 01:48:19 - INFO - modeling_roberta - Training sub-loss: O 1.0802170038223267, C 1.133449912071228, E 1.1077353954315186, A 1.085998773574829, N 1.1437358856201172
06/19/2024 01:48:19 - INFO - modeling_roberta - Training sub-loss: O 1.0953459739685059, C 1.0653510093688965, E 1.1093928813934326, A 1.0837565660476685, N 1.0765442848205566
06/19/2024 01:48:21 - INFO - modeling_roberta - Training sub-loss: O 1.115214467048645, C 1.1003837585449219, E 1.1309188604354858, A 1.1143953800201416, N 1.1388821601867676
06/19/2024 01:48:21 - INFO - modeling_roberta - Training sub-loss: O 1.081779956817627, C 1.0794577598571777, E 1.0880255699157715, A 1.0787720680236816, N 1.0712428092956543
06/19/2024 01:48:21 - ERROR - root -  76%|#######6  | 297/390 [16:17<04:57,  3.20s/it]
06/19/2024 01:48:22 - INFO - modeling_roberta - Training sub-loss: O 1.1245923042297363, C 1.069105625152588, E 1.1158634424209595, A 1.1356780529022217, N 1.1162030696868896
06/19/2024 01:48:22 - INFO - modeling_roberta - Training sub-loss: O 1.1673264503479004, C 1.0859348773956299, E 1.1189603805541992, A 1.0931133031845093, N 1.0691380500793457
06/19/2024 01:48:24 - INFO - modeling_roberta - Training sub-loss: O 1.1035091876983643, C 1.1451647281646729, E 1.085301399230957, A 1.0944784879684448, N 1.1225249767303467
06/19/2024 01:48:24 - INFO - modeling_roberta - Training sub-loss: O 1.1005522012710571, C 1.0657963752746582, E 1.1165249347686768, A 1.1316585540771484, N 1.0785181522369385
06/19/2024 01:48:25 - ERROR - root -  76%|#######6  | 298/390 [16:20<04:57,  3.23s/it]
06/19/2024 01:48:26 - INFO - modeling_roberta - Training sub-loss: O 1.1076191663742065, C 1.1221047639846802, E 1.1436798572540283, A 1.1226260662078857, N 1.1190582513809204
06/19/2024 01:48:26 - INFO - modeling_roberta - Training sub-loss: O 1.1097215414047241, C 1.1139858961105347, E 1.1352852582931519, A 1.1376242637634277, N 1.1255772113800049
06/19/2024 01:48:28 - INFO - modeling_roberta - Training sub-loss: O 1.142547845840454, C 1.1094387769699097, E 1.1459825038909912, A 1.1001884937286377, N 1.1234430074691772
06/19/2024 01:48:28 - INFO - modeling_roberta - Training sub-loss: O 1.1446986198425293, C 1.0796542167663574, E 1.0834050178527832, A 1.1084338426589966, N 1.106285572052002
06/19/2024 01:48:29 - ERROR - root -  77%|#######6  | 299/390 [16:24<05:16,  3.48s/it]
06/19/2024 01:48:30 - INFO - modeling_roberta - Training sub-loss: O 1.1381487846374512, C 1.0989785194396973, E 1.1097739934921265, A 1.104069471359253, N 1.096347451210022
06/19/2024 01:48:30 - INFO - modeling_roberta - Training sub-loss: O 1.1115989685058594, C 1.0955638885498047, E 1.0852444171905518, A 1.1068577766418457, N 1.0805944204330444
06/19/2024 01:48:31 - INFO - modeling_roberta - Training sub-loss: O 1.1086006164550781, C 1.0845086574554443, E 1.0789934396743774, A 1.1337867975234985, N 1.0931038856506348
06/19/2024 01:48:31 - INFO - modeling_roberta - Training sub-loss: O 1.0986604690551758, C 1.0958698987960815, E 1.126334309577942, A 1.0862181186676025, N 1.1043694019317627
06/19/2024 01:48:32 - ERROR - root -  77%|#######6  | 300/390 [16:27<05:05,  3.40s/it]
06/19/2024 01:48:32 - INFO - root - {'loss': 1.1042, 'grad_norm': 77071.140625, 'learning_rate': 2.307692307692308e-05, 'epoch': 3.82}
06/19/2024 01:48:32 - ERROR - root -  77%|#######6  | 300/390 [16:27<05:05,  3.40s/it]
06/19/2024 01:48:33 - INFO - modeling_roberta - Training sub-loss: O 1.096471905708313, C 1.1713428497314453, E 1.232802391052246, A 1.069504976272583, N 1.1017531156539917
06/19/2024 01:48:33 - INFO - modeling_roberta - Training sub-loss: O 1.10238516330719, C 1.0781506299972534, E 1.112788438796997, A 1.1731390953063965, N 1.0579276084899902
06/19/2024 01:48:34 - INFO - modeling_roberta - Training sub-loss: O 1.0965807437896729, C 1.0790035724639893, E 1.0880564451217651, A 1.1174030303955078, N 1.0835474729537964
06/19/2024 01:48:34 - INFO - modeling_roberta - Training sub-loss: O 1.134129285812378, C 1.045255184173584, E 1.0874792337417603, A 1.1096065044403076, N 1.0833032131195068
06/19/2024 01:48:35 - ERROR - root -  77%|#######7  | 301/390 [16:30<04:57,  3.34s/it]
06/19/2024 01:48:36 - INFO - modeling_roberta - Training sub-loss: O 1.0848242044448853, C 1.1342780590057373, E 1.1083216667175293, A 1.1046606302261353, N 1.0964906215667725
06/19/2024 01:48:36 - INFO - modeling_roberta - Training sub-loss: O 1.090787410736084, C 1.1250981092453003, E 1.0181610584259033, A 1.0508805513381958, N 1.1052659749984741
06/19/2024 01:48:37 - INFO - modeling_roberta - Training sub-loss: O 1.0906316041946411, C 1.173068642616272, E 1.1356472969055176, A 1.1523351669311523, N 1.1111408472061157
06/19/2024 01:48:37 - INFO - modeling_roberta - Training sub-loss: O 1.1038782596588135, C 1.1552231311798096, E 1.1222895383834839, A 1.1075873374938965, N 1.100511074066162
06/19/2024 01:48:38 - ERROR - root -  77%|#######7  | 302/390 [16:34<04:50,  3.30s/it]
06/19/2024 01:48:39 - INFO - modeling_roberta - Training sub-loss: O 1.095458745956421, C 1.0863914489746094, E 1.0998598337173462, A 1.1011409759521484, N 1.0850551128387451
06/19/2024 01:48:39 - INFO - modeling_roberta - Training sub-loss: O 1.09630286693573, C 1.0359221696853638, E 1.1167188882827759, A 1.1216638088226318, N 1.1012470722198486
06/19/2024 01:48:41 - INFO - modeling_roberta - Training sub-loss: O 1.0836358070373535, C 1.0943607091903687, E 1.1072485446929932, A 1.1151330471038818, N 1.135619878768921
06/19/2024 01:48:41 - INFO - modeling_roberta - Training sub-loss: O 1.0987987518310547, C 1.1055957078933716, E 1.0699796676635742, A 1.1557250022888184, N 1.0938732624053955
06/19/2024 01:48:42 - ERROR - root -  78%|#######7  | 303/390 [16:37<04:45,  3.29s/it]
06/19/2024 01:48:42 - INFO - modeling_roberta - Training sub-loss: O 1.1143431663513184, C 1.109642505645752, E 1.149548053741455, A 1.1041841506958008, N 1.1421480178833008
06/19/2024 01:48:42 - INFO - modeling_roberta - Training sub-loss: O 1.126977801322937, C 1.101381540298462, E 1.113668441772461, A 1.0950595140457153, N 1.119011640548706
06/19/2024 01:48:44 - INFO - modeling_roberta - Training sub-loss: O 1.1279851198196411, C 1.0853354930877686, E 1.0482487678527832, A 1.1038663387298584, N 1.0960050821304321
06/19/2024 01:48:44 - INFO - modeling_roberta - Training sub-loss: O 1.0860751867294312, C 1.0936540365219116, E 1.1249356269836426, A 1.094695806503296, N 1.1446164846420288
06/19/2024 01:48:45 - ERROR - root -  78%|#######7  | 304/390 [16:40<04:44,  3.30s/it]
06/19/2024 01:48:46 - INFO - modeling_roberta - Training sub-loss: O 1.1299470663070679, C 1.0963290929794312, E 1.1118806600570679, A 1.0886073112487793, N 1.0800317525863647
06/19/2024 01:48:46 - INFO - modeling_roberta - Training sub-loss: O 1.0973095893859863, C 1.118498682975769, E 1.0998728275299072, A 1.1351165771484375, N 1.1273566484451294
06/19/2024 01:48:47 - INFO - modeling_roberta - Training sub-loss: O 1.13431715965271, C 1.0863434076309204, E 1.1360039710998535, A 1.1166210174560547, N 1.1200143098831177
06/19/2024 01:48:47 - INFO - modeling_roberta - Training sub-loss: O 1.1211819648742676, C 1.152544617652893, E 1.1401597261428833, A 1.1181660890579224, N 1.127547025680542
06/19/2024 01:48:48 - ERROR - root -  78%|#######8  | 305/390 [16:43<04:40,  3.30s/it]
06/19/2024 01:48:49 - INFO - modeling_roberta - Training sub-loss: O 1.066238522529602, C 1.0995731353759766, E 1.1015421152114868, A 1.10871422290802, N 1.1194145679473877
06/19/2024 01:48:49 - INFO - modeling_roberta - Training sub-loss: O 1.0863714218139648, C 1.0762567520141602, E 1.1088290214538574, A 1.0841654539108276, N 1.1285111904144287
06/19/2024 01:48:51 - INFO - modeling_roberta - Training sub-loss: O 1.1171197891235352, C 1.1029094457626343, E 1.0551847219467163, A 1.0840651988983154, N 1.1074659824371338
06/19/2024 01:48:51 - INFO - modeling_roberta - Training sub-loss: O 1.0788204669952393, C 1.1537305116653442, E 1.0640596151351929, A 1.0699522495269775, N 1.0735805034637451
06/19/2024 01:48:52 - ERROR - root -  78%|#######8  | 306/390 [16:47<04:38,  3.31s/it]
06/19/2024 01:48:52 - INFO - modeling_roberta - Training sub-loss: O 1.0741872787475586, C 1.090338110923767, E 1.0936827659606934, A 1.1018246412277222, N 1.0966899394989014
06/19/2024 01:48:52 - INFO - modeling_roberta - Training sub-loss: O 1.0804038047790527, C 1.1079974174499512, E 1.1258139610290527, A 1.1331877708435059, N 1.1571415662765503
06/19/2024 01:48:54 - INFO - modeling_roberta - Training sub-loss: O 1.095253825187683, C 1.1317527294158936, E 1.0377428531646729, A 1.0868345499038696, N 1.0898363590240479
06/19/2024 01:48:54 - INFO - modeling_roberta - Training sub-loss: O 1.1191588640213013, C 1.0862557888031006, E 1.1181048154830933, A 1.1431469917297363, N 1.0759069919586182
06/19/2024 01:48:55 - ERROR - root -  79%|#######8  | 307/390 [16:50<04:36,  3.33s/it]
06/19/2024 01:48:56 - INFO - modeling_roberta - Training sub-loss: O 1.1455912590026855, C 1.063354730606079, E 1.107039213180542, A 1.096937656402588, N 1.138877272605896
06/19/2024 01:48:56 - INFO - modeling_roberta - Training sub-loss: O 1.0970051288604736, C 1.0239317417144775, E 1.0735913515090942, A 1.1057329177856445, N 1.1273646354675293
06/19/2024 01:48:57 - INFO - modeling_roberta - Training sub-loss: O 1.1472012996673584, C 1.0784622430801392, E 1.0970885753631592, A 1.0753188133239746, N 1.0997042655944824
06/19/2024 01:48:57 - INFO - modeling_roberta - Training sub-loss: O 1.0621533393859863, C 1.0698283910751343, E 1.0915098190307617, A 1.0650224685668945, N 1.1378759145736694
06/19/2024 01:48:58 - ERROR - root -  79%|#######8  | 308/390 [16:53<04:32,  3.33s/it]
06/19/2024 01:48:59 - INFO - modeling_roberta - Training sub-loss: O 1.1047022342681885, C 1.1247608661651611, E 1.055492639541626, A 1.0793969631195068, N 1.147914171218872
06/19/2024 01:48:59 - INFO - modeling_roberta - Training sub-loss: O 1.0932612419128418, C 1.1620564460754395, E 1.0717034339904785, A 1.1328699588775635, N 1.0800849199295044
06/19/2024 01:49:01 - INFO - modeling_roberta - Training sub-loss: O 1.0656709671020508, C 1.1165235042572021, E 1.0807431936264038, A 1.083777904510498, N 1.0813847780227661
06/19/2024 01:49:01 - INFO - modeling_roberta - Training sub-loss: O 1.1289277076721191, C 1.1414997577667236, E 1.0699739456176758, A 1.096437931060791, N 1.114556074142456
06/19/2024 01:49:02 - ERROR - root -  79%|#######9  | 309/390 [16:57<04:30,  3.34s/it]
06/19/2024 01:49:02 - INFO - modeling_roberta - Training sub-loss: O 1.0851101875305176, C 1.1023350954055786, E 1.1114864349365234, A 1.0727335214614868, N 1.1125497817993164
06/19/2024 01:49:02 - INFO - modeling_roberta - Training sub-loss: O 1.166975975036621, C 1.1551674604415894, E 1.0935333967208862, A 1.1148204803466797, N 1.0973095893859863
06/19/2024 01:49:04 - INFO - modeling_roberta - Training sub-loss: O 1.1056725978851318, C 1.0931016206741333, E 1.0987656116485596, A 1.125811219215393, N 1.0498346090316772
06/19/2024 01:49:04 - INFO - modeling_roberta - Training sub-loss: O 1.0782217979431152, C 1.1548900604248047, E 1.1266108751296997, A 1.1514699459075928, N 1.1701960563659668
06/19/2024 01:49:05 - ERROR - root -  79%|#######9  | 310/390 [17:00<04:30,  3.38s/it]
06/19/2024 01:49:05 - INFO - root - {'loss': 1.1047, 'grad_norm': 74934.171875, 'learning_rate': 2.0512820512820512e-05, 'epoch': 3.95}
06/19/2024 01:49:05 - ERROR - root -  79%|#######9  | 310/390 [17:00<04:30,  3.38s/it]
06/19/2024 01:49:06 - INFO - modeling_roberta - Training sub-loss: O 1.0857455730438232, C 1.1152241230010986, E 1.0915595293045044, A 1.0901405811309814, N 1.106494426727295
06/19/2024 01:49:06 - INFO - modeling_roberta - Training sub-loss: O 1.0920954942703247, C 1.125537395477295, E 1.1080477237701416, A 1.1079890727996826, N 1.110052227973938
06/19/2024 01:49:08 - INFO - modeling_roberta - Training sub-loss: O 1.1271421909332275, C 1.118609070777893, E 1.0996285676956177, A 1.1346503496170044, N 1.1100550889968872
06/19/2024 01:49:08 - INFO - modeling_roberta - Training sub-loss: O 1.1062778234481812, C 1.1116377115249634, E 1.0654387474060059, A 1.124638557434082, N 1.0863323211669922
06/19/2024 01:49:09 - ERROR - root -  80%|#######9  | 311/390 [17:04<04:24,  3.35s/it]
06/19/2024 01:49:09 - INFO - modeling_roberta - Training sub-loss: O 1.0840691328048706, C 1.0691908597946167, E 1.0989155769348145, A 1.1197655200958252, N 1.063962697982788
06/19/2024 01:49:09 - INFO - modeling_roberta - Training sub-loss: O 1.0912119150161743, C 1.1072849035263062, E 1.0924835205078125, A 1.0945788621902466, N 1.1378819942474365
06/19/2024 01:49:11 - INFO - modeling_roberta - Training sub-loss: O 1.1191515922546387, C 1.0845304727554321, E 1.0879377126693726, A 1.0452094078063965, N 1.0974249839782715
06/19/2024 01:49:11 - INFO - modeling_roberta - Training sub-loss: O 1.1129223108291626, C 1.0724987983703613, E 1.123067855834961, A 1.0875943899154663, N 1.1035702228546143
06/19/2024 01:49:12 - ERROR - root -  80%|########  | 312/390 [17:07<04:20,  3.34s/it]
06/19/2024 01:49:13 - INFO - modeling_roberta - Training sub-loss: O 1.0964069366455078, C 1.1136267185211182, E 1.1329152584075928, A 1.1082985401153564, N 1.0966147184371948
06/19/2024 01:49:13 - INFO - modeling_roberta - Training sub-loss: O 1.1329747438430786, C 1.080000877380371, E 1.0951682329177856, A 1.1621519327163696, N 1.1036689281463623
06/19/2024 01:49:14 - INFO - modeling_roberta - Training sub-loss: O 1.1120796203613281, C 1.0849549770355225, E 1.0865637063980103, A 1.086546540260315, N 1.0722804069519043
06/19/2024 01:49:14 - INFO - modeling_roberta - Training sub-loss: O 1.089130163192749, C 1.0878114700317383, E 1.136486291885376, A 1.1185030937194824, N 1.079115390777588
06/19/2024 01:49:15 - ERROR - root -  80%|########  | 313/390 [17:10<04:14,  3.30s/it]
06/19/2024 01:49:16 - INFO - modeling_roberta - Training sub-loss: O 1.1093865633010864, C 1.131761074066162, E 1.0532262325286865, A 1.1243376731872559, N 1.0638737678527832
06/19/2024 01:49:16 - INFO - modeling_roberta - Training sub-loss: O 1.1342363357543945, C 1.0569555759429932, E 1.1087822914123535, A 1.0697529315948486, N 1.1287758350372314
06/19/2024 01:49:18 - INFO - modeling_roberta - Training sub-loss: O 1.1265840530395508, C 1.083892583847046, E 1.031144380569458, A 1.0771287679672241, N 1.1569368839263916
06/19/2024 01:49:18 - INFO - modeling_roberta - Training sub-loss: O 1.1282857656478882, C 1.2392776012420654, E 1.1071126461029053, A 1.1883752346038818, N 1.0964298248291016
06/19/2024 01:49:18 - ERROR - root -  81%|########  | 314/390 [17:13<04:05,  3.23s/it]
06/19/2024 01:49:20 - INFO - modeling_roberta - Training sub-loss: O 1.112665057182312, C 1.0975346565246582, E 1.0955026149749756, A 1.0828787088394165, N 1.124652624130249
06/19/2024 01:49:20 - INFO - modeling_roberta - Training sub-loss: O 1.077216625213623, C 1.1185224056243896, E 1.092186689376831, A 1.1025550365447998, N 1.104041576385498
06/19/2024 01:49:22 - INFO - modeling_roberta - Training sub-loss: O 1.0763132572174072, C 1.0995821952819824, E 1.0672740936279297, A 1.0969653129577637, N 1.1124281883239746
06/19/2024 01:49:22 - INFO - modeling_roberta - Training sub-loss: O 1.1589584350585938, C 1.112149715423584, E 1.0729870796203613, A 1.0860755443572998, N 1.087004542350769
06/19/2024 01:49:23 - ERROR - root -  81%|########  | 315/390 [17:18<04:35,  3.67s/it]
06/19/2024 01:49:23 - INFO - modeling_roberta - Training sub-loss: O 1.1455965042114258, C 1.0727646350860596, E 1.1417771577835083, A 1.073354721069336, N 1.1151769161224365
06/19/2024 01:49:24 - INFO - modeling_roberta - Training sub-loss: O 1.104081630706787, C 1.0763185024261475, E 1.0818507671356201, A 1.1250144243240356, N 1.1267322301864624
06/19/2024 01:49:25 - INFO - modeling_roberta - Training sub-loss: O 1.1360503435134888, C 1.105934739112854, E 1.1169065237045288, A 1.1042187213897705, N 1.1354234218597412
06/19/2024 01:49:25 - INFO - modeling_roberta - Training sub-loss: O 1.0965290069580078, C 1.0798498392105103, E 1.0618407726287842, A 1.0993890762329102, N 1.1009984016418457
06/19/2024 01:49:26 - ERROR - root -  81%|########1 | 316/390 [17:21<04:23,  3.56s/it]
06/19/2024 01:49:27 - INFO - modeling_roberta - Training sub-loss: O 1.061485767364502, C 1.1006052494049072, E 1.0985417366027832, A 1.0970165729522705, N 1.0941115617752075
06/19/2024 01:49:27 - INFO - modeling_roberta - Training sub-loss: O 1.117368459701538, C 1.1192795038223267, E 1.0903327465057373, A 1.1038531064987183, N 1.1081314086914062
06/19/2024 01:49:28 - INFO - modeling_roberta - Training sub-loss: O 1.1040236949920654, C 1.1290843486785889, E 1.1385232210159302, A 1.1542576551437378, N 1.1155180931091309
06/19/2024 01:49:28 - INFO - modeling_roberta - Training sub-loss: O 1.131553292274475, C 1.0852359533309937, E 1.0857946872711182, A 1.1093511581420898, N 1.0716321468353271
06/19/2024 01:49:29 - ERROR - root -  81%|########1 | 317/390 [17:24<04:13,  3.48s/it]
06/19/2024 01:49:30 - INFO - modeling_roberta - Training sub-loss: O 1.1026250123977661, C 1.0887830257415771, E 1.1522130966186523, A 1.0769026279449463, N 1.1331578493118286
06/19/2024 01:49:30 - INFO - modeling_roberta - Training sub-loss: O 1.1013593673706055, C 1.0874810218811035, E 1.091496229171753, A 1.0816818475723267, N 1.1155047416687012
06/19/2024 01:49:32 - INFO - modeling_roberta - Training sub-loss: O 1.1127264499664307, C 1.0908440351486206, E 1.1087669134140015, A 1.1047358512878418, N 1.1369317770004272
06/19/2024 01:49:32 - INFO - modeling_roberta - Training sub-loss: O 1.1182467937469482, C 1.1267716884613037, E 1.0551221370697021, A 1.0819017887115479, N 1.0389831066131592
06/19/2024 01:49:33 - ERROR - root -  82%|########1 | 318/390 [17:28<04:05,  3.41s/it]
06/19/2024 01:49:33 - INFO - modeling_roberta - Training sub-loss: O 1.065443754196167, C 1.1391994953155518, E 1.0725972652435303, A 1.087648868560791, N 1.1177995204925537
06/19/2024 01:49:33 - INFO - modeling_roberta - Training sub-loss: O 1.1012643575668335, C 1.0624793767929077, E 1.114195466041565, A 1.1164155006408691, N 1.1289710998535156
06/19/2024 01:49:35 - INFO - modeling_roberta - Training sub-loss: O 1.1097050905227661, C 1.1047303676605225, E 1.1315057277679443, A 1.0786831378936768, N 1.1410528421401978
06/19/2024 01:49:35 - INFO - modeling_roberta - Training sub-loss: O 1.1397457122802734, C 1.0978862047195435, E 1.103186011314392, A 1.085864782333374, N 1.1211328506469727
06/19/2024 01:49:36 - ERROR - root -  82%|########1 | 319/390 [17:31<03:59,  3.38s/it]
06/19/2024 01:49:37 - INFO - modeling_roberta - Training sub-loss: O 1.0739922523498535, C 1.1351399421691895, E 1.152915120124817, A 1.0789515972137451, N 1.0758978128433228
06/19/2024 01:49:37 - INFO - modeling_roberta - Training sub-loss: O 1.1693555116653442, C 1.0985240936279297, E 1.0752708911895752, A 1.1054673194885254, N 1.13060462474823
06/19/2024 01:49:38 - INFO - modeling_roberta - Training sub-loss: O 1.1255005598068237, C 1.0948989391326904, E 1.0851216316223145, A 1.0895066261291504, N 1.051100254058838
06/19/2024 01:49:38 - INFO - modeling_roberta - Training sub-loss: O 1.1453720331192017, C 1.096622109413147, E 1.0970566272735596, A 1.0963793992996216, N 1.1155301332473755
06/19/2024 01:49:39 - ERROR - root -  82%|########2 | 320/390 [17:34<03:54,  3.35s/it]
06/19/2024 01:49:39 - INFO - root - {'loss': 1.1036, 'grad_norm': 82887.109375, 'learning_rate': 1.794871794871795e-05, 'epoch': 4.08}
06/19/2024 01:49:39 - ERROR - root -  82%|########2 | 320/390 [17:34<03:54,  3.35s/it]
06/19/2024 01:49:40 - INFO - modeling_roberta - Training sub-loss: O 1.1013309955596924, C 1.1064496040344238, E 1.1216609477996826, A 1.1462185382843018, N 1.1166304349899292
06/19/2024 01:49:40 - INFO - modeling_roberta - Training sub-loss: O 1.0905673503875732, C 1.117600679397583, E 1.1297881603240967, A 1.0824401378631592, N 1.0965825319290161
06/19/2024 01:49:42 - INFO - modeling_roberta - Training sub-loss: O 1.1142358779907227, C 1.1284326314926147, E 1.079033613204956, A 1.1169248819351196, N 1.1127851009368896
06/19/2024 01:49:42 - INFO - modeling_roberta - Training sub-loss: O 1.1037499904632568, C 1.15436589717865, E 1.100758671760559, A 1.131561279296875, N 1.0989792346954346
06/19/2024 01:49:43 - ERROR - root -  82%|########2 | 321/390 [17:38<03:51,  3.35s/it]
06/19/2024 01:49:43 - INFO - modeling_roberta - Training sub-loss: O 1.1066055297851562, C 1.078329086303711, E 1.1381555795669556, A 1.1241984367370605, N 1.0899758338928223
06/19/2024 01:49:43 - INFO - modeling_roberta - Training sub-loss: O 1.0770533084869385, C 1.0650485754013062, E 1.1238130331039429, A 1.1034355163574219, N 1.1452443599700928
06/19/2024 01:49:45 - INFO - modeling_roberta - Training sub-loss: O 1.1125917434692383, C 1.0936148166656494, E 1.0844013690948486, A 1.0925877094268799, N 1.1179065704345703
06/19/2024 01:49:45 - INFO - modeling_roberta - Training sub-loss: O 1.0631111860275269, C 1.1476151943206787, E 1.1006171703338623, A 1.1345973014831543, N 1.1279196739196777
06/19/2024 01:49:46 - ERROR - root -  83%|########2 | 322/390 [17:41<03:49,  3.37s/it]
06/19/2024 01:49:47 - INFO - modeling_roberta - Training sub-loss: O 1.1252552270889282, C 1.0826871395111084, E 1.0995454788208008, A 1.1098850965499878, N 1.1237404346466064
06/19/2024 01:49:47 - INFO - modeling_roberta - Training sub-loss: O 1.0897235870361328, C 1.0926135778427124, E 1.1185370683670044, A 1.070249319076538, N 1.088479995727539
06/19/2024 01:49:50 - INFO - modeling_roberta - Training sub-loss: O 1.1170604228973389, C 1.094712257385254, E 1.11453115940094, A 1.1381884813308716, N 1.1087937355041504
06/19/2024 01:49:50 - INFO - modeling_roberta - Training sub-loss: O 1.096685528755188, C 1.1071754693984985, E 1.0876970291137695, A 1.091491460800171, N 1.0675842761993408
06/19/2024 01:49:50 - ERROR - root -  83%|########2 | 323/390 [17:46<04:08,  3.71s/it]
06/19/2024 01:49:51 - INFO - modeling_roberta - Training sub-loss: O 1.125469446182251, C 1.1126317977905273, E 1.1084142923355103, A 1.0933467149734497, N 1.1089997291564941
06/19/2024 01:49:51 - INFO - modeling_roberta - Training sub-loss: O 1.103827953338623, C 1.0848865509033203, E 1.1122004985809326, A 1.0270267724990845, N 1.0815355777740479
06/19/2024 01:49:53 - INFO - modeling_roberta - Training sub-loss: O 1.1200308799743652, C 1.0898425579071045, E 1.133802890777588, A 1.1600618362426758, N 1.1104700565338135
06/19/2024 01:49:53 - INFO - modeling_roberta - Training sub-loss: O 1.1000010967254639, C 1.12319016456604, E 1.1512970924377441, A 1.1171218156814575, N 1.1320451498031616
06/19/2024 01:49:54 - ERROR - root -  83%|########3 | 324/390 [17:49<03:56,  3.58s/it]
06/19/2024 01:49:54 - INFO - modeling_roberta - Training sub-loss: O 1.1430761814117432, C 1.0977389812469482, E 1.0964717864990234, A 1.097486972808838, N 1.1360701322555542
06/19/2024 01:49:54 - INFO - modeling_roberta - Training sub-loss: O 1.117109775543213, C 1.0772545337677002, E 1.1310378313064575, A 1.1221644878387451, N 1.0629322528839111
06/19/2024 01:49:56 - INFO - modeling_roberta - Training sub-loss: O 1.0249569416046143, C 1.080270767211914, E 1.1393545866012573, A 1.1214630603790283, N 1.121063470840454
06/19/2024 01:49:56 - INFO - modeling_roberta - Training sub-loss: O 1.0853427648544312, C 1.0900893211364746, E 1.1447498798370361, A 1.0960710048675537, N 1.0851011276245117
06/19/2024 01:49:57 - ERROR - root -  83%|########3 | 325/390 [17:52<03:45,  3.47s/it]
06/19/2024 01:49:58 - INFO - modeling_roberta - Training sub-loss: O 1.0584180355072021, C 1.1234147548675537, E 1.0986714363098145, A 1.0553312301635742, N 1.0818895101547241
06/19/2024 01:49:58 - INFO - modeling_roberta - Training sub-loss: O 1.1232730150222778, C 1.1043283939361572, E 1.0974335670471191, A 1.1133744716644287, N 1.0608210563659668
06/19/2024 01:49:59 - INFO - modeling_roberta - Training sub-loss: O 1.1096676588058472, C 1.1106150150299072, E 1.0861518383026123, A 1.104668140411377, N 1.126523494720459
06/19/2024 01:49:59 - INFO - modeling_roberta - Training sub-loss: O 1.0947799682617188, C 1.1030704975128174, E 1.1233396530151367, A 1.1013842821121216, N 1.0850836038589478
06/19/2024 01:50:00 - ERROR - root -  84%|########3 | 326/390 [17:55<03:39,  3.42s/it]
06/19/2024 01:50:01 - INFO - modeling_roberta - Training sub-loss: O 1.1038100719451904, C 1.1067543029785156, E 1.0797306299209595, A 1.1085364818572998, N 1.1046617031097412
06/19/2024 01:50:01 - INFO - modeling_roberta - Training sub-loss: O 1.122268795967102, C 1.1072534322738647, E 1.110770344734192, A 1.1265608072280884, N 1.1007716655731201
06/19/2024 01:50:03 - INFO - modeling_roberta - Training sub-loss: O 1.0817182064056396, C 1.1171776056289673, E 1.087611198425293, A 1.0807565450668335, N 1.1059765815734863
06/19/2024 01:50:03 - INFO - modeling_roberta - Training sub-loss: O 1.0790760517120361, C 1.1066038608551025, E 1.0827323198318481, A 1.1060214042663574, N 1.1279957294464111
06/19/2024 01:50:04 - ERROR - root -  84%|########3 | 327/390 [17:59<03:32,  3.38s/it]
06/19/2024 01:50:04 - INFO - modeling_roberta - Training sub-loss: O 1.109571099281311, C 1.0976033210754395, E 1.099382758140564, A 1.1181378364562988, N 1.117773413658142
06/19/2024 01:50:04 - INFO - modeling_roberta - Training sub-loss: O 1.0926382541656494, C 1.136467695236206, E 1.093074083328247, A 1.114088535308838, N 1.0932501554489136
06/19/2024 01:50:06 - INFO - modeling_roberta - Training sub-loss: O 1.0815359354019165, C 1.0743807554244995, E 1.1415294408798218, A 1.12334144115448, N 1.0716043710708618
06/19/2024 01:50:06 - INFO - modeling_roberta - Training sub-loss: O 1.135353922843933, C 1.0934157371520996, E 1.0493216514587402, A 1.0849864482879639, N 1.1080949306488037
06/19/2024 01:50:07 - ERROR - root -  84%|########4 | 328/390 [18:02<03:27,  3.34s/it]
06/19/2024 01:50:08 - INFO - modeling_roberta - Training sub-loss: O 1.124114990234375, C 1.1333177089691162, E 1.0919100046157837, A 1.140560507774353, N 1.1264517307281494
06/19/2024 01:50:08 - INFO - modeling_roberta - Training sub-loss: O 1.128271222114563, C 1.1163723468780518, E 1.0694668292999268, A 1.094230055809021, N 1.1051530838012695
06/19/2024 01:50:09 - INFO - modeling_roberta - Training sub-loss: O 1.1347321271896362, C 1.0830458402633667, E 1.110610842704773, A 1.1330646276474, N 1.1156771183013916
06/19/2024 01:50:09 - INFO - modeling_roberta - Training sub-loss: O 1.0634262561798096, C 1.0907105207443237, E 1.125617504119873, A 1.1229171752929688, N 1.1463149785995483
06/19/2024 01:50:10 - ERROR - root -  84%|########4 | 329/390 [18:05<03:23,  3.33s/it]
06/19/2024 01:50:11 - INFO - modeling_roberta - Training sub-loss: O 1.0872957706451416, C 1.0997838973999023, E 1.0935540199279785, A 1.1293894052505493, N 1.0828144550323486
06/19/2024 01:50:11 - INFO - modeling_roberta - Training sub-loss: O 1.1255390644073486, C 1.1678917407989502, E 1.111856460571289, A 1.1389062404632568, N 1.0623149871826172
06/19/2024 01:50:12 - INFO - modeling_roberta - Training sub-loss: O 1.1602003574371338, C 1.0952820777893066, E 1.1284167766571045, A 1.094037413597107, N 1.0924088954925537
06/19/2024 01:50:12 - INFO - modeling_roberta - Training sub-loss: O 1.0995265245437622, C 1.0829163789749146, E 1.1011933088302612, A 1.1280579566955566, N 1.1026586294174194
06/19/2024 01:50:14 - ERROR - root -  85%|########4 | 330/390 [18:09<03:21,  3.35s/it]
06/19/2024 01:50:14 - INFO - root - {'loss': 1.1058, 'grad_norm': 55209.09765625, 'learning_rate': 1.5384615384615387e-05, 'epoch': 4.2}
06/19/2024 01:50:14 - ERROR - root -  85%|########4 | 330/390 [18:09<03:21,  3.35s/it]
06/19/2024 01:50:14 - INFO - modeling_roberta - Training sub-loss: O 1.1506280899047852, C 1.080137848854065, E 1.1231465339660645, A 1.0481503009796143, N 1.136913537979126
06/19/2024 01:50:14 - INFO - modeling_roberta - Training sub-loss: O 1.1196633577346802, C 1.1619163751602173, E 1.0933189392089844, A 1.145103931427002, N 1.0944814682006836
06/19/2024 01:50:16 - INFO - modeling_roberta - Training sub-loss: O 1.1425323486328125, C 1.109372854232788, E 1.1309096813201904, A 1.0992215871810913, N 1.1187647581100464
06/19/2024 01:50:16 - INFO - modeling_roberta - Training sub-loss: O 1.1220462322235107, C 1.0985791683197021, E 1.0995399951934814, A 1.1153614521026611, N 1.099778413772583
06/19/2024 01:50:17 - ERROR - root -  85%|########4 | 331/390 [18:12<03:18,  3.37s/it]
06/19/2024 01:50:18 - INFO - modeling_roberta - Training sub-loss: O 1.134151816368103, C 1.0972652435302734, E 1.0739976167678833, A 1.0956634283065796, N 1.1183278560638428
06/19/2024 01:50:18 - INFO - modeling_roberta - Training sub-loss: O 1.1384916305541992, C 1.10908842086792, E 1.0793524980545044, A 1.1336698532104492, N 1.1171064376831055
06/19/2024 01:50:19 - INFO - modeling_roberta - Training sub-loss: O 1.1038908958435059, C 1.1580548286437988, E 1.1132175922393799, A 1.1077038049697876, N 1.0996739864349365
06/19/2024 01:50:19 - INFO - modeling_roberta - Training sub-loss: O 1.1347837448120117, C 1.1382484436035156, E 1.111580729484558, A 1.0961377620697021, N 1.1089932918548584
06/19/2024 01:50:20 - ERROR - root -  85%|########5 | 332/390 [18:15<03:12,  3.32s/it]
06/19/2024 01:50:21 - INFO - modeling_roberta - Training sub-loss: O 1.0969642400741577, C 1.073817253112793, E 1.096587061882019, A 1.0881314277648926, N 1.1030833721160889
06/19/2024 01:50:21 - INFO - modeling_roberta - Training sub-loss: O 1.0830039978027344, C 1.125889539718628, E 1.1191701889038086, A 1.0870156288146973, N 1.0791232585906982
06/19/2024 01:50:22 - INFO - modeling_roberta - Training sub-loss: O 1.0900089740753174, C 1.1241908073425293, E 1.0852526426315308, A 1.0949203968048096, N 1.085200309753418
06/19/2024 01:50:22 - INFO - modeling_roberta - Training sub-loss: O 1.071463942527771, C 1.1146125793457031, E 1.0796910524368286, A 1.1474063396453857, N 1.064589500427246
06/19/2024 01:50:23 - ERROR - root -  85%|########5 | 333/390 [18:18<03:08,  3.31s/it]
06/19/2024 01:50:24 - INFO - modeling_roberta - Training sub-loss: O 1.144240140914917, C 1.1417607069015503, E 1.1429076194763184, A 1.1152499914169312, N 1.094625473022461
06/19/2024 01:50:24 - INFO - modeling_roberta - Training sub-loss: O 1.0505211353302002, C 1.0912351608276367, E 1.1195247173309326, A 1.1287510395050049, N 1.1098116636276245
06/19/2024 01:50:26 - INFO - modeling_roberta - Training sub-loss: O 1.09941828250885, C 1.1300143003463745, E 1.0722405910491943, A 1.12998628616333, N 1.1812827587127686
06/19/2024 01:50:26 - INFO - modeling_roberta - Training sub-loss: O 1.094628095626831, C 1.0660537481307983, E 1.0859097242355347, A 1.1137200593948364, N 1.1377993822097778
06/19/2024 01:50:27 - ERROR - root -  86%|########5 | 334/390 [18:22<03:04,  3.29s/it]
06/19/2024 01:50:27 - INFO - modeling_roberta - Training sub-loss: O 1.1464307308197021, C 1.0839931964874268, E 1.1094894409179688, A 1.1270108222961426, N 1.0833171606063843
06/19/2024 01:50:27 - INFO - modeling_roberta - Training sub-loss: O 1.0918835401535034, C 1.1010593175888062, E 1.117293357849121, A 1.09282648563385, N 1.1049168109893799
06/19/2024 01:50:29 - INFO - modeling_roberta - Training sub-loss: O 1.133000373840332, C 1.0751290321350098, E 1.0557202100753784, A 1.1009397506713867, N 1.0832690000534058
06/19/2024 01:50:29 - INFO - modeling_roberta - Training sub-loss: O 1.1103484630584717, C 1.0626814365386963, E 1.0128408670425415, A 1.1074585914611816, N 1.0775227546691895
06/19/2024 01:50:30 - ERROR - root -  86%|########5 | 335/390 [18:25<02:59,  3.27s/it]
06/19/2024 01:50:31 - INFO - modeling_roberta - Training sub-loss: O 1.1015104055404663, C 1.0821020603179932, E 1.076080322265625, A 1.098419189453125, N 1.1113157272338867
06/19/2024 01:50:31 - INFO - modeling_roberta - Training sub-loss: O 1.0795893669128418, C 1.0982515811920166, E 1.0963605642318726, A 1.0865778923034668, N 1.0888445377349854
06/19/2024 01:50:32 - INFO - modeling_roberta - Training sub-loss: O 1.098767876625061, C 1.0873655080795288, E 1.0820266008377075, A 1.105558156967163, N 1.1124904155731201
06/19/2024 01:50:32 - INFO - modeling_roberta - Training sub-loss: O 1.1349163055419922, C 1.1121183633804321, E 1.1168022155761719, A 1.1308397054672241, N 1.1220108270645142
06/19/2024 01:50:33 - ERROR - root -  86%|########6 | 336/390 [18:28<02:55,  3.25s/it]
06/19/2024 01:50:34 - INFO - modeling_roberta - Training sub-loss: O 1.1256836652755737, C 1.1114308834075928, E 1.068983554840088, A 1.053324580192566, N 1.0937288999557495
06/19/2024 01:50:34 - INFO - modeling_roberta - Training sub-loss: O 1.094281554222107, C 1.0669450759887695, E 1.0995395183563232, A 1.1019099950790405, N 1.0640509128570557
06/19/2024 01:50:35 - INFO - modeling_roberta - Training sub-loss: O 1.140864610671997, C 1.165881872177124, E 1.10252046585083, A 1.1340432167053223, N 1.133992314338684
06/19/2024 01:50:35 - INFO - modeling_roberta - Training sub-loss: O 1.0857975482940674, C 1.1406553983688354, E 1.0956367254257202, A 1.136671543121338, N 1.1461153030395508
06/19/2024 01:50:36 - ERROR - root -  86%|########6 | 337/390 [18:31<02:51,  3.23s/it]
06/19/2024 01:50:37 - INFO - modeling_roberta - Training sub-loss: O 1.1234426498413086, C 1.0975960493087769, E 1.0714526176452637, A 1.068650484085083, N 1.071264386177063
06/19/2024 01:50:37 - INFO - modeling_roberta - Training sub-loss: O 1.0882383584976196, C 1.1860079765319824, E 1.117161512374878, A 1.1148953437805176, N 1.1160684823989868
06/19/2024 01:50:39 - INFO - modeling_roberta - Training sub-loss: O 1.1007106304168701, C 1.1071257591247559, E 1.1303420066833496, A 1.087220549583435, N 1.0802589654922485
06/19/2024 01:50:39 - INFO - modeling_roberta - Training sub-loss: O 1.1024751663208008, C 1.0998728275299072, E 1.0871686935424805, A 1.10800039768219, N 1.0819019079208374
06/19/2024 01:50:39 - ERROR - root -  87%|########6 | 338/390 [18:35<02:47,  3.22s/it]
06/19/2024 01:50:40 - INFO - modeling_roberta - Training sub-loss: O 1.0914013385772705, C 1.1116101741790771, E 1.105518102645874, A 1.1054643392562866, N 1.0830917358398438
06/19/2024 01:50:40 - INFO - modeling_roberta - Training sub-loss: O 1.1147406101226807, C 1.0737959146499634, E 1.1292062997817993, A 1.0734783411026, N 1.101780891418457
06/19/2024 01:50:42 - INFO - modeling_roberta - Training sub-loss: O 1.1075838804244995, C 1.0746510028839111, E 1.0830830335617065, A 1.0876119136810303, N 1.1334097385406494
06/19/2024 01:50:42 - INFO - modeling_roberta - Training sub-loss: O 1.0912553071975708, C 1.0998539924621582, E 1.1134521961212158, A 1.0994277000427246, N 1.0857203006744385
06/19/2024 01:50:43 - ERROR - root -  87%|########6 | 339/390 [18:38<02:43,  3.21s/it]
06/19/2024 01:50:43 - INFO - modeling_roberta - Training sub-loss: O 1.0907042026519775, C 1.0723378658294678, E 1.0873558521270752, A 1.1154500246047974, N 1.111754059791565
06/19/2024 01:50:43 - INFO - modeling_roberta - Training sub-loss: O 1.104590654373169, C 1.099833369255066, E 1.0774636268615723, A 1.057536244392395, N 1.082289218902588
06/19/2024 01:50:45 - INFO - modeling_roberta - Training sub-loss: O 1.1485595703125, C 1.0766007900238037, E 1.1135265827178955, A 1.101783275604248, N 1.0727864503860474
06/19/2024 01:50:45 - INFO - modeling_roberta - Training sub-loss: O 1.1158313751220703, C 1.0885334014892578, E 1.1165599822998047, A 1.042052984237671, N 1.0895836353302002
06/19/2024 01:50:46 - ERROR - root -  87%|########7 | 340/390 [18:41<02:40,  3.21s/it]
06/19/2024 01:50:46 - INFO - root - {'loss': 1.1033, 'grad_norm': 90135.921875, 'learning_rate': 1.282051282051282e-05, 'epoch': 4.33}
06/19/2024 01:50:46 - ERROR - root -  87%|########7 | 340/390 [18:41<02:40,  3.21s/it]
06/19/2024 01:50:47 - INFO - modeling_roberta - Training sub-loss: O 1.1031270027160645, C 1.094325065612793, E 1.070791482925415, A 1.138932704925537, N 1.0986371040344238
06/19/2024 01:50:47 - INFO - modeling_roberta - Training sub-loss: O 1.1333470344543457, C 1.0910106897354126, E 1.1079691648483276, A 1.131058931350708, N 1.141647219657898
06/19/2024 01:50:48 - INFO - modeling_roberta - Training sub-loss: O 1.0337077379226685, C 1.1150784492492676, E 1.0710723400115967, A 1.1475892066955566, N 1.0630253553390503
06/19/2024 01:50:48 - INFO - modeling_roberta - Training sub-loss: O 1.081397533416748, C 1.1264904737472534, E 1.102443814277649, A 1.070420503616333, N 1.056693434715271
06/19/2024 01:50:49 - ERROR - root -  87%|########7 | 341/390 [18:44<02:37,  3.21s/it]
06/19/2024 01:50:50 - INFO - modeling_roberta - Training sub-loss: O 1.106571912765503, C 1.0407894849777222, E 1.0467915534973145, A 1.1147829294204712, N 1.134997010231018
06/19/2024 01:50:50 - INFO - modeling_roberta - Training sub-loss: O 1.112525224685669, C 1.0723309516906738, E 1.1613154411315918, A 1.0829493999481201, N 1.1472324132919312
06/19/2024 01:50:51 - INFO - modeling_roberta - Training sub-loss: O 1.1108512878417969, C 1.1246373653411865, E 1.08553147315979, A 1.143918514251709, N 1.1075801849365234
06/19/2024 01:50:51 - INFO - modeling_roberta - Training sub-loss: O 1.0899614095687866, C 1.1251075267791748, E 1.0971494913101196, A 1.0998388528823853, N 1.1210960149765015
06/19/2024 01:50:52 - ERROR - root -  88%|########7 | 342/390 [18:47<02:33,  3.21s/it]
06/19/2024 01:50:53 - INFO - modeling_roberta - Training sub-loss: O 1.1291298866271973, C 1.1259630918502808, E 1.0748271942138672, A 1.1180460453033447, N 1.0981740951538086
06/19/2024 01:50:53 - INFO - modeling_roberta - Training sub-loss: O 1.0582242012023926, C 1.0912859439849854, E 1.0866141319274902, A 1.0901449918746948, N 1.0845134258270264
06/19/2024 01:50:55 - INFO - modeling_roberta - Training sub-loss: O 1.0668797492980957, C 1.1209383010864258, E 1.0556010007858276, A 1.0986465215682983, N 1.098801612854004
06/19/2024 01:50:55 - INFO - modeling_roberta - Training sub-loss: O 1.107957363128662, C 1.1091399192810059, E 1.0709056854248047, A 1.1158978939056396, N 1.1044872999191284
06/19/2024 01:50:56 - ERROR - root -  88%|########7 | 343/390 [18:51<02:30,  3.21s/it]
06/19/2024 01:50:56 - INFO - modeling_roberta - Training sub-loss: O 1.0821635723114014, C 1.0955324172973633, E 1.114454746246338, A 1.099726676940918, N 1.0921921730041504
06/19/2024 01:50:56 - INFO - modeling_roberta - Training sub-loss: O 1.0809292793273926, C 1.0910141468048096, E 1.1250983476638794, A 1.0877702236175537, N 1.0801833868026733
06/19/2024 01:50:58 - INFO - modeling_roberta - Training sub-loss: O 1.0965148210525513, C 1.0893634557724, E 1.1193393468856812, A 1.0796091556549072, N 1.0903087854385376
06/19/2024 01:50:58 - INFO - modeling_roberta - Training sub-loss: O 1.0978933572769165, C 1.0561054944992065, E 1.082294225692749, A 1.1314412355422974, N 1.0989779233932495
06/19/2024 01:50:59 - ERROR - root -  88%|########8 | 344/390 [18:54<02:27,  3.21s/it]
06/19/2024 01:50:59 - INFO - modeling_roberta - Training sub-loss: O 1.0813976526260376, C 1.106567144393921, E 1.1006340980529785, A 1.1145102977752686, N 1.0855909585952759
06/19/2024 01:50:59 - INFO - modeling_roberta - Training sub-loss: O 1.0822527408599854, C 1.1134827136993408, E 1.0854322910308838, A 1.1009414196014404, N 1.0918303728103638
06/19/2024 01:51:01 - INFO - modeling_roberta - Training sub-loss: O 1.1003059148788452, C 1.080308437347412, E 1.1212024688720703, A 1.0840065479278564, N 1.0727055072784424
06/19/2024 01:51:01 - INFO - modeling_roberta - Training sub-loss: O 1.1068071126937866, C 1.1183210611343384, E 1.0881743431091309, A 1.0997717380523682, N 1.150490403175354
06/19/2024 01:51:02 - ERROR - root -  88%|########8 | 345/390 [18:57<02:25,  3.23s/it]
06/19/2024 01:51:04 - INFO - modeling_roberta - Training sub-loss: O 1.1195895671844482, C 1.1232110261917114, E 1.0835015773773193, A 1.1000049114227295, N 1.085378885269165
06/19/2024 01:51:04 - INFO - modeling_roberta - Training sub-loss: O 1.0505990982055664, C 1.0885531902313232, E 1.1543703079223633, A 1.1029990911483765, N 1.1222647428512573
06/19/2024 01:51:05 - INFO - modeling_roberta - Training sub-loss: O 1.0716170072555542, C 1.121215581893921, E 1.0736335515975952, A 1.1244423389434814, N 1.1080925464630127
06/19/2024 01:51:05 - INFO - modeling_roberta - Training sub-loss: O 1.1165614128112793, C 1.089173674583435, E 1.0568633079528809, A 1.0624289512634277, N 1.0853447914123535
06/19/2024 01:51:06 - ERROR - root -  89%|########8 | 346/390 [19:01<02:36,  3.55s/it]
06/19/2024 01:51:07 - INFO - modeling_roberta - Training sub-loss: O 1.085113763809204, C 1.0870583057403564, E 1.0990302562713623, A 1.1050145626068115, N 1.079464316368103
06/19/2024 01:51:07 - INFO - modeling_roberta - Training sub-loss: O 1.1533335447311401, C 1.0980290174484253, E 1.117293357849121, A 1.1094481945037842, N 1.0857045650482178
06/19/2024 01:51:09 - INFO - modeling_roberta - Training sub-loss: O 1.1048921346664429, C 1.1287353038787842, E 1.065019130706787, A 1.1129562854766846, N 1.1312596797943115
06/19/2024 01:51:09 - INFO - modeling_roberta - Training sub-loss: O 1.0778552293777466, C 1.106490135192871, E 1.0943078994750977, A 1.1059855222702026, N 1.137143611907959
06/19/2024 01:51:10 - ERROR - root -  89%|########8 | 347/390 [19:05<02:31,  3.52s/it]
06/19/2024 01:51:11 - INFO - modeling_roberta - Training sub-loss: O 1.1019749641418457, C 1.111201286315918, E 1.098806381225586, A 1.0953283309936523, N 1.0945578813552856
06/19/2024 01:51:11 - INFO - modeling_roberta - Training sub-loss: O 1.1111048460006714, C 1.1302905082702637, E 1.1276856660842896, A 1.0655527114868164, N 1.0756886005401611
06/19/2024 01:51:12 - INFO - modeling_roberta - Training sub-loss: O 1.1120351552963257, C 1.0923371315002441, E 1.1214812994003296, A 1.0806630849838257, N 1.0872327089309692
06/19/2024 01:51:12 - INFO - modeling_roberta - Training sub-loss: O 1.1075403690338135, C 1.1340875625610352, E 1.1369349956512451, A 1.0858619213104248, N 1.1233587265014648
06/19/2024 01:51:13 - ERROR - root -  89%|########9 | 348/390 [19:08<02:28,  3.53s/it]
06/19/2024 01:51:14 - INFO - modeling_roberta - Training sub-loss: O 1.0671489238739014, C 1.0840831995010376, E 1.1041467189788818, A 1.1260132789611816, N 1.1028962135314941
06/19/2024 01:51:14 - INFO - modeling_roberta - Training sub-loss: O 1.0918197631835938, C 1.097083568572998, E 1.1361074447631836, A 1.1353247165679932, N 1.0994631052017212
06/19/2024 01:51:16 - INFO - modeling_roberta - Training sub-loss: O 1.1318120956420898, C 1.089424729347229, E 1.1309298276901245, A 1.1330015659332275, N 1.1030669212341309
06/19/2024 01:51:16 - INFO - modeling_roberta - Training sub-loss: O 1.108302354812622, C 1.1142256259918213, E 1.1381945610046387, A 1.1225696802139282, N 1.0881197452545166
06/19/2024 01:51:17 - ERROR - root -  89%|########9 | 349/390 [19:12<02:21,  3.46s/it]
06/19/2024 01:51:17 - INFO - modeling_roberta - Training sub-loss: O 1.0764834880828857, C 1.124175786972046, E 1.0575380325317383, A 1.0727579593658447, N 1.089796543121338
06/19/2024 01:51:17 - INFO - modeling_roberta - Training sub-loss: O 1.0950560569763184, C 1.0754668712615967, E 1.0869203805923462, A 1.1083426475524902, N 1.11289644241333
06/19/2024 01:51:19 - INFO - modeling_roberta - Training sub-loss: O 1.114039421081543, C 1.1185762882232666, E 1.088964819908142, A 1.1213610172271729, N 1.127638578414917
06/19/2024 01:51:19 - INFO - modeling_roberta - Training sub-loss: O 1.1110209226608276, C 1.1439831256866455, E 1.1350440979003906, A 1.1690726280212402, N 1.1267056465148926
06/19/2024 01:51:20 - ERROR - root -  90%|########9 | 350/390 [19:15<02:19,  3.48s/it]
06/19/2024 01:51:20 - INFO - root - {'loss': 1.1018, 'grad_norm': 58087.015625, 'learning_rate': 1.0256410256410256e-05, 'epoch': 4.46}
06/19/2024 01:51:20 - ERROR - root -  90%|########9 | 350/390 [19:15<02:19,  3.48s/it]
06/19/2024 01:51:21 - INFO - modeling_roberta - Training sub-loss: O 1.0790586471557617, C 1.1233835220336914, E 1.084549903869629, A 1.0988301038742065, N 1.0963548421859741
06/19/2024 01:51:21 - INFO - modeling_roberta - Training sub-loss: O 1.132206678390503, C 1.0665820837020874, E 1.1041933298110962, A 1.0924118757247925, N 1.1161572933197021
06/19/2024 01:51:23 - INFO - modeling_roberta - Training sub-loss: O 1.1248419284820557, C 1.0998153686523438, E 1.1072697639465332, A 1.107325553894043, N 1.1295602321624756
06/19/2024 01:51:23 - INFO - modeling_roberta - Training sub-loss: O 1.1351134777069092, C 1.0882210731506348, E 1.0802147388458252, A 1.1158838272094727, N 1.0718281269073486
06/19/2024 01:51:24 - ERROR - root -  90%|######### | 351/390 [19:19<02:15,  3.47s/it]
06/19/2024 01:51:24 - INFO - modeling_roberta - Training sub-loss: O 1.0971448421478271, C 1.0980533361434937, E 1.0683643817901611, A 1.123241901397705, N 1.1149004697799683
06/19/2024 01:51:24 - INFO - modeling_roberta - Training sub-loss: O 1.1276848316192627, C 1.1401927471160889, E 1.1318044662475586, A 1.072137475013733, N 1.1006563901901245
06/19/2024 01:51:26 - INFO - modeling_roberta - Training sub-loss: O 1.097266435623169, C 1.0986047983169556, E 1.0770251750946045, A 1.1256440877914429, N 1.1192697286605835
06/19/2024 01:51:26 - INFO - modeling_roberta - Training sub-loss: O 1.080599069595337, C 1.0698784589767456, E 1.0540409088134766, A 1.1054863929748535, N 1.0791192054748535
06/19/2024 01:51:27 - ERROR - root -  90%|######### | 352/390 [19:22<02:10,  3.45s/it]
06/19/2024 01:51:28 - INFO - modeling_roberta - Training sub-loss: O 1.1034817695617676, C 1.1327292919158936, E 1.0627843141555786, A 1.1024186611175537, N 1.1233316659927368
06/19/2024 01:51:28 - INFO - modeling_roberta - Training sub-loss: O 1.0683341026306152, C 1.0614802837371826, E 1.1290353536605835, A 1.1095647811889648, N 1.0859493017196655
06/19/2024 01:51:29 - INFO - modeling_roberta - Training sub-loss: O 1.068817377090454, C 1.11018705368042, E 1.0972024202346802, A 1.1102358102798462, N 1.0535640716552734
06/19/2024 01:51:29 - INFO - modeling_roberta - Training sub-loss: O 1.0919454097747803, C 1.112797498703003, E 1.0738157033920288, A 1.1207636594772339, N 1.0659700632095337
06/19/2024 01:51:30 - ERROR - root -  91%|######### | 353/390 [19:25<02:07,  3.45s/it]
06/19/2024 01:51:31 - INFO - modeling_roberta - Training sub-loss: O 1.114626169204712, C 1.0894346237182617, E 1.1066718101501465, A 1.1190063953399658, N 1.1088604927062988
06/19/2024 01:51:31 - INFO - modeling_roberta - Training sub-loss: O 1.1064937114715576, C 1.0494188070297241, E 1.1101034879684448, A 1.0956073999404907, N 1.117617130279541
06/19/2024 01:51:33 - INFO - modeling_roberta - Training sub-loss: O 1.1163570880889893, C 1.0582995414733887, E 1.107906460762024, A 1.1490007638931274, N 1.0901799201965332
06/19/2024 01:51:33 - INFO - modeling_roberta - Training sub-loss: O 1.0974619388580322, C 1.0728979110717773, E 1.1167629957199097, A 1.1005403995513916, N 1.0862183570861816
06/19/2024 01:51:34 - ERROR - root -  91%|######### | 354/390 [19:29<02:06,  3.51s/it]
06/19/2024 01:51:35 - INFO - modeling_roberta - Training sub-loss: O 1.1294386386871338, C 1.1125686168670654, E 1.0869863033294678, A 1.1062264442443848, N 1.1110150814056396
06/19/2024 01:51:35 - INFO - modeling_roberta - Training sub-loss: O 1.0318737030029297, C 1.0708692073822021, E 1.0948503017425537, A 1.0620503425598145, N 1.1024693250656128
06/19/2024 01:51:36 - INFO - modeling_roberta - Training sub-loss: O 1.1115342378616333, C 1.0941027402877808, E 1.1171027421951294, A 1.0972672700881958, N 1.0964865684509277
06/19/2024 01:51:36 - INFO - modeling_roberta - Training sub-loss: O 1.0595662593841553, C 1.0623054504394531, E 1.071359634399414, A 1.1143109798431396, N 1.080337405204773
06/19/2024 01:51:37 - ERROR - root -  91%|#########1| 355/390 [19:32<02:01,  3.46s/it]
06/19/2024 01:51:38 - INFO - modeling_roberta - Training sub-loss: O 1.1230230331420898, C 1.0888733863830566, E 1.126444697380066, A 1.062561273574829, N 1.106752634048462
06/19/2024 01:51:38 - INFO - modeling_roberta - Training sub-loss: O 1.1089273691177368, C 1.1150790452957153, E 1.1635408401489258, A 1.1122829914093018, N 1.1131463050842285
06/19/2024 01:51:40 - INFO - modeling_roberta - Training sub-loss: O 1.111876130104065, C 1.1204630136489868, E 1.067201852798462, A 1.1374388933181763, N 1.130214810371399
06/19/2024 01:51:40 - INFO - modeling_roberta - Training sub-loss: O 1.0892119407653809, C 1.1270403861999512, E 1.139756679534912, A 1.100509524345398, N 1.1316630840301514
06/19/2024 01:51:41 - ERROR - root -  91%|#########1| 356/390 [19:36<01:56,  3.43s/it]
06/19/2024 01:51:41 - INFO - modeling_roberta - Training sub-loss: O 1.1438051462173462, C 1.1069121360778809, E 1.0941524505615234, A 1.055356502532959, N 1.0809509754180908
06/19/2024 01:51:41 - INFO - modeling_roberta - Training sub-loss: O 1.083893895149231, C 1.0778419971466064, E 1.1285234689712524, A 1.1135237216949463, N 1.1106394529342651
06/19/2024 01:51:43 - INFO - modeling_roberta - Training sub-loss: O 1.1110479831695557, C 1.104598879814148, E 1.1571354866027832, A 1.1012362241744995, N 1.101933479309082
06/19/2024 01:51:43 - INFO - modeling_roberta - Training sub-loss: O 1.0640441179275513, C 1.0940083265304565, E 1.1092076301574707, A 1.1259745359420776, N 1.0857839584350586
06/19/2024 01:51:44 - ERROR - root -  92%|#########1| 357/390 [19:39<01:52,  3.40s/it]
06/19/2024 01:51:45 - INFO - modeling_roberta - Training sub-loss: O 1.0946857929229736, C 1.0602283477783203, E 1.1134870052337646, A 1.1168073415756226, N 1.1072076559066772
06/19/2024 01:51:45 - INFO - modeling_roberta - Training sub-loss: O 1.0699005126953125, C 1.1015706062316895, E 1.1107280254364014, A 1.067979335784912, N 1.086552381515503
06/19/2024 01:51:46 - INFO - modeling_roberta - Training sub-loss: O 1.1234773397445679, C 1.100067138671875, E 1.07122802734375, A 1.1323521137237549, N 1.0802628993988037
06/19/2024 01:51:46 - INFO - modeling_roberta - Training sub-loss: O 1.1565415859222412, C 1.1038157939910889, E 1.1050488948822021, A 1.0906951427459717, N 1.0974701642990112
06/19/2024 01:51:47 - ERROR - root -  92%|#########1| 358/390 [19:42<01:48,  3.38s/it]
06/19/2024 01:51:48 - INFO - modeling_roberta - Training sub-loss: O 1.0953400135040283, C 1.0526354312896729, E 1.119612455368042, A 1.1384007930755615, N 1.092954397201538
06/19/2024 01:51:48 - INFO - modeling_roberta - Training sub-loss: O 1.1163663864135742, C 1.0778905153274536, E 1.1235511302947998, A 1.072421908378601, N 1.1301891803741455
06/19/2024 01:51:50 - INFO - modeling_roberta - Training sub-loss: O 1.0915924310684204, C 1.1000430583953857, E 1.0525152683258057, A 1.075397253036499, N 1.0774251222610474
06/19/2024 01:51:50 - INFO - modeling_roberta - Training sub-loss: O 1.067713737487793, C 1.0878828763961792, E 1.1160602569580078, A 1.1051688194274902, N 1.0617170333862305
06/19/2024 01:51:51 - ERROR - root -  92%|#########2| 359/390 [19:46<01:43,  3.34s/it]
06/19/2024 01:51:51 - INFO - modeling_roberta - Training sub-loss: O 1.0722732543945312, C 1.0577993392944336, E 1.124693751335144, A 1.1246343851089478, N 1.1147792339324951
06/19/2024 01:51:51 - INFO - modeling_roberta - Training sub-loss: O 1.0905932188034058, C 1.0808053016662598, E 1.0890603065490723, A 1.1009242534637451, N 1.1243505477905273
06/19/2024 01:51:53 - INFO - modeling_roberta - Training sub-loss: O 1.1052926778793335, C 1.0742093324661255, E 1.1003490686416626, A 1.1349382400512695, N 1.1254639625549316
06/19/2024 01:51:53 - INFO - modeling_roberta - Training sub-loss: O 1.0829122066497803, C 1.1161985397338867, E 1.119856357574463, A 1.1232552528381348, N 1.1124846935272217
06/19/2024 01:51:54 - ERROR - root -  92%|#########2| 360/390 [19:49<01:39,  3.33s/it]
06/19/2024 01:51:54 - INFO - root - {'loss': 1.1, 'grad_norm': 61877.68359375, 'learning_rate': 7.692307692307694e-06, 'epoch': 4.59}
06/19/2024 01:51:54 - ERROR - root -  92%|#########2| 360/390 [19:49<01:39,  3.33s/it]
06/19/2024 01:51:55 - INFO - modeling_roberta - Training sub-loss: O 1.1050655841827393, C 1.1016743183135986, E 1.0881757736206055, A 1.1455551385879517, N 1.123457431793213
06/19/2024 01:51:55 - INFO - modeling_roberta - Training sub-loss: O 1.092134952545166, C 1.0910532474517822, E 1.071688175201416, A 1.0761125087738037, N 1.106688380241394
06/19/2024 01:51:56 - INFO - modeling_roberta - Training sub-loss: O 1.1308339834213257, C 1.0854122638702393, E 1.0640623569488525, A 1.0938265323638916, N 1.1207568645477295
06/19/2024 01:51:56 - INFO - modeling_roberta - Training sub-loss: O 1.093768835067749, C 1.0981136560440063, E 1.0819623470306396, A 1.086447834968567, N 1.113417387008667
06/19/2024 01:51:57 - ERROR - root -  93%|#########2| 361/390 [19:52<01:35,  3.29s/it]
06/19/2024 01:51:58 - INFO - modeling_roberta - Training sub-loss: O 1.1109871864318848, C 1.0882465839385986, E 1.077455997467041, A 1.1084576845169067, N 1.0980639457702637
06/19/2024 01:51:58 - INFO - modeling_roberta - Training sub-loss: O 1.0908887386322021, C 1.1068098545074463, E 1.0907809734344482, A 1.0840582847595215, N 1.0456960201263428
06/19/2024 01:51:59 - INFO - modeling_roberta - Training sub-loss: O 1.1415766477584839, C 1.0673246383666992, E 1.1198776960372925, A 1.1368780136108398, N 1.0942556858062744
06/19/2024 01:52:00 - INFO - modeling_roberta - Training sub-loss: O 1.1401011943817139, C 1.0715574026107788, E 1.0861343145370483, A 1.1424193382263184, N 1.075214147567749
06/19/2024 01:52:00 - ERROR - root -  93%|#########2| 362/390 [19:56<01:31,  3.28s/it]
06/19/2024 01:52:01 - INFO - modeling_roberta - Training sub-loss: O 1.1327276229858398, C 1.127364158630371, E 1.1439125537872314, A 1.0965304374694824, N 1.1471078395843506
06/19/2024 01:52:01 - INFO - modeling_roberta - Training sub-loss: O 1.1155496835708618, C 1.1583619117736816, E 1.1178191900253296, A 1.098605751991272, N 1.080568790435791
06/19/2024 01:52:03 - INFO - modeling_roberta - Training sub-loss: O 1.0935286283493042, C 1.1012277603149414, E 1.1448525190353394, A 1.1226351261138916, N 1.0924854278564453
06/19/2024 01:52:03 - INFO - modeling_roberta - Training sub-loss: O 1.1201128959655762, C 1.1126660108566284, E 1.1317968368530273, A 1.1494513750076294, N 1.11505126953125
06/19/2024 01:52:04 - ERROR - root -  93%|#########3| 363/390 [19:59<01:29,  3.31s/it]
06/19/2024 01:52:05 - INFO - modeling_roberta - Training sub-loss: O 1.1424915790557861, C 1.1030317544937134, E 1.1162121295928955, A 1.1137863397598267, N 1.118788480758667
06/19/2024 01:52:05 - INFO - modeling_roberta - Training sub-loss: O 1.1209772825241089, C 1.1145540475845337, E 1.1235929727554321, A 1.105774998664856, N 1.162287950515747
06/19/2024 01:52:06 - INFO - modeling_roberta - Training sub-loss: O 1.123679518699646, C 1.108769178390503, E 1.1123239994049072, A 1.1120834350585938, N 1.1138558387756348
06/19/2024 01:52:06 - INFO - modeling_roberta - Training sub-loss: O 1.0458354949951172, C 1.0908335447311401, E 1.1296918392181396, A 1.085306167602539, N 1.1051099300384521
06/19/2024 01:52:07 - ERROR - root -  93%|#########3| 364/390 [20:02<01:26,  3.32s/it]
06/19/2024 01:52:08 - INFO - modeling_roberta - Training sub-loss: O 1.0672729015350342, C 1.0873403549194336, E 1.1204445362091064, A 1.0953463315963745, N 1.126169204711914
06/19/2024 01:52:08 - INFO - modeling_roberta - Training sub-loss: O 1.1100857257843018, C 1.0965358018875122, E 1.0903334617614746, A 1.1105823516845703, N 1.147452473640442
06/19/2024 01:52:09 - INFO - modeling_roberta - Training sub-loss: O 1.0767773389816284, C 1.0975816249847412, E 1.0785261392593384, A 1.1086845397949219, N 1.1056715250015259
06/19/2024 01:52:09 - INFO - modeling_roberta - Training sub-loss: O 1.1031477451324463, C 1.1297756433486938, E 1.0710605382919312, A 1.1014492511749268, N 1.066235065460205
06/19/2024 01:52:10 - ERROR - root -  94%|#########3| 365/390 [20:05<01:22,  3.29s/it]
06/19/2024 01:52:11 - INFO - modeling_roberta - Training sub-loss: O 1.0903654098510742, C 1.0952112674713135, E 1.0642163753509521, A 1.0641019344329834, N 1.1329272985458374
06/19/2024 01:52:11 - INFO - modeling_roberta - Training sub-loss: O 1.1340967416763306, C 1.1086270809173584, E 1.0869388580322266, A 1.1130130290985107, N 1.1211532354354858
06/19/2024 01:52:13 - INFO - modeling_roberta - Training sub-loss: O 1.143383502960205, C 1.1341328620910645, E 1.0971693992614746, A 1.101118564605713, N 1.0998910665512085
06/19/2024 01:52:13 - INFO - modeling_roberta - Training sub-loss: O 1.0801904201507568, C 1.0845472812652588, E 1.1109764575958252, A 1.1095359325408936, N 1.117390513420105
06/19/2024 01:52:14 - ERROR - root -  94%|#########3| 366/390 [20:09<01:18,  3.27s/it]
06/19/2024 01:52:14 - INFO - modeling_roberta - Training sub-loss: O 1.0878984928131104, C 1.0515391826629639, E 1.1228010654449463, A 1.0983357429504395, N 1.1104618310928345
06/19/2024 01:52:14 - INFO - modeling_roberta - Training sub-loss: O 1.0752766132354736, C 1.0930968523025513, E 1.1253019571304321, A 1.0625641345977783, N 1.1373738050460815
06/19/2024 01:52:16 - INFO - modeling_roberta - Training sub-loss: O 1.1088204383850098, C 1.1113898754119873, E 1.142099142074585, A 1.1014437675476074, N 1.1280436515808105
06/19/2024 01:52:16 - INFO - modeling_roberta - Training sub-loss: O 1.0459696054458618, C 1.125858187675476, E 1.100886344909668, A 1.1303223371505737, N 1.1141115427017212
06/19/2024 01:52:17 - ERROR - root -  94%|#########4| 367/390 [20:12<01:14,  3.25s/it]
06/19/2024 01:52:17 - INFO - modeling_roberta - Training sub-loss: O 1.121797800064087, C 1.1153488159179688, E 1.1191914081573486, A 1.064902663230896, N 1.1201791763305664
06/19/2024 01:52:17 - INFO - modeling_roberta - Training sub-loss: O 1.1109108924865723, C 1.1035165786743164, E 1.0832200050354004, A 1.115745186805725, N 1.1039538383483887
06/19/2024 01:52:19 - INFO - modeling_roberta - Training sub-loss: O 1.0786933898925781, C 1.0747727155685425, E 1.0939972400665283, A 1.0974552631378174, N 1.1109931468963623
06/19/2024 01:52:19 - INFO - modeling_roberta - Training sub-loss: O 1.0904734134674072, C 1.1103107929229736, E 1.1071009635925293, A 1.1000546216964722, N 1.1309635639190674
06/19/2024 01:52:20 - ERROR - root -  94%|#########4| 368/390 [20:15<01:12,  3.30s/it]
06/19/2024 01:52:21 - INFO - modeling_roberta - Training sub-loss: O 1.0695385932922363, C 1.0805954933166504, E 1.0927956104278564, A 1.1055183410644531, N 1.0957973003387451
06/19/2024 01:52:21 - INFO - modeling_roberta - Training sub-loss: O 1.0671195983886719, C 1.0969834327697754, E 1.0448150634765625, A 1.090434193611145, N 1.0809218883514404
06/19/2024 01:52:22 - INFO - modeling_roberta - Training sub-loss: O 1.065511703491211, C 1.131636142730713, E 1.0977985858917236, A 1.1003285646438599, N 1.0897901058197021
06/19/2024 01:52:22 - INFO - modeling_roberta - Training sub-loss: O 1.0872728824615479, C 1.0749751329421997, E 1.0871814489364624, A 1.116013526916504, N 1.1115243434906006
06/19/2024 01:52:23 - ERROR - root -  95%|#########4| 369/390 [20:19<01:08,  3.28s/it]
06/19/2024 01:52:24 - INFO - modeling_roberta - Training sub-loss: O 1.1039533615112305, C 1.1066914796829224, E 1.1081147193908691, A 1.1057898998260498, N 1.1219950914382935
06/19/2024 01:52:24 - INFO - modeling_roberta - Training sub-loss: O 1.0896304845809937, C 1.0694661140441895, E 1.0722863674163818, A 1.1583833694458008, N 1.0614330768585205
06/19/2024 01:52:26 - INFO - modeling_roberta - Training sub-loss: O 1.1444778442382812, C 1.1174545288085938, E 1.0905762910842896, A 1.097449779510498, N 1.1553637981414795
06/19/2024 01:52:26 - INFO - modeling_roberta - Training sub-loss: O 1.0997557640075684, C 1.092871904373169, E 1.0998846292495728, A 1.101180076599121, N 1.0729937553405762
06/19/2024 01:52:27 - ERROR - root -  95%|#########4| 370/390 [20:22<01:05,  3.25s/it]
06/19/2024 01:52:27 - INFO - root - {'loss': 1.1033, 'grad_norm': 82917.5390625, 'learning_rate': 5.128205128205128e-06, 'epoch': 4.71}
06/19/2024 01:52:27 - ERROR - root -  95%|#########4| 370/390 [20:22<01:05,  3.25s/it]
06/19/2024 01:52:27 - INFO - modeling_roberta - Training sub-loss: O 1.1202936172485352, C 1.1095744371414185, E 1.0576179027557373, A 1.1047266721725464, N 1.1346391439437866
06/19/2024 01:52:27 - INFO - modeling_roberta - Training sub-loss: O 1.109898328781128, C 1.1017135381698608, E 1.0919334888458252, A 1.0973502397537231, N 1.119531273841858
06/19/2024 01:52:29 - INFO - modeling_roberta - Training sub-loss: O 1.1046656370162964, C 1.1272938251495361, E 1.079222559928894, A 1.1102957725524902, N 1.10202956199646
06/19/2024 01:52:29 - INFO - modeling_roberta - Training sub-loss: O 1.1035805940628052, C 1.0691912174224854, E 1.0961225032806396, A 1.1209355592727661, N 1.0748274326324463
06/19/2024 01:52:30 - ERROR - root -  95%|#########5| 371/390 [20:25<01:01,  3.24s/it]
06/19/2024 01:52:31 - INFO - modeling_roberta - Training sub-loss: O 1.138577938079834, C 1.0729360580444336, E 1.1402570009231567, A 1.0986979007720947, N 1.0578763484954834
06/19/2024 01:52:31 - INFO - modeling_roberta - Training sub-loss: O 1.1401891708374023, C 1.0800458192825317, E 1.1283917427062988, A 1.0992763042449951, N 1.105217456817627
06/19/2024 01:52:32 - INFO - modeling_roberta - Training sub-loss: O 1.1045784950256348, C 1.0966339111328125, E 1.1167503595352173, A 1.0825791358947754, N 1.1112643480300903
06/19/2024 01:52:32 - INFO - modeling_roberta - Training sub-loss: O 1.0856963396072388, C 1.0833945274353027, E 1.0979931354522705, A 1.1331229209899902, N 1.0973502397537231
06/19/2024 01:52:33 - ERROR - root -  95%|#########5| 372/390 [20:28<00:57,  3.22s/it]
06/19/2024 01:52:34 - INFO - modeling_roberta - Training sub-loss: O 1.1069769859313965, C 1.0845801830291748, E 1.0993833541870117, A 1.1082757711410522, N 1.0640478134155273
06/19/2024 01:52:34 - INFO - modeling_roberta - Training sub-loss: O 1.1230086088180542, C 1.1283848285675049, E 1.0895010232925415, A 1.0954416990280151, N 1.1155786514282227
06/19/2024 01:52:35 - INFO - modeling_roberta - Training sub-loss: O 1.1051466464996338, C 1.1249736547470093, E 1.1213042736053467, A 1.1298742294311523, N 1.1313364505767822
06/19/2024 01:52:35 - INFO - modeling_roberta - Training sub-loss: O 1.1445331573486328, C 1.1401662826538086, E 1.1368833780288696, A 1.110577940940857, N 1.0828369855880737
06/19/2024 01:52:36 - ERROR - root -  96%|#########5| 373/390 [20:31<00:54,  3.21s/it]
06/19/2024 01:52:37 - INFO - modeling_roberta - Training sub-loss: O 1.0588427782058716, C 1.0833957195281982, E 1.0952138900756836, A 1.0946152210235596, N 1.1114072799682617
06/19/2024 01:52:37 - INFO - modeling_roberta - Training sub-loss: O 1.126975178718567, C 1.1039772033691406, E 1.1026334762573242, A 1.1412971019744873, N 1.061477780342102
06/19/2024 01:52:38 - INFO - modeling_roberta - Training sub-loss: O 1.101170301437378, C 1.1030036211013794, E 1.0306756496429443, A 1.1125946044921875, N 1.106575846672058
06/19/2024 01:52:38 - INFO - modeling_roberta - Training sub-loss: O 1.0655333995819092, C 1.1109240055084229, E 1.1721882820129395, A 1.082110047340393, N 1.1014543771743774
06/19/2024 01:52:39 - ERROR - root -  96%|#########5| 374/390 [20:34<00:51,  3.20s/it]
06/19/2024 01:52:40 - INFO - modeling_roberta - Training sub-loss: O 1.151763677597046, C 1.1628133058547974, E 1.155099630355835, A 1.0749082565307617, N 1.0785900354385376
06/19/2024 01:52:40 - INFO - modeling_roberta - Training sub-loss: O 1.1157407760620117, C 1.1022719144821167, E 1.126331090927124, A 1.0891927480697632, N 1.1029109954833984
06/19/2024 01:52:42 - INFO - modeling_roberta - Training sub-loss: O 1.088279366493225, C 1.116795539855957, E 1.1183449029922485, A 1.1084961891174316, N 1.0808837413787842
06/19/2024 01:52:42 - INFO - modeling_roberta - Training sub-loss: O 1.0319430828094482, C 1.1555023193359375, E 1.1382116079330444, A 1.0886356830596924, N 1.1397125720977783
06/19/2024 01:52:43 - ERROR - root -  96%|#########6| 375/390 [20:38<00:48,  3.21s/it]
06/19/2024 01:52:43 - INFO - modeling_roberta - Training sub-loss: O 1.0748636722564697, C 1.1391266584396362, E 1.0771241188049316, A 1.0779533386230469, N 1.1090061664581299
06/19/2024 01:52:43 - INFO - modeling_roberta - Training sub-loss: O 1.1359095573425293, C 1.0984768867492676, E 1.1421878337860107, A 1.1225860118865967, N 1.0974533557891846
06/19/2024 01:52:45 - INFO - modeling_roberta - Training sub-loss: O 1.1016933917999268, C 1.0919344425201416, E 1.11006498336792, A 1.0894804000854492, N 1.104237675666809
06/19/2024 01:52:45 - INFO - modeling_roberta - Training sub-loss: O 1.1204582452774048, C 1.114454746246338, E 1.0536742210388184, A 1.1600303649902344, N 1.0850205421447754
06/19/2024 01:52:46 - ERROR - root -  96%|#########6| 376/390 [20:41<00:44,  3.20s/it]
06/19/2024 01:52:46 - INFO - modeling_roberta - Training sub-loss: O 1.0821950435638428, C 1.0893657207489014, E 1.1159199476242065, A 1.0771820545196533, N 1.0957801342010498
06/19/2024 01:52:46 - INFO - modeling_roberta - Training sub-loss: O 1.1120553016662598, C 1.0506069660186768, E 1.1087924242019653, A 1.1063992977142334, N 1.1344670057296753
06/19/2024 01:52:48 - INFO - modeling_roberta - Training sub-loss: O 1.120227575302124, C 1.0990638732910156, E 1.1083273887634277, A 1.0836106538772583, N 1.1406651735305786
06/19/2024 01:52:48 - INFO - modeling_roberta - Training sub-loss: O 1.0881314277648926, C 1.1174089908599854, E 1.1006841659545898, A 1.090897798538208, N 1.0715728998184204
06/19/2024 01:52:49 - ERROR - root -  97%|#########6| 377/390 [20:44<00:41,  3.20s/it]
06/19/2024 01:52:50 - INFO - modeling_roberta - Training sub-loss: O 1.1210389137268066, C 1.079946517944336, E 1.0804648399353027, A 1.079750895500183, N 1.0673186779022217
06/19/2024 01:52:50 - INFO - modeling_roberta - Training sub-loss: O 1.0860087871551514, C 1.1305686235427856, E 1.0778698921203613, A 1.1324642896652222, N 1.0933783054351807
06/19/2024 01:52:51 - INFO - modeling_roberta - Training sub-loss: O 1.0987552404403687, C 1.1282151937484741, E 1.099723219871521, A 1.121070384979248, N 1.1038401126861572
06/19/2024 01:52:51 - INFO - modeling_roberta - Training sub-loss: O 1.1692216396331787, C 1.1018584966659546, E 1.1202607154846191, A 1.1068410873413086, N 1.1017663478851318
06/19/2024 01:52:52 - ERROR - root -  97%|#########6| 378/390 [20:47<00:38,  3.21s/it]
06/19/2024 01:52:53 - INFO - modeling_roberta - Training sub-loss: O 1.103675127029419, C 1.1228694915771484, E 1.145536184310913, A 1.1224348545074463, N 1.0960243940353394
06/19/2024 01:52:53 - INFO - modeling_roberta - Training sub-loss: O 1.1116869449615479, C 1.1021242141723633, E 1.089856505393982, A 1.1007959842681885, N 1.0869357585906982
06/19/2024 01:52:54 - INFO - modeling_roberta - Training sub-loss: O 1.0744397640228271, C 1.0702377557754517, E 1.088425636291504, A 1.1049882173538208, N 1.0796775817871094
06/19/2024 01:52:54 - INFO - modeling_roberta - Training sub-loss: O 1.1268202066421509, C 1.1106116771697998, E 1.1183834075927734, A 1.093272089958191, N 1.0958433151245117
06/19/2024 01:52:55 - ERROR - root -  97%|#########7| 379/390 [20:50<00:35,  3.21s/it]
06/19/2024 01:52:56 - INFO - modeling_roberta - Training sub-loss: O 1.0938100814819336, C 1.063326120376587, E 1.0965197086334229, A 1.0874031782150269, N 1.1246837377548218
06/19/2024 01:52:56 - INFO - modeling_roberta - Training sub-loss: O 1.104830026626587, C 1.162384271621704, E 1.098679542541504, A 1.1325562000274658, N 1.112745761871338
06/19/2024 01:52:58 - INFO - modeling_roberta - Training sub-loss: O 1.0923949480056763, C 1.1192107200622559, E 1.0919106006622314, A 1.0747339725494385, N 1.1069061756134033
06/19/2024 01:52:58 - INFO - modeling_roberta - Training sub-loss: O 1.0958623886108398, C 1.1014926433563232, E 1.1429977416992188, A 1.138541579246521, N 1.0675801038742065
06/19/2024 01:52:59 - ERROR - root -  97%|#########7| 380/390 [20:54<00:32,  3.22s/it]
06/19/2024 01:52:59 - INFO - root - {'loss': 1.1045, 'grad_norm': 61285.5, 'learning_rate': 2.564102564102564e-06, 'epoch': 4.84}
06/19/2024 01:52:59 - ERROR - root -  97%|#########7| 380/390 [20:54<00:32,  3.22s/it]
06/19/2024 01:52:59 - INFO - modeling_roberta - Training sub-loss: O 1.070838451385498, C 1.098589301109314, E 1.0797338485717773, A 1.1531310081481934, N 1.0974515676498413
06/19/2024 01:52:59 - INFO - modeling_roberta - Training sub-loss: O 1.0965759754180908, C 1.0944288969039917, E 1.1367809772491455, A 1.1112691164016724, N 1.062894582748413
06/19/2024 01:53:01 - INFO - modeling_roberta - Training sub-loss: O 1.0814173221588135, C 1.1212764978408813, E 1.1032458543777466, A 1.0784127712249756, N 1.1268706321716309
06/19/2024 01:53:01 - INFO - modeling_roberta - Training sub-loss: O 1.0605682134628296, C 1.0753443241119385, E 1.120558500289917, A 1.0904297828674316, N 1.1210969686508179
06/19/2024 01:53:02 - ERROR - root -  98%|#########7| 381/390 [20:57<00:29,  3.24s/it]
06/19/2024 01:53:03 - INFO - modeling_roberta - Training sub-loss: O 1.109002947807312, C 1.0885701179504395, E 1.0977377891540527, A 1.0809234380722046, N 1.094388484954834
06/19/2024 01:53:03 - INFO - modeling_roberta - Training sub-loss: O 1.0968589782714844, C 1.05497145652771, E 1.0828227996826172, A 1.0960474014282227, N 1.096714973449707
06/19/2024 01:53:04 - INFO - modeling_roberta - Training sub-loss: O 1.0787882804870605, C 1.0893586874008179, E 1.1131951808929443, A 1.1203140020370483, N 1.1005641222000122
06/19/2024 01:53:04 - INFO - modeling_roberta - Training sub-loss: O 1.0628714561462402, C 1.0922235250473022, E 1.1150715351104736, A 1.1305701732635498, N 1.078568696975708
06/19/2024 01:53:05 - ERROR - root -  98%|#########7| 382/390 [21:00<00:25,  3.22s/it]
06/19/2024 01:53:06 - INFO - modeling_roberta - Training sub-loss: O 1.0956088304519653, C 1.085191249847412, E 1.0861297845840454, A 1.0991300344467163, N 1.135048508644104
06/19/2024 01:53:06 - INFO - modeling_roberta - Training sub-loss: O 1.1415435075759888, C 1.1183030605316162, E 1.0582129955291748, A 1.118757963180542, N 1.0959715843200684
06/19/2024 01:53:07 - INFO - modeling_roberta - Training sub-loss: O 1.1382865905761719, C 1.0991543531417847, E 1.0967459678649902, A 1.0765125751495361, N 1.1177209615707397
06/19/2024 01:53:07 - INFO - modeling_roberta - Training sub-loss: O 1.0512347221374512, C 1.10599684715271, E 1.0891517400741577, A 1.1163697242736816, N 1.066394329071045
06/19/2024 01:53:08 - ERROR - root -  98%|#########8| 383/390 [21:03<00:22,  3.22s/it]
06/19/2024 01:53:09 - INFO - modeling_roberta - Training sub-loss: O 1.09345281124115, C 1.1250290870666504, E 1.0430264472961426, A 1.130021572113037, N 1.1185276508331299
06/19/2024 01:53:09 - INFO - modeling_roberta - Training sub-loss: O 1.0940663814544678, C 1.1459404230117798, E 1.1222798824310303, A 1.0889302492141724, N 1.060898780822754
06/19/2024 01:53:11 - INFO - modeling_roberta - Training sub-loss: O 1.145148515701294, C 1.1014461517333984, E 1.0654311180114746, A 1.1143250465393066, N 1.0919278860092163
06/19/2024 01:53:11 - INFO - modeling_roberta - Training sub-loss: O 1.0702557563781738, C 1.0970580577850342, E 1.0784063339233398, A 1.1072402000427246, N 1.0888540744781494
06/19/2024 01:53:12 - ERROR - root -  98%|#########8| 384/390 [21:07<00:19,  3.25s/it]
06/19/2024 01:53:12 - INFO - modeling_roberta - Training sub-loss: O 1.128352165222168, C 1.1202735900878906, E 1.0947638750076294, A 1.1391183137893677, N 1.1029679775238037
06/19/2024 01:53:12 - INFO - modeling_roberta - Training sub-loss: O 1.1251341104507446, C 1.1630258560180664, E 1.1225135326385498, A 1.0849580764770508, N 1.0974128246307373
06/19/2024 01:53:14 - INFO - modeling_roberta - Training sub-loss: O 1.117852807044983, C 1.13926100730896, E 1.0964908599853516, A 1.0744354724884033, N 1.0816670656204224
06/19/2024 01:53:14 - INFO - modeling_roberta - Training sub-loss: O 1.097646713256836, C 1.0897855758666992, E 1.1480680704116821, A 1.065577507019043, N 1.0901880264282227
06/19/2024 01:53:15 - ERROR - root -  99%|#########8| 385/390 [21:10<00:16,  3.29s/it]
06/19/2024 01:53:16 - INFO - modeling_roberta - Training sub-loss: O 1.1028201580047607, C 1.1130011081695557, E 1.1286766529083252, A 1.1099133491516113, N 1.0996100902557373
06/19/2024 01:53:16 - INFO - modeling_roberta - Training sub-loss: O 1.1310908794403076, C 1.083147644996643, E 1.080289602279663, A 1.1005076169967651, N 1.1049424409866333
06/19/2024 01:53:17 - INFO - modeling_roberta - Training sub-loss: O 1.142195701599121, C 1.0627009868621826, E 1.0901095867156982, A 1.1116673946380615, N 1.0997447967529297
06/19/2024 01:53:17 - INFO - modeling_roberta - Training sub-loss: O 1.1275891065597534, C 1.0678067207336426, E 1.0983279943466187, A 1.1090617179870605, N 1.106073260307312
06/19/2024 01:53:18 - ERROR - root -  99%|#########8| 386/390 [21:13<00:13,  3.30s/it]
06/19/2024 01:53:19 - INFO - modeling_roberta - Training sub-loss: O 1.114891767501831, C 1.1133441925048828, E 1.1263660192489624, A 1.064046859741211, N 1.1077873706817627
06/19/2024 01:53:19 - INFO - modeling_roberta - Training sub-loss: O 1.0908098220825195, C 1.0813096761703491, E 1.1158690452575684, A 1.1205873489379883, N 1.1212314367294312
06/19/2024 01:53:21 - INFO - modeling_roberta - Training sub-loss: O 1.106748342514038, C 1.0648713111877441, E 1.169175624847412, A 1.081626296043396, N 1.113515853881836
06/19/2024 01:53:21 - INFO - modeling_roberta - Training sub-loss: O 1.1030104160308838, C 1.0453852415084839, E 1.1230580806732178, A 1.0807688236236572, N 1.0778344869613647
06/19/2024 01:53:22 - ERROR - root -  99%|#########9| 387/390 [21:17<00:09,  3.30s/it]
06/19/2024 01:53:22 - INFO - modeling_roberta - Training sub-loss: O 1.0940990447998047, C 1.0915724039077759, E 1.112871766090393, A 1.0824147462844849, N 1.065812587738037
06/19/2024 01:53:22 - INFO - modeling_roberta - Training sub-loss: O 1.0608928203582764, C 1.0627061128616333, E 1.0710549354553223, A 1.1115961074829102, N 1.0944898128509521
06/19/2024 01:53:24 - INFO - modeling_roberta - Training sub-loss: O 1.0996781587600708, C 1.065708875656128, E 1.0642731189727783, A 1.1221803426742554, N 1.047266960144043
06/19/2024 01:53:24 - INFO - modeling_roberta - Training sub-loss: O 1.1085118055343628, C 1.0987772941589355, E 1.1403071880340576, A 1.1129333972930908, N 1.1165752410888672
06/19/2024 01:53:25 - ERROR - root -  99%|#########9| 388/390 [21:20<00:06,  3.29s/it]
06/19/2024 01:53:26 - INFO - modeling_roberta - Training sub-loss: O 1.1318604946136475, C 1.1299082040786743, E 1.0867984294891357, A 1.1316161155700684, N 1.1203199625015259
06/19/2024 01:53:26 - INFO - modeling_roberta - Training sub-loss: O 1.1291911602020264, C 1.1104536056518555, E 1.1094775199890137, A 1.0949829816818237, N 1.1125352382659912
06/19/2024 01:53:27 - INFO - modeling_roberta - Training sub-loss: O 1.1092138290405273, C 1.122063398361206, E 1.0973198413848877, A 1.1236217021942139, N 1.0971057415008545
06/19/2024 01:53:27 - INFO - modeling_roberta - Training sub-loss: O 1.0822021961212158, C 1.07878839969635, E 1.1211178302764893, A 1.086835265159607, N 1.0995937585830688
06/19/2024 01:53:28 - ERROR - root - 100%|#########9| 389/390 [21:23<00:03,  3.29s/it]
06/19/2024 01:53:29 - INFO - modeling_roberta - Training sub-loss: O 1.1189758777618408, C 1.1303627490997314, E 1.0770421028137207, A 1.0982635021209717, N 1.0823607444763184
06/19/2024 01:53:29 - INFO - modeling_roberta - Training sub-loss: O 1.1312698125839233, C 1.1093071699142456, E 1.0829832553863525, A 1.0815529823303223, N 1.1427907943725586
06/19/2024 01:53:32 - INFO - modeling_roberta - Training sub-loss: O 1.0573136806488037, C 1.0905841588974, E 1.0757670402526855, A 1.0776405334472656, N 1.102599859237671
06/19/2024 01:53:32 - INFO - modeling_roberta - Training sub-loss: O 1.0866693258285522, C 1.1123318672180176, E 1.0897750854492188, A 1.094536542892456, N 1.1107478141784668
06/19/2024 01:53:33 - ERROR - root - 100%|##########| 390/390 [21:28<00:00,  3.80s/it]
06/19/2024 01:53:33 - INFO - root - {'loss': 1.1003, 'grad_norm': 54129.375, 'learning_rate': 0.0, 'epoch': 4.97}
06/19/2024 01:53:33 - ERROR - root - 100%|##########| 390/390 [21:28<00:00,  3.80s/it]
06/19/2024 01:53:34 - INFO - root - {'train_runtime': 1289.5594, 'train_samples_per_second': 19.386, 'train_steps_per_second': 0.302, 'train_loss': 1.1065528845175718, 'epoch': 4.97}
06/19/2024 01:53:34 - ERROR - root - 100%|##########| 390/390 [21:29<00:00,  3.80s/it]
06/19/2024 01:53:34 - ERROR - root - 100%|##########| 390/390 [21:29<00:00,  3.31s/it]
