{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from models.question_generation import *\n",
    "from prompts.prompt_template import QuestionTemplate\n",
    "from data_processing.preprocess import KaggleDataset\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "args = SimpleNamespace(\n",
    "    api_key = 'sk-',\n",
    "    api_base='http://babel-1-23:5050/v1',\n",
    "    model='llama2-70b-chat',\n",
    "    chat_mode = False,\n",
    "    max_tokens = 256,\n",
    "    model_kwargs = {\"stop\": [\"<\\s>\"]},\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# openai.api_key = args.api_key\n",
    "# openai.api_base = args.api_base\n",
    "QGtemplate = QuestionTemplate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: \u001b[1mVLLMOpenAI\u001b[0m\n",
      "Params: {'model_name': '/data/datasets/models/huggingface/meta-llama/Llama-2-70b-chat-hf/', 'temperature': 0.0, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'logit_bias': {}, 'max_tokens': 256, 'stop': ['<\\\\s>']}\n"
     ]
    }
   ],
   "source": [
    "generator = QuestionGeneration(args, system_prompt=QGtemplate.system_prompt, user_prompts=QGtemplate.user_prompts, ai_prompts=QGtemplate.ai_prompts, json_message=QGtemplate.json_message ,response_schemas = QGtemplate.response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.invoke_agent(\"I dreamed a lot of weird stuff but generally my dream always sent me back to school for some reason to meet someone I haven't met in a long while. Previously I dreamed of flying in a machine...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "dataset = KaggleDataset()\n",
    "print(len(dataset.poster_data))\n",
    "# with open('/home/zw3/ANLP_Final/data/kaggleWithQuestion.csv', 'w', newline='') as file:\n",
    "#     writer = csv.writer(file, delimiter='\\t')\n",
    "\n",
    "#     # Write CSV Header\n",
    "#     writer.writerow(['posts', 'questions', 'label0', 'label1', 'label2', 'label3'])\n",
    "#     for row in tqdm(dataset.poster_data):\n",
    "#         questions = []\n",
    "#         for post in row['posts']:\n",
    "#             try:\n",
    "#                 question = generator.invoke_agent(post)\n",
    "#                 questions.append(question['question'])\n",
    "#             except:\n",
    "#                 questions.append(\"N/A\")\n",
    "#             print(questions[-1])\n",
    "#         row['questions'] = questions\n",
    "#         print(row['posts'])\n",
    "#         print(row['questions'])\n",
    "#         writer.writerow(['|||'.join(row['posts']), '|||'.join(row['questions']), row['label0'], row['label1'], row['label2'], row['label3']])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Question Generation\n",
    "  - Question Post Pair * 50\n",
    "\n",
    "- Llama2 History (User AI) \n",
    "  - Question: Your personality is ?\n",
    "\n",
    "- Q -> embedding -> (Q, vector)\n",
    "  - select from 50. \n",
    "# Q/(P) 50, Question of Personality/ Q, max_tokens\n",
    "50 embedding Q -> cos\n",
    "\"MBTI\"\n",
    "\n",
    "# GPT3.5 + embedding\n",
    "\n",
    "- Questionaire: Question **Answer**\n",
    "- 模仿 Ablation\n",
    "Answer Classify "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
