{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llama3_70b_dpo_results.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['llama3_70b_a_low', 'llama3_70b_o_low', 'llama3_70b_n_high', 'llama3_70b_o_high', 'llama3_70b_c_high', 'llama3_70b_n_low', 'llama3_70b_c_low', 'llama3_70b_a_high', 'llama3_70b_e_high', 'llama3_70b_e_low'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"llama3_70b_a_low\": {\"truthfulqa\": 0.5058314086539912, \"gpqa_main_zeroshot\": 0.35714285714285715, \"gpqa_main_n_shot\": 0.32142857142857145, \"social_iqa\": 0.39048106448311154, \"commonsense_qa\": 0.3923013923013923, \"gsm8k\": 0.8999241849886277, \"mathqa\": 0.32763819095477387, \"mmlu\": 0.6251958410482837, \"piqa\": 0.7404787812840044}\n",
      "\"llama3_70b_o_low\": {\"truthfulqa\": 0.5421157034230984, \"gpqa_main_zeroshot\": 0.31919642857142855, \"gpqa_main_n_shot\": 0.3125, \"social_iqa\": 0.44472876151484136, \"commonsense_qa\": 0.6592956592956593, \"gsm8k\": 0.8847611827141774, \"mathqa\": 0.34706867671691793, \"mmlu\": 0.6437117219769264, \"piqa\": 0.7676822633297062}\n",
      "\"llama3_70b_n_high\": {\"truthfulqa\": 0.4304264387243563, \"gpqa_main_zeroshot\": 0.32589285714285715, \"gpqa_main_n_shot\": 0.36607142857142855, \"social_iqa\": 0.39969293756397134, \"commonsense_qa\": 0.20065520065520065, \"gsm8k\": 0.1516300227445034, \"mathqa\": 0.2887772194304858, \"mmlu\": 0.33186155818259505, \"piqa\": 0.7285092491838956}\n",
      "\"llama3_70b_o_high\": {\"truthfulqa\": 0.5463692530636998, \"gpqa_main_zeroshot\": 0.36830357142857145, \"gpqa_main_n_shot\": 0.375, \"social_iqa\": 0.41453428863868985, \"commonsense_qa\": 0.5765765765765766, \"gsm8k\": 0.8786959818043972, \"mathqa\": 0.33936348408710215, \"mmlu\": 0.5789061387266771, \"piqa\": 0.764417845484222}\n",
      "\"llama3_70b_c_high\": {\"truthfulqa\": 0.6464106843287672, \"gpqa_main_zeroshot\": 0.35714285714285715, \"gpqa_main_n_shot\": 0.359375, \"social_iqa\": 0.4467758444216991, \"commonsense_qa\": 0.2375102375102375, \"gsm8k\": 0.9021986353297953, \"mathqa\": 0.32897822445561137, \"mmlu\": 0.5032046716991881, \"piqa\": 0.79379760609358}\n",
      "\"llama3_70b_n_low\": {\"truthfulqa\": 0.6582290610101554, \"gpqa_main_zeroshot\": 0.34598214285714285, \"gpqa_main_n_shot\": 0.35714285714285715, \"social_iqa\": 0.4534288638689867, \"commonsense_qa\": 0.44553644553644556, \"gsm8k\": 0.9097801364670205, \"mathqa\": 0.34003350083752093, \"mmlu\": 0.6913545079048569, \"piqa\": 0.795429815016322}\n",
      "\"llama3_70b_c_low\": {\"truthfulqa\": 0.38507280756049417, \"gpqa_main_zeroshot\": 0.30580357142857145, \"gpqa_main_n_shot\": 0.3125, \"social_iqa\": 0.37615148413510746, \"commonsense_qa\": 0.257985257985258, \"gsm8k\": 0.8059135708870356, \"mathqa\": 0.2814070351758794, \"mmlu\": 0.3378436120210796, \"piqa\": 0.7094668117519043}\n",
      "\"llama3_70b_a_high\": {\"truthfulqa\": 0.5961727803056094, \"gpqa_main_zeroshot\": 0.3549107142857143, \"gpqa_main_n_shot\": 0.33482142857142855, \"social_iqa\": 0.44779938587512796, \"commonsense_qa\": 0.21294021294021295, \"gsm8k\": 0.8733889310083397, \"mathqa\": 0.3132328308207705, \"mmlu\": 0.34346959122632104, \"piqa\": 0.7850924918389554}\n",
      "\"llama3_70b_e_high\": {\"truthfulqa\": 0.46042942351359656, \"gpqa_main_zeroshot\": 0.359375, \"gpqa_main_n_shot\": 0.3705357142857143, \"social_iqa\": 0.43039918116683723, \"commonsense_qa\": 0.23177723177723178, \"gsm8k\": 0.8893100833965125, \"mathqa\": 0.3051926298157454, \"mmlu\": 0.42273180458624127, \"piqa\": 0.764417845484222}\n",
      "\"llama3_70b_e_low\": {\"truthfulqa\": 0.6528340114952984, \"gpqa_main_zeroshot\": 0.359375, \"gpqa_main_n_shot\": 0.3549107142857143, \"social_iqa\": 0.43551688843398156, \"commonsense_qa\": 0.7084357084357085, \"gsm8k\": 0.9044730856709629, \"mathqa\": 0.3504187604690117, \"mmlu\": 0.7230451502634953, \"piqa\": 0.7976060935799782}\n"
     ]
    }
   ],
   "source": [
    "def extract_metrics(data, metrics):\n",
    "    results = {}\n",
    "    for model in data:\n",
    "        results[model] = {}\n",
    "        for metric, specific_metric in metrics.items():\n",
    "            for test_suite in data[model]:\n",
    "                if metric in test_suite:\n",
    "                    if metric == \"truthfulqa\":\n",
    "                        value = data[model][test_suite][\"truthfulqa_mc2\"][\"acc,none\"]\n",
    "                    elif metric == \"gsm8k\":\n",
    "                        value = data[model][test_suite][\"gsm8k\"][\"exact_match,flexible-extract\"]\n",
    "                    else:\n",
    "                        value = data[model][test_suite][metric][specific_metric]\n",
    "                    results[model][metric] = value\n",
    "                    break\n",
    "    return results\n",
    "\n",
    "metrics = {\n",
    "    \"truthfulqa\": \"truthfulqa_mc2\", \n",
    "    \"gpqa_main_zeroshot\": \"acc,none\", \n",
    "    \"gpqa_main_n_shot\": \"acc,none\", \n",
    "    \"social_iqa\": \"acc,none\", \n",
    "    \"commonsense_qa\": \"acc,none\", \n",
    "    \"gsm8k\": \"exact_match,flexible-extract\", \n",
    "    \"mathqa\": \"acc,none\",\n",
    "    \"mmlu\": \"acc,none\",\n",
    "    \"piqa\": \"acc,none\",\n",
    "}\n",
    "\n",
    "results = extract_metrics(data, metrics)\n",
    "\n",
    "# 打印结果\n",
    "for model, model_results in results.items():\n",
    "    print(f'\"{model}\": {json.dumps(model_results)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"llama3_70b_a_low\": {\"truthfulqa\": {\"value\": 0.5058314086539912, \"stderr\": 0.016427216245233724}, \"gpqa_main_zeroshot\": {\"value\": 0.35714285714285715, \"stderr\": 0.02266336846322688}, \"gpqa_main_n_shot\": {\"value\": 0.32142857142857145, \"stderr\": 0.022089519157170157}, \"social_iqa\": {\"value\": 0.39048106448311154, \"stderr\": 0.01103932371486307}, \"commonsense_qa\": {\"value\": 0.3923013923013923, \"stderr\": 0.01397893643494679}, \"gsm8k\": {\"value\": 0.8999241849886277, \"stderr\": 0.008266274528685637}, \"mathqa\": {\"value\": 0.32763819095477387, \"stderr\": 0.008592100906266604}, \"mmlu\": {\"value\": 0.6251958410482837, \"stderr\": 0.00392094851749934}}\n",
      "\"llama3_70b_o_low\": {\"truthfulqa\": {\"value\": 0.5421157034230984, \"stderr\": 0.016755339076097026}, \"gpqa_main_zeroshot\": {\"value\": 0.31919642857142855, \"stderr\": 0.022048861164576057}, \"gpqa_main_n_shot\": {\"value\": 0.3125, \"stderr\": 0.021923384489444957}, \"social_iqa\": {\"value\": 0.44472876151484136, \"stderr\": 0.011244731148193177}, \"commonsense_qa\": {\"value\": 0.6592956592956593, \"stderr\": 0.013569036984855006}, \"gsm8k\": {\"value\": 0.8847611827141774, \"stderr\": 0.00879538230154542}, \"mathqa\": {\"value\": 0.34706867671691793, \"stderr\": 0.00871449153541417}, \"mmlu\": {\"value\": 0.6437117219769264, \"stderr\": 0.0038392275190125944}}\n",
      "\"llama3_70b_n_high\": {\"truthfulqa\": {\"value\": 0.4304264387243563, \"stderr\": 0.016580910277876004}, \"gpqa_main_zeroshot\": {\"value\": 0.32589285714285715, \"stderr\": 0.022169103134643414}, \"gpqa_main_n_shot\": {\"value\": 0.36607142857142855, \"stderr\": 0.02278501498199051}, \"social_iqa\": {\"value\": 0.39969293756397134, \"stderr\": 0.011084059334882369}, \"commonsense_qa\": {\"value\": 0.20065520065520065, \"stderr\": 0.011466011466011533}, \"gsm8k\": {\"value\": 0.1516300227445034, \"stderr\": 0.009879331091354297}, \"mathqa\": {\"value\": 0.2887772194304858, \"stderr\": 0.008296308349383155}, \"mmlu\": {\"value\": 0.33186155818259505, \"stderr\": 0.003918672275666112}}\n",
      "\"llama3_70b_o_high\": {\"truthfulqa\": {\"value\": 0.5463692530636998, \"stderr\": 0.01648277570651695}, \"gpqa_main_zeroshot\": {\"value\": 0.36830357142857145, \"stderr\": 0.02281410385929623}, \"gpqa_main_n_shot\": {\"value\": 0.375, \"stderr\": 0.02289822829522849}, \"social_iqa\": {\"value\": 0.41453428863868985, \"stderr\": 0.01114756056703673}, \"commonsense_qa\": {\"value\": 0.5765765765765766, \"stderr\": 0.014146077134489551}, \"gsm8k\": {\"value\": 0.8786959818043972, \"stderr\": 0.00899288849727559}, \"mathqa\": {\"value\": 0.33936348408710215, \"stderr\": 0.008667910793954913}, \"mmlu\": {\"value\": 0.5789061387266771, \"stderr\": 0.004013950469431933}}\n",
      "\"llama3_70b_c_high\": {\"truthfulqa\": {\"value\": 0.6464106843287672, \"stderr\": 0.016135148130813463}, \"gpqa_main_zeroshot\": {\"value\": 0.35714285714285715, \"stderr\": 0.02266336846322688}, \"gpqa_main_n_shot\": {\"value\": 0.359375, \"stderr\": 0.022694577961439925}, \"social_iqa\": {\"value\": 0.4467758444216991, \"stderr\": 0.011249786691110377}, \"commonsense_qa\": {\"value\": 0.2375102375102375, \"stderr\": 0.012183673723473452}, \"gsm8k\": {\"value\": 0.9021986353297953, \"stderr\": 0.008182119821849056}, \"mathqa\": {\"value\": 0.32897822445561137, \"stderr\": 0.008601069831238388}, \"mmlu\": {\"value\": 0.5032046716991881, \"stderr\": 0.004034416971227507}}\n",
      "\"llama3_70b_n_low\": {\"truthfulqa\": {\"value\": 0.6582290610101554, \"stderr\": 0.015965345604524485}, \"gpqa_main_zeroshot\": {\"value\": 0.34598214285714285, \"stderr\": 0.02249924183068251}, \"gpqa_main_n_shot\": {\"value\": 0.35714285714285715, \"stderr\": 0.02266336846322688}, \"social_iqa\": {\"value\": 0.4534288638689867, \"stderr\": 0.011264886135301386}, \"commonsense_qa\": {\"value\": 0.44553644553644556, \"stderr\": 0.014229780629024427}, \"gsm8k\": {\"value\": 0.9097801364670205, \"stderr\": 0.007891537108449958}, \"mathqa\": {\"value\": 0.34003350083752093, \"stderr\": 0.008672062303343067}, \"mmlu\": {\"value\": 0.6913545079048569, \"stderr\": 0.003678671513586357}}\n",
      "\"llama3_70b_c_low\": {\"truthfulqa\": {\"value\": 0.38507280756049417, \"stderr\": 0.015975820931627572}, \"gpqa_main_zeroshot\": {\"value\": 0.30580357142857145, \"stderr\": 0.021792582688756987}, \"gpqa_main_n_shot\": {\"value\": 0.3125, \"stderr\": 0.021923384489444957}, \"social_iqa\": {\"value\": 0.37615148413510746, \"stderr\": 0.010961496293030143}, \"commonsense_qa\": {\"value\": 0.257985257985258, \"stderr\": 0.012526328490375856}, \"gsm8k\": {\"value\": 0.8059135708870356, \"stderr\": 0.010893918308192413}, \"mathqa\": {\"value\": 0.2814070351758794, \"stderr\": 0.008232079320325311}, \"mmlu\": {\"value\": 0.3378436120210796, \"stderr\": 0.0039556005989972425}}\n",
      "\"llama3_70b_a_high\": {\"truthfulqa\": {\"value\": 0.5961727803056094, \"stderr\": 0.016334354466768022}, \"gpqa_main_zeroshot\": {\"value\": 0.3549107142857143, \"stderr\": 0.02263162341632674}, \"gpqa_main_n_shot\": {\"value\": 0.33482142857142855, \"stderr\": 0.022321428571428627}, \"social_iqa\": {\"value\": 0.44779938587512796, \"stderr\": 0.011252242102001767}, \"commonsense_qa\": {\"value\": 0.21294021294021295, \"stderr\": 0.011720679449797579}, \"gsm8k\": {\"value\": 0.8733889310083397, \"stderr\": 0.009159715283081092}, \"mathqa\": {\"value\": 0.3132328308207705, \"stderr\": 0.008490611920810433}, \"mmlu\": {\"value\": 0.34346959122632104, \"stderr\": 0.0038651700998585496}}\n",
      "\"llama3_70b_e_high\": {\"truthfulqa\": {\"value\": 0.46042942351359656, \"stderr\": 0.01653885248336244}, \"gpqa_main_zeroshot\": {\"value\": 0.359375, \"stderr\": 0.022694577961439925}, \"gpqa_main_n_shot\": {\"value\": 0.3705357142857143, \"stderr\": 0.0228426677334829}, \"social_iqa\": {\"value\": 0.43039918116683723, \"stderr\": 0.011203917417496392}, \"commonsense_qa\": {\"value\": 0.23177723177723178, \"stderr\": 0.012080893552302283}, \"gsm8k\": {\"value\": 0.8893100833965125, \"stderr\": 0.008642172551392473}, \"mathqa\": {\"value\": 0.3051926298157454, \"stderr\": 0.008429849471087473}, \"mmlu\": {\"value\": 0.42273180458624127, \"stderr\": 0.0040785828773805795}}\n",
      "\"llama3_70b_e_low\": {\"truthfulqa\": {\"value\": 0.6528340114952984, \"stderr\": 0.01595351060013572}, \"gpqa_main_zeroshot\": {\"value\": 0.359375, \"stderr\": 0.022694577961439925}, \"gpqa_main_n_shot\": {\"value\": 0.3549107142857143, \"stderr\": 0.022631623416326744}, \"social_iqa\": {\"value\": 0.43551688843398156, \"stderr\": 0.011219586604022594}, \"commonsense_qa\": {\"value\": 0.7084357084357085, \"stderr\": 0.013011802821401595}, \"gsm8k\": {\"value\": 0.9044730856709629, \"stderr\": 0.00809660577115574}, \"mathqa\": {\"value\": 0.3504187604690117, \"stderr\": 0.008733956045067806}, \"mmlu\": {\"value\": 0.7230451502634953, \"stderr\": 0.0035789783761124203}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def extract_metrics_with_stderr(data, metrics):\n",
    "    results = {}\n",
    "    for model in data:\n",
    "        results[model] = {}\n",
    "        for metric, specific_metric in metrics.items():\n",
    "            for test_suite in data[model]:\n",
    "                if metric in test_suite:\n",
    "                    if metric == \"truthfulqa\":\n",
    "                        value = data[model][test_suite][\"truthfulqa_mc2\"][\"acc,none\"]\n",
    "                        stderr = data[model][test_suite][\"truthfulqa_mc2\"].get(\"acc_stderr,none\", None)\n",
    "                    elif metric == \"gsm8k\":\n",
    "                        value = data[model][test_suite][\"gsm8k\"][\"exact_match,flexible-extract\"]\n",
    "                        stderr = data[model][test_suite][\"gsm8k\"].get(\"exact_match_stderr,flexible-extract\", None)\n",
    "                    else:\n",
    "                        value = data[model][test_suite][metric][specific_metric]\n",
    "                        stderr = data[model][test_suite][metric].get(specific_metric.replace(\"acc,\", \"acc_stderr,\"), None)\n",
    "                    results[model][metric] = (value, stderr)\n",
    "                    break\n",
    "    return results\n",
    "\n",
    "metrics = {\n",
    "    \"truthfulqa\": \"truthfulqa_mc2\", \n",
    "    \"gpqa_main_zeroshot\": \"acc,none\", \n",
    "    \"gpqa_main_n_shot\": \"acc,none\", \n",
    "    \"social_iqa\": \"acc,none\", \n",
    "    \"commonsense_qa\": \"acc,none\", \n",
    "    \"gsm8k\": \"exact_match,flexible-extract\", \n",
    "    \"mathqa\": \"acc,none\",\n",
    "    \"mmlu\": \"acc,none\"\n",
    "}\n",
    "\n",
    "results = extract_metrics_with_stderr(data, metrics)\n",
    "\n",
    "# 打印结果\n",
    "for model, model_results in results.items():\n",
    "    formatted_results = {k: {\"value\": v[0], \"stderr\": v[1]} for k, v in model_results.items()}\n",
    "    print(f'\"{model}\": {json.dumps(formatted_results)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'truthfulqa': (0.6528340114952984, 0.01595351060013572),\n",
       " 'gpqa_main_zeroshot': (0.359375, 0.022694577961439925),\n",
       " 'gpqa_main_n_shot': (0.3549107142857143, 0.022631623416326744),\n",
       " 'social_iqa': (0.43551688843398156, 0.011219586604022594),\n",
       " 'commonsense_qa': (0.7084357084357085, 0.013011802821401595),\n",
       " 'gsm8k': (0.9044730856709629, 0.00809660577115574),\n",
       " 'mathqa': (0.3504187604690117, 0.008733956045067806),\n",
       " 'mmlu': (0.7230451502634953, 0.0035789783761124203)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llama3_70b_a_low': {'truthfulqa': (0.5058314086539912, 0.016427216245233724),\n",
       "  'gpqa_main_zeroshot': (0.35714285714285715, 0.02266336846322688),\n",
       "  'gpqa_main_n_shot': (0.32142857142857145, 0.022089519157170157),\n",
       "  'social_iqa': (0.39048106448311154, 0.01103932371486307),\n",
       "  'commonsense_qa': (0.3923013923013923, 0.01397893643494679),\n",
       "  'gsm8k': (0.8999241849886277, 0.008266274528685637),\n",
       "  'mathqa': (0.32763819095477387, 0.008592100906266604),\n",
       "  'mmlu': (0.6251958410482837, 0.00392094851749934)},\n",
       " 'llama3_70b_o_low': {'truthfulqa': (0.5421157034230984, 0.016755339076097026),\n",
       "  'gpqa_main_zeroshot': (0.31919642857142855, 0.022048861164576057),\n",
       "  'gpqa_main_n_shot': (0.3125, 0.021923384489444957),\n",
       "  'social_iqa': (0.44472876151484136, 0.011244731148193177),\n",
       "  'commonsense_qa': (0.6592956592956593, 0.013569036984855006),\n",
       "  'gsm8k': (0.8847611827141774, 0.00879538230154542),\n",
       "  'mathqa': (0.34706867671691793, 0.00871449153541417),\n",
       "  'mmlu': (0.6437117219769264, 0.0038392275190125944)},\n",
       " 'llama3_70b_n_high': {'truthfulqa': (0.4304264387243563,\n",
       "   0.016580910277876004),\n",
       "  'gpqa_main_zeroshot': (0.32589285714285715, 0.022169103134643414),\n",
       "  'gpqa_main_n_shot': (0.36607142857142855, 0.02278501498199051),\n",
       "  'social_iqa': (0.39969293756397134, 0.011084059334882369),\n",
       "  'commonsense_qa': (0.20065520065520065, 0.011466011466011533),\n",
       "  'gsm8k': (0.1516300227445034, 0.009879331091354297),\n",
       "  'mathqa': (0.2887772194304858, 0.008296308349383155),\n",
       "  'mmlu': (0.33186155818259505, 0.003918672275666112)},\n",
       " 'llama3_70b_o_high': {'truthfulqa': (0.5463692530636998, 0.01648277570651695),\n",
       "  'gpqa_main_zeroshot': (0.36830357142857145, 0.02281410385929623),\n",
       "  'gpqa_main_n_shot': (0.375, 0.02289822829522849),\n",
       "  'social_iqa': (0.41453428863868985, 0.01114756056703673),\n",
       "  'commonsense_qa': (0.5765765765765766, 0.014146077134489551),\n",
       "  'gsm8k': (0.8786959818043972, 0.00899288849727559),\n",
       "  'mathqa': (0.33936348408710215, 0.008667910793954913),\n",
       "  'mmlu': (0.5789061387266771, 0.004013950469431933)},\n",
       " 'llama3_70b_c_high': {'truthfulqa': (0.6464106843287672,\n",
       "   0.016135148130813463),\n",
       "  'gpqa_main_zeroshot': (0.35714285714285715, 0.02266336846322688),\n",
       "  'gpqa_main_n_shot': (0.359375, 0.022694577961439925),\n",
       "  'social_iqa': (0.4467758444216991, 0.011249786691110377),\n",
       "  'commonsense_qa': (0.2375102375102375, 0.012183673723473452),\n",
       "  'gsm8k': (0.9021986353297953, 0.008182119821849056),\n",
       "  'mathqa': (0.32897822445561137, 0.008601069831238388),\n",
       "  'mmlu': (0.5032046716991881, 0.004034416971227507)},\n",
       " 'llama3_70b_n_low': {'truthfulqa': (0.6582290610101554, 0.015965345604524485),\n",
       "  'gpqa_main_zeroshot': (0.34598214285714285, 0.02249924183068251),\n",
       "  'gpqa_main_n_shot': (0.35714285714285715, 0.02266336846322688),\n",
       "  'social_iqa': (0.4534288638689867, 0.011264886135301386),\n",
       "  'commonsense_qa': (0.44553644553644556, 0.014229780629024427),\n",
       "  'gsm8k': (0.9097801364670205, 0.007891537108449958),\n",
       "  'mathqa': (0.34003350083752093, 0.008672062303343067),\n",
       "  'mmlu': (0.6913545079048569, 0.003678671513586357)},\n",
       " 'llama3_70b_c_low': {'truthfulqa': (0.38507280756049417,\n",
       "   0.015975820931627572),\n",
       "  'gpqa_main_zeroshot': (0.30580357142857145, 0.021792582688756987),\n",
       "  'gpqa_main_n_shot': (0.3125, 0.021923384489444957),\n",
       "  'social_iqa': (0.37615148413510746, 0.010961496293030143),\n",
       "  'commonsense_qa': (0.257985257985258, 0.012526328490375856),\n",
       "  'gsm8k': (0.8059135708870356, 0.010893918308192413),\n",
       "  'mathqa': (0.2814070351758794, 0.008232079320325311),\n",
       "  'mmlu': (0.3378436120210796, 0.0039556005989972425)},\n",
       " 'llama3_70b_a_high': {'truthfulqa': (0.5961727803056094,\n",
       "   0.016334354466768022),\n",
       "  'gpqa_main_zeroshot': (0.3549107142857143, 0.02263162341632674),\n",
       "  'gpqa_main_n_shot': (0.33482142857142855, 0.022321428571428627),\n",
       "  'social_iqa': (0.44779938587512796, 0.011252242102001767),\n",
       "  'commonsense_qa': (0.21294021294021295, 0.011720679449797579),\n",
       "  'gsm8k': (0.8733889310083397, 0.009159715283081092),\n",
       "  'mathqa': (0.3132328308207705, 0.008490611920810433),\n",
       "  'mmlu': (0.34346959122632104, 0.0038651700998585496)},\n",
       " 'llama3_70b_e_high': {'truthfulqa': (0.46042942351359656,\n",
       "   0.01653885248336244),\n",
       "  'gpqa_main_zeroshot': (0.359375, 0.022694577961439925),\n",
       "  'gpqa_main_n_shot': (0.3705357142857143, 0.0228426677334829),\n",
       "  'social_iqa': (0.43039918116683723, 0.011203917417496392),\n",
       "  'commonsense_qa': (0.23177723177723178, 0.012080893552302283),\n",
       "  'gsm8k': (0.8893100833965125, 0.008642172551392473),\n",
       "  'mathqa': (0.3051926298157454, 0.008429849471087473),\n",
       "  'mmlu': (0.42273180458624127, 0.0040785828773805795)},\n",
       " 'llama3_70b_e_low': {'truthfulqa': (0.6528340114952984, 0.01595351060013572),\n",
       "  'gpqa_main_zeroshot': (0.359375, 0.022694577961439925),\n",
       "  'gpqa_main_n_shot': (0.3549107142857143, 0.022631623416326744),\n",
       "  'social_iqa': (0.43551688843398156, 0.011219586604022594),\n",
       "  'commonsense_qa': (0.7084357084357085, 0.013011802821401595),\n",
       "  'gsm8k': (0.9044730856709629, 0.00809660577115574),\n",
       "  'mathqa': (0.3504187604690117, 0.008733956045067806),\n",
       "  'mmlu': (0.7230451502634953, 0.0035789783761124203)}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "\n",
    "def format_value(value, error):\n",
    "    return f\"{(value * 100):.1f} $\\\\pm$ {(error * 100):.1f}\"\n",
    "\n",
    "def get_benchmark_name(key):\n",
    "    benchmark_map = {\n",
    "        'truthfulqa': 'TruthfulQA',\n",
    "        'gpqa_main_zeroshot': 'GPQA Zero Shot',\n",
    "        'gpqa_main_n_shot': 'GPQA N Shot',\n",
    "        'social_iqa': 'SocialIQA',\n",
    "        'commonsense_qa': 'CommonsenseQA',\n",
    "        'gsm8k': 'GSM8K',\n",
    "        'mathqa': 'MathQA',\n",
    "        'mmlu': 'MMLU'\n",
    "    }\n",
    "    return benchmark_map.get(key, key.capitalize())\n",
    "\n",
    "def generate_latex_table(data):\n",
    "    benchmarks = list(next(iter(data.values())).keys())\n",
    "    personalities = ['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism']\n",
    "    trait_abbr = {'o': 'Openness', 'c': 'Conscientiousness', 'e': 'Extraversion', 'a': 'Agreeableness', 'n': 'Neuroticism'}\n",
    "    \n",
    "    table = \"\\\\begin{table}[htbp]\\n\\\\centering\\n\\\\resizebox{\\\\textwidth}{!}{\\n\"\n",
    "    table += \"\\\\begin{tabular}{llc\" + \"cc\" * len(personalities) + \"c}\\n\"\n",
    "    table += \"\\\\toprule\\n\"\n",
    "    table += \"\\\\textbf{Benchmark} & \\\\textbf{Original} & \\\\textbf{Method} & \"\n",
    "    table += \" & \".join([f\"\\\\multicolumn{{2}}{{c}}{{\\\\textbf{{{p}}}}}\" for p in personalities])\n",
    "    table += \" & \\\\multicolumn{2}{c}{\\\\textbf{Average}} \\\\\\\\\\n\"\n",
    "    table += \" & & & \" + \"High & Low & \" * (len(personalities) + 1) + \"\\\\\\\\\\n\"\n",
    "    table += \"\\\\midrule\\n\"\n",
    "    \n",
    "    for benchmark in benchmarks:\n",
    "        row = f\"\\\\textbf{{{get_benchmark_name(benchmark)}}} & - & DPO & \"\n",
    "        for trait in personalities:\n",
    "            trait_abbr_key = trait[0].lower()\n",
    "            high_key = f\"llama3_70b_{trait_abbr_key}_high\"\n",
    "            low_key = f\"llama3_70b_{trait_abbr_key}_low\"\n",
    "            if high_key in data and low_key in data and benchmark in data[high_key] and benchmark in data[low_key]:\n",
    "                row += format_value(*data[high_key][benchmark]) + \" & \"\n",
    "                row += format_value(*data[low_key][benchmark]) + \" & \"\n",
    "            else:\n",
    "                row += \"- & - & \"\n",
    "        row += \"- & - \\\\\\\\\\n\"\n",
    "        table += row\n",
    "    \n",
    "    table += \"\\\\bottomrule\\n\"\n",
    "    table += \"\\\\end{tabular}\\n}\\n\"\n",
    "    table += \"\\\\caption{DPO Benchmark results for different personality traits on Llama3 70B.}\\n\"\n",
    "    table += \"\\\\label{tab:dpo_personality_results_llama3_70b}\\n\"\n",
    "    table += \"\\\\end{table}\"\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\resizebox{\\textwidth}{!}{\n",
      "\\begin{tabular}{llcccccccccccc}\n",
      "\\toprule\n",
      "\\textbf{Benchmark} & \\textbf{Original} & \\textbf{Method} & \\multicolumn{2}{c}{\\textbf{Openness}} & \\multicolumn{2}{c}{\\textbf{Conscientiousness}} & \\multicolumn{2}{c}{\\textbf{Extraversion}} & \\multicolumn{2}{c}{\\textbf{Agreeableness}} & \\multicolumn{2}{c}{\\textbf{Neuroticism}} & \\multicolumn{2}{c}{\\textbf{Average}} \\\\\n",
      " & & & High & Low & High & Low & High & Low & High & Low & High & Low & High & Low & \\\\\n",
      "\\midrule\n",
      "\\textbf{TruthfulQA} & - & DPO & 54.6 $\\pm$ 1.6 & 54.2 $\\pm$ 1.7 & 64.6 $\\pm$ 1.6 & 38.5 $\\pm$ 1.6 & 46.0 $\\pm$ 1.7 & 65.3 $\\pm$ 1.6 & 59.6 $\\pm$ 1.6 & 50.6 $\\pm$ 1.6 & 43.0 $\\pm$ 1.7 & 65.8 $\\pm$ 1.6 & - & - \\\\\n",
      "\\textbf{GPQA Zero Shot} & - & DPO & 36.8 $\\pm$ 2.3 & 31.9 $\\pm$ 2.2 & 35.7 $\\pm$ 2.3 & 30.6 $\\pm$ 2.2 & 35.9 $\\pm$ 2.3 & 35.9 $\\pm$ 2.3 & 35.5 $\\pm$ 2.3 & 35.7 $\\pm$ 2.3 & 32.6 $\\pm$ 2.2 & 34.6 $\\pm$ 2.2 & - & - \\\\\n",
      "\\textbf{GPQA N Shot} & - & DPO & 37.5 $\\pm$ 2.3 & 31.2 $\\pm$ 2.2 & 35.9 $\\pm$ 2.3 & 31.2 $\\pm$ 2.2 & 37.1 $\\pm$ 2.3 & 35.5 $\\pm$ 2.3 & 33.5 $\\pm$ 2.2 & 32.1 $\\pm$ 2.2 & 36.6 $\\pm$ 2.3 & 35.7 $\\pm$ 2.3 & - & - \\\\\n",
      "\\textbf{SocialIQA} & - & DPO & 41.5 $\\pm$ 1.1 & 44.5 $\\pm$ 1.1 & 44.7 $\\pm$ 1.1 & 37.6 $\\pm$ 1.1 & 43.0 $\\pm$ 1.1 & 43.6 $\\pm$ 1.1 & 44.8 $\\pm$ 1.1 & 39.0 $\\pm$ 1.1 & 40.0 $\\pm$ 1.1 & 45.3 $\\pm$ 1.1 & - & - \\\\\n",
      "\\textbf{CommonsenseQA} & - & DPO & 57.7 $\\pm$ 1.4 & 65.9 $\\pm$ 1.4 & 23.8 $\\pm$ 1.2 & 25.8 $\\pm$ 1.3 & 23.2 $\\pm$ 1.2 & 70.8 $\\pm$ 1.3 & 21.3 $\\pm$ 1.2 & 39.2 $\\pm$ 1.4 & 20.1 $\\pm$ 1.1 & 44.6 $\\pm$ 1.4 & - & - \\\\\n",
      "\\textbf{GSM8K} & - & DPO & 87.9 $\\pm$ 0.9 & 88.5 $\\pm$ 0.9 & 90.2 $\\pm$ 0.8 & 80.6 $\\pm$ 1.1 & 88.9 $\\pm$ 0.9 & 90.4 $\\pm$ 0.8 & 87.3 $\\pm$ 0.9 & 90.0 $\\pm$ 0.8 & 15.2 $\\pm$ 1.0 & 91.0 $\\pm$ 0.8 & - & - \\\\\n",
      "\\textbf{MathQA} & - & DPO & 33.9 $\\pm$ 0.9 & 34.7 $\\pm$ 0.9 & 32.9 $\\pm$ 0.9 & 28.1 $\\pm$ 0.8 & 30.5 $\\pm$ 0.8 & 35.0 $\\pm$ 0.9 & 31.3 $\\pm$ 0.8 & 32.8 $\\pm$ 0.9 & 28.9 $\\pm$ 0.8 & 34.0 $\\pm$ 0.9 & - & - \\\\\n",
      "\\textbf{MMLU} & - & DPO & 57.9 $\\pm$ 0.4 & 64.4 $\\pm$ 0.4 & 50.3 $\\pm$ 0.4 & 33.8 $\\pm$ 0.4 & 42.3 $\\pm$ 0.4 & 72.3 $\\pm$ 0.4 & 34.3 $\\pm$ 0.4 & 62.5 $\\pm$ 0.4 & 33.2 $\\pm$ 0.4 & 69.1 $\\pm$ 0.4 & - & - \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\caption{DPO Benchmark results for different personality traits on Llama3 70B.}\n",
      "\\label{tab:dpo_personality_results_llama3_70b}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(generate_latex_table(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{llcccccccccccc}\n",
      "\\toprule\n",
      "\\multirow[c]{2}{*}{\\textbf{Benchmark}} & \\multirow[c]{2}{*}{\\textbf{Original}} & \\multirow[c]{2}{*}{\\textbf{Method}} & \\multicolumn{2}{c}{\\textbf{Openness}} & \\multicolumn{2}{c}{\\textbf{Conscientiousness}} & \\multicolumn{2}{c}{\\textbf{Extraversion}} & \\multicolumn{2}{c}{\\textbf{Agreeableness}} & \\multicolumn{2}{c}{\\textbf{Neuroticism}} & \\multicolumn{2}{c}{\\textbf{Average}} \\\\\n",
      " & & & High & Low & High & Low & High & Low & High & Low & High & Low & \\textbf{High} & \\textbf{Low} \\\\\n",
      "\\midrule\n",
      "\\multirow[c]{3}{*}{\\textbf{TruthfulQA}}\n",
      " & \\multirow[c]{3}{*}{-} & Prompt &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      " & & SFT & 55.2 $\\pm$ 1.6 & 52.8 $\\pm$ 1.6 & 55.6 $\\pm$ 1.6 & 50.8 $\\pm$ 1.5 & 54.5 $\\pm$ 1.6 & 56.7 $\\pm$ 1.6 & 54.4 $\\pm$ 1.6 & 51.6 $\\pm$ 1.6 & 52.4 $\\pm$ 1.5 & 56.7 $\\pm$ 1.6 & - & - \\\\\n",
      " & & DPO & 54.6 $\\pm$ 1.6 & 54.2 $\\pm$ 1.7 & 64.6 $\\pm$ 1.6 & 38.5 $\\pm$ 1.6 & 46.0 $\\pm$ 1.7 & 65.3 $\\pm$ 1.6 & 59.6 $\\pm$ 1.6 & 50.6 $\\pm$ 1.6 & 43.0 $\\pm$ 1.7 & 65.8 $\\pm$ 1.6 & - & - \\\\\n",
      "\\midrule\n",
      "\\multirow[c]{3}{*}{\\textbf{GPQA Zero Shot}}\n",
      " & \\multirow[c]{3}{*}{-} & Prompt &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      " & & SFT & 33.5 $\\pm$ 2.2 & 32.4 $\\pm$ 2.2 & 34.2 $\\pm$ 2.2 & 34.2 $\\pm$ 2.2 & 33.3 $\\pm$ 2.2 & 34.4 $\\pm$ 2.2 & 33.3 $\\pm$ 2.2 & 33.3 $\\pm$ 2.2 & 34.4 $\\pm$ 2.2 & 33.5 $\\pm$ 2.2 & - & - \\\\\n",
      " & & DPO & 36.8 $\\pm$ 2.3 & 31.9 $\\pm$ 2.2 & 35.7 $\\pm$ 2.3 & 30.6 $\\pm$ 2.2 & 35.9 $\\pm$ 2.3 & 35.9 $\\pm$ 2.3 & 35.5 $\\pm$ 2.3 & 35.7 $\\pm$ 2.3 & 32.6 $\\pm$ 2.2 & 34.6 $\\pm$ 2.2 & - & - \\\\\n",
      "\\midrule\n",
      "\\multirow[c]{3}{*}{\\textbf{GPQA N Shot}}\n",
      " & \\multirow[c]{3}{*}{-} & Prompt &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      " & & SFT & 32.4 $\\pm$ 2.2 & 32.8 $\\pm$ 2.2 & 34.4 $\\pm$ 2.2 & 33.7 $\\pm$ 2.2 & 33.0 $\\pm$ 2.2 & 33.9 $\\pm$ 2.2 & 33.7 $\\pm$ 2.2 & 32.8 $\\pm$ 2.2 & 33.7 $\\pm$ 2.2 & 34.8 $\\pm$ 2.3 & - & - \\\\\n",
      " & & DPO & 37.5 $\\pm$ 2.3 & 31.2 $\\pm$ 2.2 & 35.9 $\\pm$ 2.3 & 31.2 $\\pm$ 2.2 & 37.1 $\\pm$ 2.3 & 35.5 $\\pm$ 2.3 & 33.5 $\\pm$ 2.2 & 32.1 $\\pm$ 2.2 & 36.6 $\\pm$ 2.3 & 35.7 $\\pm$ 2.3 & - & - \\\\\n",
      "\\midrule\n",
      "\\multirow[c]{3}{*}{\\textbf{SocialIQA}}\n",
      " & \\multirow[c]{3}{*}{-} & Prompt &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      " & & SFT & 50.3 $\\pm$ 1.1 & 50.4 $\\pm$ 1.1 & 50.9 $\\pm$ 1.1 & 46.8 $\\pm$ 1.1 & 50.0 $\\pm$ 1.1 & 50.3 $\\pm$ 1.1 & 50.5 $\\pm$ 1.1 & 46.6 $\\pm$ 1.1 & 48.2 $\\pm$ 1.1 & 50.6 $\\pm$ 1.1 & - & - \\\\\n",
      " & & DPO & 41.5 $\\pm$ 1.1 & 44.5 $\\pm$ 1.1 & 44.7 $\\pm$ 1.1 & 37.6 $\\pm$ 1.1 & 43.0 $\\pm$ 1.1 & 43.6 $\\pm$ 1.1 & 44.8 $\\pm$ 1.1 & 39.0 $\\pm$ 1.1 & 40.0 $\\pm$ 1.1 & 45.3 $\\pm$ 1.1 & - & - \\\\\n",
      "\\midrule\n",
      "\\multirow[c]{3}{*}{\\textbf{CommonsenseQA}}\n",
      " & \\multirow[c]{3}{*}{-} & Prompt &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      " & & SFT & 77.7 $\\pm$ 1.2 & 78.8 $\\pm$ 1.2 & 77.6 $\\pm$ 1.2 & 66.0 $\\pm$ 1.4 & 75.7 $\\pm$ 1.2 & 78.9 $\\pm$ 1.2 & 77.0 $\\pm$ 1.2 & 73.8 $\\pm$ 1.3 & 79.1 $\\pm$ 1.2 & 78.5 $\\pm$ 1.2 & - & - \\\\\n",
      " & & DPO & 57.7 $\\pm$ 1.4 & 65.9 $\\pm$ 1.4 & 23.8 $\\pm$ 1.2 & 25.8 $\\pm$ 1.3 & 23.2 $\\pm$ 1.2 & 70.8 $\\pm$ 1.3 & 21.3 $\\pm$ 1.2 & 39.2 $\\pm$ 1.4 & 20.1 $\\pm$ 1.1 & 44.6 $\\pm$ 1.4 & - & - \\\\\n",
      "\\midrule\n",
      "\\multirow[c]{3}{*}{\\textbf{GSM8K}}\n",
      " & \\multirow[c]{3}{*}{-} & Prompt &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      " & & SFT & 85.8 $\\pm$ 1.0 & 76.2 $\\pm$ 1.2 & 86.4 $\\pm$ 0.9 & 81.7 $\\pm$ 1.1 & 85.1 $\\pm$ 1.0 & 86.7 $\\pm$ 0.9 & 87.0 $\\pm$ 0.9 & 74.5 $\\pm$ 1.2 & 76.0 $\\pm$ 1.2 & 87.3 $\\pm$ 0.9 & - & - \\\\\n",
      " & & DPO & 87.9 $\\pm$ 0.9 & 88.5 $\\pm$ 0.9 & 90.2 $\\pm$ 0.8 & 80.6 $\\pm$ 1.1 & 88.9 $\\pm$ 0.9 & 90.4 $\\pm$ 0.8 & 87.3 $\\pm$ 0.9 & 90.0 $\\pm$ 0.8 & 15.2 $\\pm$ 1.0 & 91.0 $\\pm$ 0.8 & - & - \\\\\n",
      "\\midrule\n",
      "\\multirow[c]{3}{*}{\\textbf{MathQA}}\n",
      " & \\multirow[c]{3}{*}{-} & Prompt &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      " & & SFT & 43.3 $\\pm$ 0.9 & 42.6 $\\pm$ 0.9 & 43.0 $\\pm$ 0.9 & 43.3 $\\pm$ 0.9 & 43.2 $\\pm$ 0.9 & 42.7 $\\pm$ 0.9 & 42.9 $\\pm$ 0.9 & 42.9 $\\pm$ 0.9 & 42.8 $\\pm$ 0.9 & 43.3 $\\pm$ 0.9 & - & - \\\\\n",
      " & & DPO & 33.9 $\\pm$ 0.9 & 34.7 $\\pm$ 0.9 & 32.9 $\\pm$ 0.9 & 28.1 $\\pm$ 0.8 & 30.5 $\\pm$ 0.8 & 35.0 $\\pm$ 0.9 & 31.3 $\\pm$ 0.8 & 32.8 $\\pm$ 0.9 & 28.9 $\\pm$ 0.8 & 34.0 $\\pm$ 0.9 & - & - \\\\\n",
      "\\midrule\n",
      "\\multirow[c]{3}{*}{\\textbf{MMLU}}\n",
      " & \\multirow[c]{3}{*}{-} & Prompt &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      " & & SFT & 72.5 $\\pm$ 0.4 & 72.0 $\\pm$ 0.4 & 73.1 $\\pm$ 0.4 & 68.6 $\\pm$ 0.4 & 72.1 $\\pm$ 0.4 & 73.5 $\\pm$ 0.4 & 72.8 $\\pm$ 0.4 & 70.7 $\\pm$ 0.4 & 72.5 $\\pm$ 0.4 & 73.8 $\\pm$ 0.4 & - & - \\\\\n",
      " & & DPO & 57.9 $\\pm$ 0.4 & 64.4 $\\pm$ 0.4 & 50.3 $\\pm$ 0.4 & 33.8 $\\pm$ 0.4 & 42.3 $\\pm$ 0.4 & 72.3 $\\pm$ 0.4 & 34.3 $\\pm$ 0.4 & 62.5 $\\pm$ 0.4 & 33.2 $\\pm$ 0.4 & 69.1 $\\pm$ 0.4 & - & - \\\\\n",
      "\\midrule\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\caption{Benchmark results for different personality traits on Llama3 70B.}\n",
      "\\label{tab:benchmark_results_llama3_70b}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to create LaTeX table\n",
    "def create_latex_table(data):\n",
    "    latex_table = r\"\\begin{table}[htbp]\" + \"\\n\"\n",
    "    latex_table += r\"\\centering\" + \"\\n\"\n",
    "    latex_table += r\"\\resizebox{\\textwidth}{!}{%\" + \"\\n\"\n",
    "    latex_table += r\"\\begin{tabular}{llcccccccccccc}\" + \"\\n\"\n",
    "    latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    latex_table += r\"\\multirow[c]{2}{*}{\\textbf{Benchmark}} & \\multirow[c]{2}{*}{\\textbf{Original}} & \\multirow[c]{2}{*}{\\textbf{Method}} & \\multicolumn{2}{c}{\\textbf{Openness}} & \\multicolumn{2}{c}{\\textbf{Conscientiousness}} & \\multicolumn{2}{c}{\\textbf{Extraversion}} & \\multicolumn{2}{c}{\\textbf{Agreeableness}} & \\multicolumn{2}{c}{\\textbf{Neuroticism}} & \\multicolumn{2}{c}{\\textbf{Average}} \\\\\" + \"\\n\"\n",
    "    latex_table += r\" & & & High & Low & High & Low & High & Low & High & Low & High & Low & \\textbf{High} & \\textbf{Low} \\\\\" + \"\\n\"\n",
    "    latex_table += r\"\\midrule\" + \"\\n\"\n",
    "\n",
    "    for benchmark in data:\n",
    "        latex_table += r\"\\multirow[c]{3}{*}{\\textbf{\" + benchmark[\"name\"] + r\"}}\" + \"\\n\"\n",
    "        latex_table += r\" & \\multirow[c]{3}{*}{\" + benchmark[\"original\"] + r\"} & Prompt & \" + \" & \".join(benchmark[\"prompt\"]) + r\" \\\\\" + \"\\n\"\n",
    "        latex_table += r\" & & SFT & \" + \" & \".join(benchmark[\"sft\"]) + r\" \\\\\" + \"\\n\"\n",
    "        latex_table += r\" & & DPO & \" + \" & \".join(benchmark[\"dpo\"]) + r\" \\\\\" + \"\\n\"\n",
    "        latex_table += r\"\\midrule\" + \"\\n\"\n",
    "\n",
    "    latex_table += r\"\\bottomrule\" + \"\\n\"\n",
    "    latex_table += r\"\\end{tabular}\" + \"\\n\"\n",
    "    latex_table += r\"}\" + \"\\n\"\n",
    "    latex_table += r\"\\caption{Benchmark results for different personality traits on Llama3 70B.}\" + \"\\n\"\n",
    "    latex_table += r\"\\label{tab:benchmark_results_llama3_70b}\" + \"\\n\"\n",
    "    latex_table += r\"\\end{table}\"\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "# Data for the table\n",
    "data = [\n",
    "    {\n",
    "        \"name\": \"TruthfulQA\",\n",
    "        \"original\": \"-\",\n",
    "        \"prompt\": [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "        \"sft\": [\"55.2 $\\pm$ 1.6\", \"52.8 $\\pm$ 1.6\", \"55.6 $\\pm$ 1.6\", \"50.8 $\\pm$ 1.5\", \"54.5 $\\pm$ 1.6\", \"56.7 $\\pm$ 1.6\", \"54.4 $\\pm$ 1.6\", \"51.6 $\\pm$ 1.6\", \"52.4 $\\pm$ 1.5\", \"56.7 $\\pm$ 1.6\", \"-\", \"-\"],\n",
    "        \"dpo\": [\"54.6 $\\pm$ 1.6\", \"54.2 $\\pm$ 1.7\", \"64.6 $\\pm$ 1.6\", \"38.5 $\\pm$ 1.6\", \"46.0 $\\pm$ 1.7\", \"65.3 $\\pm$ 1.6\", \"59.6 $\\pm$ 1.6\", \"50.6 $\\pm$ 1.6\", \"43.0 $\\pm$ 1.7\", \"65.8 $\\pm$ 1.6\", \"-\", \"-\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"GPQA Zero Shot\",\n",
    "        \"original\": \"-\",\n",
    "        \"prompt\": [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "        \"sft\": [\"33.5 $\\pm$ 2.2\", \"32.4 $\\pm$ 2.2\", \"34.2 $\\pm$ 2.2\", \"34.2 $\\pm$ 2.2\", \"33.3 $\\pm$ 2.2\", \"34.4 $\\pm$ 2.2\", \"33.3 $\\pm$ 2.2\", \"33.3 $\\pm$ 2.2\", \"34.4 $\\pm$ 2.2\", \"33.5 $\\pm$ 2.2\", \"-\", \"-\"],\n",
    "        \"dpo\": [\"36.8 $\\pm$ 2.3\", \"31.9 $\\pm$ 2.2\", \"35.7 $\\pm$ 2.3\", \"30.6 $\\pm$ 2.2\", \"35.9 $\\pm$ 2.3\", \"35.9 $\\pm$ 2.3\", \"35.5 $\\pm$ 2.3\", \"35.7 $\\pm$ 2.3\", \"32.6 $\\pm$ 2.2\", \"34.6 $\\pm$ 2.2\", \"-\", \"-\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"GPQA N Shot\",\n",
    "        \"original\": \"-\",\n",
    "        \"prompt\": [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "        \"sft\": [\"32.4 $\\pm$ 2.2\", \"32.8 $\\pm$ 2.2\", \"34.4 $\\pm$ 2.2\", \"33.7 $\\pm$ 2.2\", \"33.0 $\\pm$ 2.2\", \"33.9 $\\pm$ 2.2\", \"33.7 $\\pm$ 2.2\", \"32.8 $\\pm$ 2.2\", \"33.7 $\\pm$ 2.2\", \"34.8 $\\pm$ 2.3\", \"-\", \"-\"],\n",
    "        \"dpo\": [\"37.5 $\\pm$ 2.3\", \"31.2 $\\pm$ 2.2\", \"35.9 $\\pm$ 2.3\", \"31.2 $\\pm$ 2.2\", \"37.1 $\\pm$ 2.3\", \"35.5 $\\pm$ 2.3\", \"33.5 $\\pm$ 2.2\", \"32.1 $\\pm$ 2.2\", \"36.6 $\\pm$ 2.3\", \"35.7 $\\pm$ 2.3\", \"-\", \"-\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SocialIQA\",\n",
    "        \"original\": \"-\",\n",
    "        \"prompt\": [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "        \"sft\": [\"50.3 $\\pm$ 1.1\", \"50.4 $\\pm$ 1.1\", \"50.9 $\\pm$ 1.1\", \"46.8 $\\pm$ 1.1\", \"50.0 $\\pm$ 1.1\", \"50.3 $\\pm$ 1.1\", \"50.5 $\\pm$ 1.1\", \"46.6 $\\pm$ 1.1\", \"48.2 $\\pm$ 1.1\", \"50.6 $\\pm$ 1.1\", \"-\", \"-\"],\n",
    "        \"dpo\": [\"41.5 $\\pm$ 1.1\", \"44.5 $\\pm$ 1.1\", \"44.7 $\\pm$ 1.1\", \"37.6 $\\pm$ 1.1\", \"43.0 $\\pm$ 1.1\", \"43.6 $\\pm$ 1.1\", \"44.8 $\\pm$ 1.1\", \"39.0 $\\pm$ 1.1\", \"40.0 $\\pm$ 1.1\", \"45.3 $\\pm$ 1.1\", \"-\", \"-\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CommonsenseQA\",\n",
    "        \"original\": \"-\",\n",
    "        \"prompt\": [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "        \"sft\": [\"77.7 $\\pm$ 1.2\", \"78.8 $\\pm$ 1.2\", \"77.6 $\\pm$ 1.2\", \"66.0 $\\pm$ 1.4\", \"75.7 $\\pm$ 1.2\", \"78.9 $\\pm$ 1.2\", \"77.0 $\\pm$ 1.2\", \"73.8 $\\pm$ 1.3\", \"79.1 $\\pm$ 1.2\", \"78.5 $\\pm$ 1.2\", \"-\", \"-\"],\n",
    "        \"dpo\": [\"57.7 $\\pm$ 1.4\", \"65.9 $\\pm$ 1.4\", \"23.8 $\\pm$ 1.2\", \"25.8 $\\pm$ 1.3\", \"23.2 $\\pm$ 1.2\", \"70.8 $\\pm$ 1.3\", \"21.3 $\\pm$ 1.2\", \"39.2 $\\pm$ 1.4\", \"20.1 $\\pm$ 1.1\", \"44.6 $\\pm$ 1.4\", \"-\", \"-\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"GSM8K\",\n",
    "        \"original\": \"-\",\n",
    "        \"prompt\": [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "        \"sft\": [\"85.8 $\\pm$ 1.0\", \"76.2 $\\pm$ 1.2\", \"86.4 $\\pm$ 0.9\", \"81.7 $\\pm$ 1.1\", \"85.1 $\\pm$ 1.0\", \"86.7 $\\pm$ 0.9\", \"87.0 $\\pm$ 0.9\", \"74.5 $\\pm$ 1.2\", \"76.0 $\\pm$ 1.2\", \"87.3 $\\pm$ 0.9\", \"-\", \"-\"],\n",
    "        \"dpo\": [\"87.9 $\\pm$ 0.9\", \"88.5 $\\pm$ 0.9\", \"90.2 $\\pm$ 0.8\", \"80.6 $\\pm$ 1.1\", \"88.9 $\\pm$ 0.9\", \"90.4 $\\pm$ 0.8\", \"87.3 $\\pm$ 0.9\", \"90.0 $\\pm$ 0.8\", \"15.2 $\\pm$ 1.0\", \"91.0 $\\pm$ 0.8\", \"-\", \"-\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"MathQA\",\n",
    "        \"original\": \"-\",\n",
    "        \"prompt\": [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "        \"sft\": [\"43.3 $\\pm$ 0.9\", \"42.6 $\\pm$ 0.9\", \"43.0 $\\pm$ 0.9\", \"43.3 $\\pm$ 0.9\", \"43.2 $\\pm$ 0.9\", \"42.7 $\\pm$ 0.9\", \"42.9 $\\pm$ 0.9\", \"42.9 $\\pm$ 0.9\", \"42.8 $\\pm$ 0.9\", \"43.3 $\\pm$ 0.9\", \"-\", \"-\"],\n",
    "        \"dpo\": [\"33.9 $\\pm$ 0.9\", \"34.7 $\\pm$ 0.9\", \"32.9 $\\pm$ 0.9\", \"28.1 $\\pm$ 0.8\", \"30.5 $\\pm$ 0.8\", \"35.0 $\\pm$ 0.9\", \"31.3 $\\pm$ 0.8\", \"32.8 $\\pm$ 0.9\", \"28.9 $\\pm$ 0.8\", \"34.0 $\\pm$ 0.9\", \"-\", \"-\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"MMLU\",\n",
    "        \"original\": \"-\",\n",
    "        \"prompt\": [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "        \"sft\": [\"72.5 $\\pm$ 0.4\", \"72.0 $\\pm$ 0.4\", \"73.1 $\\pm$ 0.4\", \"68.6 $\\pm$ 0.4\", \"72.1 $\\pm$ 0.4\", \"73.5 $\\pm$ 0.4\", \"72.8 $\\pm$ 0.4\", \"70.7 $\\pm$ 0.4\", \"72.5 $\\pm$ 0.4\", \"73.8 $\\pm$ 0.4\", \"-\", \"-\"],\n",
    "        \"dpo\": [\"57.9 $\\pm$ 0.4\", \"64.4 $\\pm$ 0.4\", \"50.3 $\\pm$ 0.4\", \"33.8 $\\pm$ 0.4\", \"42.3 $\\pm$ 0.4\", \"72.3 $\\pm$ 0.4\", \"34.3 $\\pm$ 0.4\", \"62.5 $\\pm$ 0.4\", \"33.2 $\\pm$ 0.4\", \"69.1 $\\pm$ 0.4\", \"-\", \"-\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Generate the LaTeX table\n",
    "latex_table = create_latex_table(data)\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
