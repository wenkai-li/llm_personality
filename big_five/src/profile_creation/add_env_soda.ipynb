{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "__module__  :  __main__\n",
      "---------------------------------------\n",
      "in_file  :  /data/user_data/wenkail/llm_personality/soda_data/sample_10000.csv\n",
      "---------------------------------------\n",
      "out_file  :  /home/jiaruil5/personality/llm_personality/big_five/src/profile_creation/test_gpt.jsonl\n",
      "---------------------------------------\n",
      "generation_limit  :  None\n",
      "---------------------------------------\n",
      "model  :  gpt-3.5-turbo\n",
      "---------------------------------------\n",
      "min_dialogue_turn  :  2\n",
      "---------------------------------------\n",
      "conversation_continuation_count  :  1\n",
      "---------------------------------------\n",
      "generation_attempt_count  :  2\n",
      "---------------------------------------\n",
      "repetition_tolerance  :  1\n",
      "---------------------------------------\n",
      "__dict__  :  <attribute '__dict__' of 'args' objects>\n",
      "---------------------------------------\n",
      "__weakref__  :  <attribute '__weakref__' of 'args' objects>\n",
      "---------------------------------------\n",
      "__doc__  :  None\n",
      "=======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from env_generate_script import CO3\n",
    "class args:\n",
    "    in_file = \"/data/user_data/wenkail/llm_personality/soda_data/sample_10000.csv\"\n",
    "    # out_file = \"/data/user_data/wenkail/llm_personality/profiles/env_profiles.jsonl\"\n",
    "    out_file = \"/home/jiaruil5/personality/llm_personality/big_five/src/profile_creation/test_gpt.jsonl\"\n",
    "    generation_limit = None\n",
    "    model = \"gpt-3.5-turbo\"\n",
    "    min_dialogue_turn = 2\n",
    "    conversation_continuation_count = 1\n",
    "    generation_attempt_count = 2\n",
    "    repetition_tolerance = 1\n",
    "soda_maker = CO3(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soda_maker.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
